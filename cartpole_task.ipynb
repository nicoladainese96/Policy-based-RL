{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving cartpole task with policy-based RL algorithms\n",
    "\n",
    "**Decription of the task:**\n",
    "A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The system is controlled by applying a force of +1 or -1 to the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every timestep that the pole remains upright. The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import gym\n",
    "import agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Policy-Gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'agents' from '/home/nicola/Nicola_unipd/MasterThesis/Policy-based-RL/agents.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_episode(agent, env, return_states=False, greedy=True):\n",
    "    # Reset environment (start of an episode)\n",
    "    state = env.reset()\n",
    "    rewards = []\n",
    "    log_probs = []\n",
    "    done = []\n",
    "    \n",
    "    if return_states:\n",
    "        states = [state]\n",
    "        \n",
    "        \n",
    "    steps = 0\n",
    "    while True:\n",
    "        action, log_prob = agent.get_action(state, return_log = True, greedy=greedy)\n",
    "        new_state, reward, terminal, info = env.step(action) # gym standard step's output\n",
    "        \n",
    "        if return_states:\n",
    "            states.append(new_state)\n",
    "            \n",
    "        #if terminal and 'TimeLimit.truncated' not in info:\n",
    "        #    reward = -1\n",
    "            #print(\"terminal \", terminal)\n",
    "            #print(\"reward \", reward)\n",
    "            \n",
    "        rewards.append(reward)\n",
    "        log_probs.append(log_prob)\n",
    "        done.append(terminal)\n",
    "        \n",
    "        if terminal:\n",
    "            break\n",
    "            \n",
    "        state = new_state\n",
    "       \n",
    "    rewards = np.array(rewards)\n",
    "    log_probs = np.array(log_probs)\n",
    "    done = np.array(done)\n",
    "    \n",
    "    if return_states:\n",
    "        return rewards, log_probs, np.array(states), done\n",
    "    else:\n",
    "        return rewards, log_probs, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_cartpole(n_episodes = 100, lr = 0.01, gamma = 0.99, greedy=False):\n",
    "    # Create environment\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    observation_space = env.observation_space.shape[0]\n",
    "    action_space = env.action_space.n\n",
    "    # Init agent\n",
    "    agent = agents.PolicyGrad(observation_space, action_space, lr, gamma)\n",
    "    performance = []\n",
    "    losses = []\n",
    "    for e in range(n_episodes):\n",
    "        rewards, log_probs, _ = play_episode(agent, env, greedy=greedy)\n",
    "        performance.append(np.sum(rewards))\n",
    "        if (e+1)%10 == 0:\n",
    "            print(\"Episode %d - reward: %.0f\"%(e+1, np.mean(performance[-10:])))\n",
    "        \n",
    "        loss = agent.update(rewards, log_probs)\n",
    "        losses.append(loss)\n",
    "    return agent, np.array(performance), np.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "Episode 10 - reward: 28\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "Episode 20 - reward: 27\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "Episode 30 - reward: 50\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "Episode 40 - reward: 33\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "Episode 50 - reward: 27\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "Episode 60 - reward: 44\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "Episode 70 - reward: 53\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n",
      "terminal  True\n",
      "reward  1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f9336b4ee68e>\u001b[0m in \u001b[0;36mtrain_cartpole\u001b[0;34m(n_episodes, lr, gamma, greedy)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Episode %d - reward: %.0f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperformance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperformance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/MasterThesis/Policy-based-RL/agents.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, rewards, log_probs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mdr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscounted_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mpolicy_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trained_agentPG, cumulative_rewardPG, lossesPG = train_cartpole(n_episodes = 500, lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10 - reward: 19\n",
      "Episode 20 - reward: 46\n",
      "Episode 30 - reward: 56\n",
      "Episode 40 - reward: 86\n",
      "Episode 50 - reward: 85\n",
      "Episode 60 - reward: 67\n",
      "Episode 70 - reward: 214\n",
      "Episode 80 - reward: 408\n",
      "Episode 90 - reward: 456\n",
      "Episode 100 - reward: 416\n",
      "Episode 110 - reward: 389\n",
      "Episode 120 - reward: 500\n",
      "Episode 130 - reward: 434\n",
      "Episode 140 - reward: 157\n",
      "Episode 150 - reward: 174\n",
      "Episode 160 - reward: 388\n",
      "Episode 170 - reward: 500\n",
      "Episode 180 - reward: 359\n",
      "Episode 190 - reward: 420\n",
      "Episode 200 - reward: 500\n",
      "Episode 210 - reward: 442\n",
      "Episode 220 - reward: 367\n",
      "Episode 230 - reward: 263\n",
      "Episode 240 - reward: 101\n",
      "Episode 250 - reward: 89\n",
      "Episode 260 - reward: 98\n",
      "Episode 270 - reward: 85\n",
      "Episode 280 - reward: 100\n",
      "Episode 290 - reward: 108\n",
      "Episode 300 - reward: 89\n",
      "Episode 310 - reward: 70\n",
      "Episode 320 - reward: 106\n",
      "Episode 330 - reward: 121\n",
      "Episode 340 - reward: 124\n",
      "Episode 350 - reward: 126\n",
      "Episode 360 - reward: 140\n",
      "Episode 370 - reward: 224\n",
      "Episode 380 - reward: 268\n",
      "Episode 390 - reward: 302\n",
      "Episode 400 - reward: 440\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 500\n",
      "Episode 440 - reward: 499\n",
      "Episode 450 - reward: 441\n",
      "Episode 460 - reward: 72\n",
      "Episode 470 - reward: 27\n",
      "Episode 480 - reward: 34\n",
      "Episode 490 - reward: 58\n",
      "Episode 500 - reward: 106\n",
      "Episode 10 - reward: 20\n",
      "Episode 20 - reward: 27\n",
      "Episode 30 - reward: 29\n",
      "Episode 40 - reward: 43\n",
      "Episode 50 - reward: 36\n",
      "Episode 60 - reward: 26\n",
      "Episode 70 - reward: 38\n",
      "Episode 80 - reward: 80\n",
      "Episode 90 - reward: 63\n",
      "Episode 100 - reward: 97\n",
      "Episode 110 - reward: 82\n",
      "Episode 120 - reward: 100\n",
      "Episode 130 - reward: 323\n",
      "Episode 140 - reward: 392\n",
      "Episode 150 - reward: 223\n",
      "Episode 160 - reward: 221\n",
      "Episode 170 - reward: 188\n",
      "Episode 180 - reward: 352\n",
      "Episode 190 - reward: 338\n",
      "Episode 200 - reward: 396\n",
      "Episode 210 - reward: 328\n",
      "Episode 220 - reward: 478\n",
      "Episode 230 - reward: 500\n",
      "Episode 240 - reward: 500\n",
      "Episode 250 - reward: 316\n",
      "Episode 260 - reward: 85\n",
      "Episode 270 - reward: 35\n",
      "Episode 280 - reward: 36\n",
      "Episode 290 - reward: 92\n",
      "Episode 300 - reward: 116\n",
      "Episode 310 - reward: 135\n",
      "Episode 320 - reward: 166\n",
      "Episode 330 - reward: 198\n",
      "Episode 340 - reward: 211\n",
      "Episode 350 - reward: 253\n",
      "Episode 360 - reward: 477\n",
      "Episode 370 - reward: 500\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 250\n",
      "Episode 400 - reward: 366\n",
      "Episode 410 - reward: 89\n",
      "Episode 420 - reward: 74\n",
      "Episode 430 - reward: 142\n",
      "Episode 440 - reward: 113\n",
      "Episode 450 - reward: 47\n",
      "Episode 460 - reward: 64\n",
      "Episode 470 - reward: 105\n",
      "Episode 480 - reward: 94\n",
      "Episode 490 - reward: 94\n",
      "Episode 500 - reward: 99\n",
      "Episode 10 - reward: 34\n",
      "Episode 20 - reward: 31\n",
      "Episode 30 - reward: 31\n",
      "Episode 40 - reward: 41\n",
      "Episode 50 - reward: 41\n",
      "Episode 60 - reward: 50\n",
      "Episode 70 - reward: 112\n",
      "Episode 80 - reward: 91\n",
      "Episode 90 - reward: 120\n",
      "Episode 100 - reward: 245\n",
      "Episode 110 - reward: 279\n",
      "Episode 120 - reward: 300\n",
      "Episode 130 - reward: 290\n",
      "Episode 140 - reward: 87\n",
      "Episode 150 - reward: 26\n",
      "Episode 160 - reward: 24\n",
      "Episode 170 - reward: 26\n",
      "Episode 180 - reward: 43\n",
      "Episode 190 - reward: 58\n",
      "Episode 200 - reward: 112\n",
      "Episode 210 - reward: 147\n",
      "Episode 220 - reward: 184\n",
      "Episode 230 - reward: 168\n",
      "Episode 240 - reward: 141\n",
      "Episode 250 - reward: 126\n",
      "Episode 260 - reward: 151\n",
      "Episode 270 - reward: 224\n",
      "Episode 280 - reward: 253\n",
      "Episode 290 - reward: 222\n",
      "Episode 300 - reward: 196\n",
      "Episode 310 - reward: 175\n",
      "Episode 320 - reward: 238\n",
      "Episode 330 - reward: 293\n",
      "Episode 340 - reward: 265\n",
      "Episode 350 - reward: 243\n",
      "Episode 360 - reward: 400\n",
      "Episode 370 - reward: 500\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 500\n",
      "Episode 400 - reward: 500\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 474\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 500\n",
      "Episode 460 - reward: 500\n",
      "Episode 470 - reward: 500\n",
      "Episode 480 - reward: 500\n",
      "Episode 490 - reward: 500\n",
      "Episode 500 - reward: 500\n",
      "Episode 10 - reward: 18\n",
      "Episode 20 - reward: 29\n",
      "Episode 30 - reward: 24\n",
      "Episode 40 - reward: 39\n",
      "Episode 50 - reward: 27\n",
      "Episode 60 - reward: 86\n",
      "Episode 70 - reward: 136\n",
      "Episode 80 - reward: 256\n",
      "Episode 90 - reward: 216\n",
      "Episode 100 - reward: 390\n",
      "Episode 110 - reward: 344\n",
      "Episode 120 - reward: 84\n",
      "Episode 130 - reward: 56\n",
      "Episode 140 - reward: 71\n",
      "Episode 150 - reward: 68\n",
      "Episode 160 - reward: 82\n",
      "Episode 170 - reward: 96\n",
      "Episode 180 - reward: 352\n",
      "Episode 190 - reward: 342\n",
      "Episode 200 - reward: 473\n",
      "Episode 210 - reward: 500\n",
      "Episode 220 - reward: 479\n",
      "Episode 230 - reward: 173\n",
      "Episode 240 - reward: 94\n",
      "Episode 250 - reward: 113\n",
      "Episode 260 - reward: 135\n",
      "Episode 270 - reward: 188\n",
      "Episode 280 - reward: 154\n",
      "Episode 290 - reward: 154\n",
      "Episode 300 - reward: 91\n",
      "Episode 310 - reward: 82\n",
      "Episode 320 - reward: 100\n",
      "Episode 330 - reward: 214\n",
      "Episode 340 - reward: 316\n",
      "Episode 350 - reward: 133\n",
      "Episode 360 - reward: 94\n",
      "Episode 370 - reward: 162\n",
      "Episode 380 - reward: 360\n",
      "Episode 390 - reward: 455\n",
      "Episode 400 - reward: 464\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 454\n",
      "Episode 430 - reward: 289\n",
      "Episode 440 - reward: 209\n",
      "Episode 450 - reward: 289\n",
      "Episode 460 - reward: 453\n",
      "Episode 470 - reward: 500\n",
      "Episode 480 - reward: 500\n",
      "Episode 490 - reward: 498\n",
      "Episode 500 - reward: 419\n",
      "Episode 10 - reward: 21\n",
      "Episode 20 - reward: 24\n",
      "Episode 30 - reward: 39\n",
      "Episode 40 - reward: 44\n",
      "Episode 50 - reward: 55\n",
      "Episode 60 - reward: 74\n",
      "Episode 70 - reward: 84\n",
      "Episode 80 - reward: 110\n",
      "Episode 90 - reward: 153\n",
      "Episode 100 - reward: 20\n",
      "Episode 110 - reward: 17\n",
      "Episode 120 - reward: 22\n",
      "Episode 130 - reward: 18\n",
      "Episode 140 - reward: 18\n",
      "Episode 150 - reward: 19\n",
      "Episode 160 - reward: 26\n",
      "Episode 170 - reward: 29\n",
      "Episode 180 - reward: 29\n",
      "Episode 190 - reward: 33\n",
      "Episode 200 - reward: 42\n",
      "Episode 210 - reward: 36\n",
      "Episode 220 - reward: 44\n",
      "Episode 230 - reward: 92\n",
      "Episode 240 - reward: 112\n",
      "Episode 250 - reward: 70\n",
      "Episode 260 - reward: 70\n",
      "Episode 270 - reward: 160\n",
      "Episode 280 - reward: 227\n",
      "Episode 290 - reward: 272\n",
      "Episode 300 - reward: 161\n",
      "Episode 310 - reward: 128\n",
      "Episode 320 - reward: 121\n",
      "Episode 330 - reward: 177\n",
      "Episode 340 - reward: 273\n",
      "Episode 350 - reward: 388\n",
      "Episode 360 - reward: 492\n",
      "Episode 370 - reward: 444\n",
      "Episode 380 - reward: 477\n",
      "Episode 390 - reward: 410\n",
      "Episode 400 - reward: 500\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 500\n",
      "Episode 440 - reward: 359\n",
      "Episode 450 - reward: 254\n",
      "Episode 460 - reward: 324\n",
      "Episode 470 - reward: 155\n",
      "Episode 480 - reward: 109\n",
      "Episode 490 - reward: 114\n",
      "Episode 500 - reward: 116\n",
      "Episode 10 - reward: 21\n",
      "Episode 20 - reward: 19\n",
      "Episode 30 - reward: 30\n",
      "Episode 40 - reward: 39\n",
      "Episode 50 - reward: 69\n",
      "Episode 60 - reward: 58\n",
      "Episode 70 - reward: 99\n",
      "Episode 80 - reward: 94\n",
      "Episode 90 - reward: 174\n",
      "Episode 100 - reward: 72\n",
      "Episode 110 - reward: 36\n",
      "Episode 120 - reward: 32\n",
      "Episode 130 - reward: 26\n",
      "Episode 140 - reward: 25\n",
      "Episode 150 - reward: 25\n",
      "Episode 160 - reward: 25\n",
      "Episode 170 - reward: 26\n",
      "Episode 180 - reward: 28\n",
      "Episode 190 - reward: 26\n",
      "Episode 200 - reward: 27\n",
      "Episode 210 - reward: 29\n",
      "Episode 220 - reward: 40\n",
      "Episode 230 - reward: 51\n",
      "Episode 240 - reward: 62\n",
      "Episode 250 - reward: 71\n",
      "Episode 260 - reward: 53\n",
      "Episode 270 - reward: 43\n",
      "Episode 280 - reward: 36\n",
      "Episode 290 - reward: 33\n",
      "Episode 300 - reward: 34\n",
      "Episode 310 - reward: 44\n",
      "Episode 320 - reward: 101\n",
      "Episode 330 - reward: 180\n",
      "Episode 340 - reward: 314\n",
      "Episode 350 - reward: 244\n",
      "Episode 360 - reward: 170\n",
      "Episode 370 - reward: 260\n",
      "Episode 380 - reward: 260\n",
      "Episode 390 - reward: 116\n",
      "Episode 400 - reward: 86\n",
      "Episode 410 - reward: 129\n",
      "Episode 420 - reward: 185\n",
      "Episode 430 - reward: 218\n",
      "Episode 440 - reward: 171\n",
      "Episode 450 - reward: 157\n",
      "Episode 460 - reward: 157\n",
      "Episode 470 - reward: 171\n",
      "Episode 480 - reward: 174\n",
      "Episode 490 - reward: 226\n",
      "Episode 500 - reward: 328\n",
      "Episode 10 - reward: 20\n",
      "Episode 20 - reward: 25\n",
      "Episode 30 - reward: 28\n",
      "Episode 40 - reward: 26\n",
      "Episode 50 - reward: 24\n",
      "Episode 60 - reward: 17\n",
      "Episode 70 - reward: 14\n",
      "Episode 80 - reward: 18\n",
      "Episode 90 - reward: 22\n",
      "Episode 100 - reward: 36\n",
      "Episode 110 - reward: 75\n",
      "Episode 120 - reward: 97\n",
      "Episode 130 - reward: 155\n",
      "Episode 140 - reward: 138\n",
      "Episode 150 - reward: 64\n",
      "Episode 160 - reward: 64\n",
      "Episode 170 - reward: 177\n",
      "Episode 180 - reward: 455\n",
      "Episode 190 - reward: 187\n",
      "Episode 200 - reward: 94\n",
      "Episode 210 - reward: 342\n",
      "Episode 220 - reward: 457\n",
      "Episode 230 - reward: 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 240 - reward: 500\n",
      "Episode 250 - reward: 377\n",
      "Episode 260 - reward: 194\n",
      "Episode 270 - reward: 154\n",
      "Episode 280 - reward: 229\n",
      "Episode 290 - reward: 362\n",
      "Episode 300 - reward: 364\n",
      "Episode 310 - reward: 430\n",
      "Episode 320 - reward: 500\n",
      "Episode 330 - reward: 500\n",
      "Episode 340 - reward: 500\n",
      "Episode 350 - reward: 500\n",
      "Episode 360 - reward: 500\n",
      "Episode 370 - reward: 500\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 500\n",
      "Episode 400 - reward: 500\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 500\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 500\n",
      "Episode 460 - reward: 500\n",
      "Episode 470 - reward: 500\n",
      "Episode 480 - reward: 500\n",
      "Episode 490 - reward: 500\n",
      "Episode 500 - reward: 500\n",
      "Episode 10 - reward: 23\n",
      "Episode 20 - reward: 26\n",
      "Episode 30 - reward: 52\n",
      "Episode 40 - reward: 102\n",
      "Episode 50 - reward: 112\n",
      "Episode 60 - reward: 116\n",
      "Episode 70 - reward: 86\n",
      "Episode 80 - reward: 72\n",
      "Episode 90 - reward: 235\n",
      "Episode 100 - reward: 90\n",
      "Episode 110 - reward: 287\n",
      "Episode 120 - reward: 377\n",
      "Episode 130 - reward: 64\n",
      "Episode 140 - reward: 46\n",
      "Episode 150 - reward: 48\n",
      "Episode 160 - reward: 102\n",
      "Episode 170 - reward: 156\n",
      "Episode 180 - reward: 219\n",
      "Episode 190 - reward: 305\n",
      "Episode 200 - reward: 157\n",
      "Episode 210 - reward: 119\n",
      "Episode 220 - reward: 121\n",
      "Episode 230 - reward: 130\n",
      "Episode 240 - reward: 132\n",
      "Episode 250 - reward: 149\n",
      "Episode 260 - reward: 141\n",
      "Episode 270 - reward: 127\n",
      "Episode 280 - reward: 146\n",
      "Episode 290 - reward: 152\n",
      "Episode 300 - reward: 120\n",
      "Episode 310 - reward: 101\n",
      "Episode 320 - reward: 74\n",
      "Episode 330 - reward: 59\n",
      "Episode 340 - reward: 66\n",
      "Episode 350 - reward: 79\n",
      "Episode 360 - reward: 79\n",
      "Episode 370 - reward: 74\n",
      "Episode 380 - reward: 63\n",
      "Episode 390 - reward: 65\n",
      "Episode 400 - reward: 74\n",
      "Episode 410 - reward: 94\n",
      "Episode 420 - reward: 92\n",
      "Episode 430 - reward: 90\n",
      "Episode 440 - reward: 85\n",
      "Episode 450 - reward: 74\n",
      "Episode 460 - reward: 69\n",
      "Episode 470 - reward: 68\n",
      "Episode 480 - reward: 75\n",
      "Episode 490 - reward: 110\n",
      "Episode 500 - reward: 129\n",
      "Episode 10 - reward: 35\n",
      "Episode 20 - reward: 32\n",
      "Episode 30 - reward: 60\n",
      "Episode 40 - reward: 79\n",
      "Episode 50 - reward: 70\n",
      "Episode 60 - reward: 127\n",
      "Episode 70 - reward: 320\n",
      "Episode 80 - reward: 266\n",
      "Episode 90 - reward: 184\n",
      "Episode 100 - reward: 321\n",
      "Episode 110 - reward: 399\n",
      "Episode 120 - reward: 265\n",
      "Episode 130 - reward: 164\n",
      "Episode 140 - reward: 62\n",
      "Episode 150 - reward: 42\n",
      "Episode 160 - reward: 35\n",
      "Episode 170 - reward: 36\n",
      "Episode 180 - reward: 44\n",
      "Episode 190 - reward: 57\n",
      "Episode 200 - reward: 72\n",
      "Episode 210 - reward: 79\n",
      "Episode 220 - reward: 167\n",
      "Episode 230 - reward: 78\n",
      "Episode 240 - reward: 62\n",
      "Episode 250 - reward: 56\n",
      "Episode 260 - reward: 58\n",
      "Episode 270 - reward: 46\n",
      "Episode 280 - reward: 39\n",
      "Episode 290 - reward: 41\n",
      "Episode 300 - reward: 51\n",
      "Episode 310 - reward: 71\n",
      "Episode 320 - reward: 116\n",
      "Episode 330 - reward: 290\n",
      "Episode 340 - reward: 244\n",
      "Episode 350 - reward: 464\n",
      "Episode 360 - reward: 474\n",
      "Episode 370 - reward: 500\n",
      "Episode 380 - reward: 497\n",
      "Episode 390 - reward: 443\n",
      "Episode 400 - reward: 367\n",
      "Episode 410 - reward: 174\n",
      "Episode 420 - reward: 390\n",
      "Episode 430 - reward: 317\n",
      "Episode 440 - reward: 123\n",
      "Episode 450 - reward: 117\n",
      "Episode 460 - reward: 130\n",
      "Episode 470 - reward: 459\n",
      "Episode 480 - reward: 402\n",
      "Episode 490 - reward: 245\n",
      "Episode 500 - reward: 197\n",
      "Episode 10 - reward: 35\n",
      "Episode 20 - reward: 37\n",
      "Episode 30 - reward: 33\n",
      "Episode 40 - reward: 48\n",
      "Episode 50 - reward: 50\n",
      "Episode 60 - reward: 71\n",
      "Episode 70 - reward: 89\n",
      "Episode 80 - reward: 90\n",
      "Episode 90 - reward: 144\n",
      "Episode 100 - reward: 101\n",
      "Episode 110 - reward: 164\n",
      "Episode 120 - reward: 180\n",
      "Episode 130 - reward: 147\n",
      "Episode 140 - reward: 94\n",
      "Episode 150 - reward: 110\n",
      "Episode 160 - reward: 117\n",
      "Episode 170 - reward: 159\n",
      "Episode 180 - reward: 179\n",
      "Episode 190 - reward: 332\n",
      "Episode 200 - reward: 476\n",
      "Episode 210 - reward: 500\n",
      "Episode 220 - reward: 397\n",
      "Episode 230 - reward: 496\n",
      "Episode 240 - reward: 491\n",
      "Episode 250 - reward: 487\n",
      "Episode 260 - reward: 485\n",
      "Episode 270 - reward: 500\n",
      "Episode 280 - reward: 422\n",
      "Episode 290 - reward: 445\n",
      "Episode 300 - reward: 415\n",
      "Episode 310 - reward: 500\n",
      "Episode 320 - reward: 500\n",
      "Episode 330 - reward: 456\n",
      "Episode 340 - reward: 485\n",
      "Episode 350 - reward: 500\n",
      "Episode 360 - reward: 500\n",
      "Episode 370 - reward: 500\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 481\n",
      "Episode 400 - reward: 500\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 500\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 500\n",
      "Episode 460 - reward: 500\n",
      "Episode 470 - reward: 500\n",
      "Episode 480 - reward: 494\n",
      "Episode 490 - reward: 500\n",
      "Episode 500 - reward: 500\n",
      "Episode 10 - reward: 24\n",
      "Episode 20 - reward: 16\n",
      "Episode 30 - reward: 24\n",
      "Episode 40 - reward: 28\n",
      "Episode 50 - reward: 31\n",
      "Episode 60 - reward: 39\n",
      "Episode 70 - reward: 68\n",
      "Episode 80 - reward: 130\n",
      "Episode 90 - reward: 129\n",
      "Episode 100 - reward: 105\n",
      "Episode 110 - reward: 109\n",
      "Episode 120 - reward: 253\n",
      "Episode 130 - reward: 247\n",
      "Episode 140 - reward: 236\n",
      "Episode 150 - reward: 262\n",
      "Episode 160 - reward: 330\n",
      "Episode 170 - reward: 264\n",
      "Episode 180 - reward: 261\n",
      "Episode 190 - reward: 250\n",
      "Episode 200 - reward: 139\n",
      "Episode 210 - reward: 103\n",
      "Episode 220 - reward: 109\n",
      "Episode 230 - reward: 83\n",
      "Episode 240 - reward: 90\n",
      "Episode 250 - reward: 105\n",
      "Episode 260 - reward: 107\n",
      "Episode 270 - reward: 106\n",
      "Episode 280 - reward: 103\n",
      "Episode 290 - reward: 94\n",
      "Episode 300 - reward: 107\n",
      "Episode 310 - reward: 63\n",
      "Episode 320 - reward: 85\n",
      "Episode 330 - reward: 77\n",
      "Episode 340 - reward: 90\n",
      "Episode 350 - reward: 90\n",
      "Episode 360 - reward: 126\n",
      "Episode 370 - reward: 136\n",
      "Episode 380 - reward: 192\n",
      "Episode 390 - reward: 143\n",
      "Episode 400 - reward: 116\n",
      "Episode 410 - reward: 97\n",
      "Episode 420 - reward: 91\n",
      "Episode 430 - reward: 115\n",
      "Episode 440 - reward: 140\n",
      "Episode 450 - reward: 128\n",
      "Episode 460 - reward: 69\n",
      "Episode 470 - reward: 70\n",
      "Episode 480 - reward: 93\n",
      "Episode 490 - reward: 131\n",
      "Episode 500 - reward: 146\n",
      "Episode 10 - reward: 21\n",
      "Episode 20 - reward: 36\n",
      "Episode 30 - reward: 22\n",
      "Episode 40 - reward: 35\n",
      "Episode 50 - reward: 42\n",
      "Episode 60 - reward: 54\n",
      "Episode 70 - reward: 38\n",
      "Episode 80 - reward: 38\n",
      "Episode 90 - reward: 68\n",
      "Episode 100 - reward: 53\n",
      "Episode 110 - reward: 77\n",
      "Episode 120 - reward: 74\n",
      "Episode 130 - reward: 79\n",
      "Episode 140 - reward: 124\n",
      "Episode 150 - reward: 193\n",
      "Episode 160 - reward: 184\n",
      "Episode 170 - reward: 74\n",
      "Episode 180 - reward: 107\n",
      "Episode 190 - reward: 162\n",
      "Episode 200 - reward: 107\n",
      "Episode 210 - reward: 80\n",
      "Episode 220 - reward: 173\n",
      "Episode 230 - reward: 356\n",
      "Episode 240 - reward: 335\n",
      "Episode 250 - reward: 278\n",
      "Episode 260 - reward: 138\n",
      "Episode 270 - reward: 100\n",
      "Episode 280 - reward: 107\n",
      "Episode 290 - reward: 120\n",
      "Episode 300 - reward: 129\n",
      "Episode 310 - reward: 86\n",
      "Episode 320 - reward: 108\n",
      "Episode 330 - reward: 89\n",
      "Episode 340 - reward: 90\n",
      "Episode 350 - reward: 159\n",
      "Episode 360 - reward: 215\n",
      "Episode 370 - reward: 209\n",
      "Episode 380 - reward: 336\n",
      "Episode 390 - reward: 412\n",
      "Episode 400 - reward: 212\n",
      "Episode 410 - reward: 291\n",
      "Episode 420 - reward: 211\n",
      "Episode 430 - reward: 187\n",
      "Episode 440 - reward: 147\n",
      "Episode 450 - reward: 171\n",
      "Episode 460 - reward: 169\n",
      "Episode 470 - reward: 176\n",
      "Episode 480 - reward: 150\n",
      "Episode 490 - reward: 169\n",
      "Episode 500 - reward: 258\n",
      "Episode 10 - reward: 19\n",
      "Episode 20 - reward: 22\n",
      "Episode 30 - reward: 32\n",
      "Episode 40 - reward: 31\n",
      "Episode 50 - reward: 66\n",
      "Episode 60 - reward: 64\n",
      "Episode 70 - reward: 89\n",
      "Episode 80 - reward: 128\n",
      "Episode 90 - reward: 44\n",
      "Episode 100 - reward: 103\n",
      "Episode 110 - reward: 74\n",
      "Episode 120 - reward: 115\n",
      "Episode 130 - reward: 133\n",
      "Episode 140 - reward: 107\n",
      "Episode 150 - reward: 91\n",
      "Episode 160 - reward: 89\n",
      "Episode 170 - reward: 111\n",
      "Episode 180 - reward: 96\n",
      "Episode 190 - reward: 100\n",
      "Episode 200 - reward: 100\n",
      "Episode 210 - reward: 141\n",
      "Episode 220 - reward: 306\n",
      "Episode 230 - reward: 424\n",
      "Episode 240 - reward: 382\n",
      "Episode 250 - reward: 394\n",
      "Episode 260 - reward: 500\n",
      "Episode 270 - reward: 500\n",
      "Episode 280 - reward: 500\n",
      "Episode 290 - reward: 500\n",
      "Episode 300 - reward: 500\n",
      "Episode 310 - reward: 500\n",
      "Episode 320 - reward: 409\n",
      "Episode 330 - reward: 500\n",
      "Episode 340 - reward: 420\n",
      "Episode 350 - reward: 357\n",
      "Episode 360 - reward: 355\n",
      "Episode 370 - reward: 378\n",
      "Episode 380 - reward: 385\n",
      "Episode 390 - reward: 197\n",
      "Episode 400 - reward: 327\n",
      "Episode 410 - reward: 453\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 500\n",
      "Episode 440 - reward: 426\n",
      "Episode 450 - reward: 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 460 - reward: 500\n",
      "Episode 470 - reward: 460\n",
      "Episode 480 - reward: 464\n",
      "Episode 490 - reward: 500\n",
      "Episode 500 - reward: 500\n",
      "Episode 10 - reward: 24\n",
      "Episode 20 - reward: 31\n",
      "Episode 30 - reward: 38\n",
      "Episode 40 - reward: 58\n",
      "Episode 50 - reward: 124\n",
      "Episode 60 - reward: 64\n",
      "Episode 70 - reward: 126\n",
      "Episode 80 - reward: 81\n",
      "Episode 90 - reward: 28\n",
      "Episode 100 - reward: 29\n",
      "Episode 110 - reward: 42\n",
      "Episode 120 - reward: 116\n",
      "Episode 130 - reward: 191\n",
      "Episode 140 - reward: 73\n",
      "Episode 150 - reward: 41\n",
      "Episode 160 - reward: 55\n",
      "Episode 170 - reward: 89\n",
      "Episode 180 - reward: 103\n",
      "Episode 190 - reward: 85\n",
      "Episode 200 - reward: 79\n",
      "Episode 210 - reward: 96\n",
      "Episode 220 - reward: 154\n",
      "Episode 230 - reward: 77\n",
      "Episode 240 - reward: 31\n",
      "Episode 250 - reward: 29\n",
      "Episode 260 - reward: 58\n",
      "Episode 270 - reward: 109\n",
      "Episode 280 - reward: 207\n",
      "Episode 290 - reward: 71\n",
      "Episode 300 - reward: 36\n",
      "Episode 310 - reward: 38\n",
      "Episode 320 - reward: 58\n",
      "Episode 330 - reward: 85\n",
      "Episode 340 - reward: 96\n",
      "Episode 350 - reward: 112\n",
      "Episode 360 - reward: 161\n",
      "Episode 370 - reward: 265\n",
      "Episode 380 - reward: 247\n",
      "Episode 390 - reward: 208\n",
      "Episode 400 - reward: 205\n",
      "Episode 410 - reward: 292\n",
      "Episode 420 - reward: 385\n",
      "Episode 430 - reward: 487\n",
      "Episode 440 - reward: 491\n",
      "Episode 450 - reward: 500\n",
      "Episode 460 - reward: 500\n",
      "Episode 470 - reward: 500\n",
      "Episode 480 - reward: 500\n",
      "Episode 490 - reward: 500\n",
      "Episode 500 - reward: 482\n",
      "Episode 10 - reward: 34\n",
      "Episode 20 - reward: 35\n",
      "Episode 30 - reward: 73\n",
      "Episode 40 - reward: 63\n",
      "Episode 50 - reward: 28\n",
      "Episode 60 - reward: 41\n",
      "Episode 70 - reward: 109\n",
      "Episode 80 - reward: 184\n",
      "Episode 90 - reward: 189\n",
      "Episode 100 - reward: 145\n",
      "Episode 110 - reward: 81\n",
      "Episode 120 - reward: 265\n",
      "Episode 130 - reward: 362\n",
      "Episode 140 - reward: 151\n",
      "Episode 150 - reward: 162\n",
      "Episode 160 - reward: 215\n",
      "Episode 170 - reward: 235\n",
      "Episode 180 - reward: 256\n",
      "Episode 190 - reward: 186\n",
      "Episode 200 - reward: 152\n",
      "Episode 210 - reward: 170\n",
      "Episode 220 - reward: 184\n",
      "Episode 230 - reward: 188\n",
      "Episode 240 - reward: 198\n",
      "Episode 250 - reward: 254\n",
      "Episode 260 - reward: 181\n",
      "Episode 270 - reward: 150\n",
      "Episode 280 - reward: 245\n",
      "Episode 290 - reward: 343\n",
      "Episode 300 - reward: 278\n",
      "Episode 310 - reward: 218\n",
      "Episode 320 - reward: 210\n",
      "Episode 330 - reward: 218\n",
      "Episode 340 - reward: 272\n",
      "Episode 350 - reward: 376\n",
      "Episode 360 - reward: 395\n",
      "Episode 370 - reward: 496\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 500\n",
      "Episode 400 - reward: 500\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 363\n",
      "Episode 440 - reward: 200\n",
      "Episode 450 - reward: 433\n",
      "Episode 460 - reward: 500\n",
      "Episode 470 - reward: 500\n",
      "Episode 480 - reward: 500\n",
      "Episode 490 - reward: 500\n",
      "Episode 500 - reward: 403\n",
      "Episode 10 - reward: 17\n",
      "Episode 20 - reward: 20\n",
      "Episode 30 - reward: 25\n",
      "Episode 40 - reward: 26\n",
      "Episode 50 - reward: 24\n",
      "Episode 60 - reward: 19\n",
      "Episode 70 - reward: 22\n",
      "Episode 80 - reward: 30\n",
      "Episode 90 - reward: 51\n",
      "Episode 100 - reward: 82\n",
      "Episode 110 - reward: 82\n",
      "Episode 120 - reward: 196\n",
      "Episode 130 - reward: 385\n",
      "Episode 140 - reward: 318\n",
      "Episode 150 - reward: 63\n",
      "Episode 160 - reward: 109\n",
      "Episode 170 - reward: 59\n",
      "Episode 180 - reward: 80\n",
      "Episode 190 - reward: 96\n",
      "Episode 200 - reward: 366\n",
      "Episode 210 - reward: 491\n",
      "Episode 220 - reward: 364\n",
      "Episode 230 - reward: 269\n",
      "Episode 240 - reward: 135\n",
      "Episode 250 - reward: 131\n",
      "Episode 260 - reward: 116\n",
      "Episode 270 - reward: 117\n",
      "Episode 280 - reward: 120\n",
      "Episode 290 - reward: 118\n",
      "Episode 300 - reward: 113\n",
      "Episode 310 - reward: 120\n",
      "Episode 320 - reward: 118\n",
      "Episode 330 - reward: 138\n",
      "Episode 340 - reward: 131\n",
      "Episode 350 - reward: 142\n",
      "Episode 360 - reward: 182\n",
      "Episode 370 - reward: 458\n",
      "Episode 380 - reward: 488\n",
      "Episode 390 - reward: 500\n",
      "Episode 400 - reward: 500\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 500\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 500\n",
      "Episode 460 - reward: 500\n",
      "Episode 470 - reward: 500\n",
      "Episode 480 - reward: 500\n",
      "Episode 490 - reward: 500\n",
      "Episode 500 - reward: 500\n",
      "Episode 10 - reward: 21\n",
      "Episode 20 - reward: 35\n",
      "Episode 30 - reward: 30\n",
      "Episode 40 - reward: 24\n",
      "Episode 50 - reward: 25\n",
      "Episode 60 - reward: 32\n",
      "Episode 70 - reward: 51\n",
      "Episode 80 - reward: 38\n",
      "Episode 90 - reward: 81\n",
      "Episode 100 - reward: 69\n",
      "Episode 110 - reward: 49\n",
      "Episode 120 - reward: 75\n",
      "Episode 130 - reward: 46\n",
      "Episode 140 - reward: 198\n",
      "Episode 150 - reward: 356\n",
      "Episode 160 - reward: 399\n",
      "Episode 170 - reward: 295\n",
      "Episode 180 - reward: 477\n",
      "Episode 190 - reward: 500\n",
      "Episode 200 - reward: 394\n",
      "Episode 210 - reward: 500\n",
      "Episode 220 - reward: 500\n",
      "Episode 230 - reward: 500\n",
      "Episode 240 - reward: 495\n",
      "Episode 250 - reward: 284\n",
      "Episode 260 - reward: 104\n",
      "Episode 270 - reward: 118\n",
      "Episode 280 - reward: 230\n",
      "Episode 290 - reward: 254\n",
      "Episode 300 - reward: 144\n",
      "Episode 310 - reward: 48\n",
      "Episode 320 - reward: 82\n",
      "Episode 330 - reward: 77\n",
      "Episode 340 - reward: 120\n",
      "Episode 350 - reward: 116\n",
      "Episode 360 - reward: 113\n",
      "Episode 370 - reward: 65\n",
      "Episode 380 - reward: 110\n",
      "Episode 390 - reward: 122\n",
      "Episode 400 - reward: 135\n",
      "Episode 410 - reward: 150\n",
      "Episode 420 - reward: 158\n",
      "Episode 430 - reward: 264\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 500\n",
      "Episode 460 - reward: 500\n",
      "Episode 470 - reward: 500\n",
      "Episode 480 - reward: 500\n",
      "Episode 490 - reward: 500\n",
      "Episode 500 - reward: 500\n",
      "Episode 10 - reward: 19\n",
      "Episode 20 - reward: 21\n",
      "Episode 30 - reward: 21\n",
      "Episode 40 - reward: 27\n",
      "Episode 50 - reward: 49\n",
      "Episode 60 - reward: 66\n",
      "Episode 70 - reward: 31\n",
      "Episode 80 - reward: 86\n",
      "Episode 90 - reward: 154\n",
      "Episode 100 - reward: 70\n",
      "Episode 110 - reward: 280\n",
      "Episode 120 - reward: 430\n",
      "Episode 130 - reward: 96\n",
      "Episode 140 - reward: 29\n",
      "Episode 150 - reward: 111\n",
      "Episode 160 - reward: 282\n",
      "Episode 170 - reward: 490\n",
      "Episode 180 - reward: 481\n",
      "Episode 190 - reward: 490\n",
      "Episode 200 - reward: 500\n",
      "Episode 210 - reward: 500\n",
      "Episode 220 - reward: 111\n",
      "Episode 230 - reward: 99\n",
      "Episode 240 - reward: 156\n",
      "Episode 250 - reward: 138\n",
      "Episode 260 - reward: 270\n",
      "Episode 270 - reward: 500\n",
      "Episode 280 - reward: 500\n",
      "Episode 290 - reward: 496\n",
      "Episode 300 - reward: 470\n",
      "Episode 310 - reward: 390\n",
      "Episode 320 - reward: 395\n",
      "Episode 330 - reward: 500\n",
      "Episode 340 - reward: 500\n",
      "Episode 350 - reward: 500\n",
      "Episode 360 - reward: 500\n",
      "Episode 370 - reward: 500\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 500\n",
      "Episode 400 - reward: 500\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 500\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 446\n",
      "Episode 460 - reward: 461\n",
      "Episode 470 - reward: 447\n",
      "Episode 480 - reward: 500\n",
      "Episode 490 - reward: 500\n",
      "Episode 500 - reward: 500\n",
      "Episode 10 - reward: 20\n",
      "Episode 20 - reward: 26\n",
      "Episode 30 - reward: 35\n",
      "Episode 40 - reward: 50\n",
      "Episode 50 - reward: 47\n",
      "Episode 60 - reward: 158\n",
      "Episode 70 - reward: 148\n",
      "Episode 80 - reward: 61\n",
      "Episode 90 - reward: 62\n",
      "Episode 100 - reward: 51\n",
      "Episode 110 - reward: 34\n",
      "Episode 120 - reward: 66\n",
      "Episode 130 - reward: 98\n",
      "Episode 140 - reward: 63\n",
      "Episode 150 - reward: 87\n",
      "Episode 160 - reward: 56\n",
      "Episode 170 - reward: 42\n",
      "Episode 180 - reward: 78\n",
      "Episode 190 - reward: 79\n",
      "Episode 200 - reward: 96\n",
      "Episode 210 - reward: 160\n",
      "Episode 220 - reward: 252\n",
      "Episode 230 - reward: 159\n",
      "Episode 240 - reward: 172\n",
      "Episode 250 - reward: 165\n",
      "Episode 260 - reward: 86\n",
      "Episode 270 - reward: 73\n",
      "Episode 280 - reward: 104\n",
      "Episode 290 - reward: 166\n",
      "Episode 300 - reward: 248\n",
      "Episode 310 - reward: 195\n",
      "Episode 320 - reward: 134\n",
      "Episode 330 - reward: 116\n",
      "Episode 340 - reward: 112\n",
      "Episode 350 - reward: 137\n",
      "Episode 360 - reward: 188\n",
      "Episode 370 - reward: 384\n",
      "Episode 380 - reward: 216\n",
      "Episode 390 - reward: 137\n",
      "Episode 400 - reward: 119\n",
      "Episode 410 - reward: 128\n",
      "Episode 420 - reward: 167\n",
      "Episode 430 - reward: 127\n",
      "Episode 440 - reward: 115\n",
      "Episode 450 - reward: 110\n",
      "Episode 460 - reward: 152\n",
      "Episode 470 - reward: 300\n",
      "Episode 480 - reward: 431\n",
      "Episode 490 - reward: 230\n",
      "Episode 500 - reward: 194\n",
      "Episode 10 - reward: 20\n",
      "Episode 20 - reward: 36\n",
      "Episode 30 - reward: 32\n",
      "Episode 40 - reward: 43\n",
      "Episode 50 - reward: 64\n",
      "Episode 60 - reward: 98\n",
      "Episode 70 - reward: 148\n",
      "Episode 80 - reward: 57\n",
      "Episode 90 - reward: 52\n",
      "Episode 100 - reward: 50\n",
      "Episode 110 - reward: 72\n",
      "Episode 120 - reward: 55\n",
      "Episode 130 - reward: 85\n",
      "Episode 140 - reward: 150\n",
      "Episode 150 - reward: 358\n",
      "Episode 160 - reward: 372\n",
      "Episode 170 - reward: 65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 180 - reward: 42\n",
      "Episode 190 - reward: 46\n",
      "Episode 200 - reward: 69\n",
      "Episode 210 - reward: 97\n",
      "Episode 220 - reward: 120\n",
      "Episode 230 - reward: 132\n",
      "Episode 240 - reward: 84\n",
      "Episode 250 - reward: 85\n",
      "Episode 260 - reward: 84\n",
      "Episode 270 - reward: 63\n",
      "Episode 280 - reward: 80\n",
      "Episode 290 - reward: 170\n",
      "Episode 300 - reward: 197\n",
      "Episode 310 - reward: 163\n",
      "Episode 320 - reward: 248\n",
      "Episode 330 - reward: 184\n",
      "Episode 340 - reward: 188\n",
      "Episode 350 - reward: 250\n",
      "Episode 360 - reward: 154\n",
      "Episode 370 - reward: 236\n",
      "Episode 380 - reward: 103\n",
      "Episode 390 - reward: 120\n",
      "Episode 400 - reward: 118\n",
      "Episode 410 - reward: 126\n",
      "Episode 420 - reward: 154\n",
      "Episode 430 - reward: 379\n",
      "Episode 440 - reward: 408\n",
      "Episode 450 - reward: 162\n",
      "Episode 460 - reward: 218\n",
      "Episode 470 - reward: 363\n",
      "Episode 480 - reward: 376\n",
      "Episode 490 - reward: 157\n",
      "Episode 500 - reward: 194\n",
      "Episode 10 - reward: 20\n",
      "Episode 20 - reward: 34\n",
      "Episode 30 - reward: 28\n",
      "Episode 40 - reward: 60\n",
      "Episode 50 - reward: 98\n",
      "Episode 60 - reward: 166\n",
      "Episode 70 - reward: 233\n",
      "Episode 80 - reward: 88\n",
      "Episode 90 - reward: 137\n",
      "Episode 100 - reward: 202\n",
      "Episode 110 - reward: 164\n",
      "Episode 120 - reward: 228\n",
      "Episode 130 - reward: 245\n",
      "Episode 140 - reward: 411\n",
      "Episode 150 - reward: 484\n",
      "Episode 160 - reward: 197\n",
      "Episode 170 - reward: 124\n",
      "Episode 180 - reward: 111\n",
      "Episode 190 - reward: 127\n",
      "Episode 200 - reward: 116\n",
      "Episode 210 - reward: 117\n",
      "Episode 220 - reward: 134\n",
      "Episode 230 - reward: 174\n",
      "Episode 240 - reward: 176\n",
      "Episode 250 - reward: 220\n",
      "Episode 260 - reward: 271\n",
      "Episode 270 - reward: 237\n",
      "Episode 280 - reward: 242\n",
      "Episode 290 - reward: 196\n",
      "Episode 300 - reward: 296\n",
      "Episode 310 - reward: 170\n",
      "Episode 320 - reward: 99\n",
      "Episode 330 - reward: 144\n",
      "Episode 340 - reward: 243\n",
      "Episode 350 - reward: 467\n",
      "Episode 360 - reward: 500\n",
      "Episode 370 - reward: 500\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 500\n",
      "Episode 400 - reward: 500\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 500\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 500\n",
      "Episode 460 - reward: 500\n",
      "Episode 470 - reward: 328\n",
      "Episode 480 - reward: 85\n",
      "Episode 490 - reward: 34\n",
      "Episode 500 - reward: 155\n",
      "Episode 10 - reward: 29\n",
      "Episode 20 - reward: 32\n",
      "Episode 30 - reward: 47\n",
      "Episode 40 - reward: 38\n",
      "Episode 50 - reward: 49\n",
      "Episode 60 - reward: 58\n",
      "Episode 70 - reward: 70\n",
      "Episode 80 - reward: 202\n",
      "Episode 90 - reward: 445\n",
      "Episode 100 - reward: 395\n",
      "Episode 110 - reward: 178\n",
      "Episode 120 - reward: 58\n",
      "Episode 130 - reward: 119\n",
      "Episode 140 - reward: 202\n",
      "Episode 150 - reward: 157\n",
      "Episode 160 - reward: 119\n",
      "Episode 170 - reward: 177\n",
      "Episode 180 - reward: 255\n",
      "Episode 190 - reward: 221\n",
      "Episode 200 - reward: 360\n",
      "Episode 210 - reward: 375\n",
      "Episode 220 - reward: 192\n",
      "Episode 230 - reward: 168\n",
      "Episode 240 - reward: 152\n",
      "Episode 250 - reward: 165\n",
      "Episode 260 - reward: 184\n",
      "Episode 270 - reward: 140\n",
      "Episode 280 - reward: 117\n",
      "Episode 290 - reward: 98\n",
      "Episode 300 - reward: 98\n",
      "Episode 310 - reward: 96\n",
      "Episode 320 - reward: 106\n",
      "Episode 330 - reward: 116\n",
      "Episode 340 - reward: 118\n",
      "Episode 350 - reward: 144\n",
      "Episode 360 - reward: 145\n",
      "Episode 370 - reward: 140\n",
      "Episode 380 - reward: 131\n",
      "Episode 390 - reward: 124\n",
      "Episode 400 - reward: 139\n",
      "Episode 410 - reward: 181\n",
      "Episode 420 - reward: 249\n",
      "Episode 430 - reward: 242\n",
      "Episode 440 - reward: 253\n",
      "Episode 450 - reward: 317\n",
      "Episode 460 - reward: 367\n",
      "Episode 470 - reward: 418\n",
      "Episode 480 - reward: 341\n",
      "Episode 490 - reward: 268\n",
      "Episode 500 - reward: 178\n",
      "Episode 10 - reward: 19\n",
      "Episode 20 - reward: 19\n",
      "Episode 30 - reward: 15\n",
      "Episode 40 - reward: 24\n",
      "Episode 50 - reward: 24\n",
      "Episode 60 - reward: 25\n",
      "Episode 70 - reward: 24\n",
      "Episode 80 - reward: 33\n",
      "Episode 90 - reward: 39\n",
      "Episode 100 - reward: 62\n",
      "Episode 110 - reward: 48\n",
      "Episode 120 - reward: 262\n",
      "Episode 130 - reward: 320\n",
      "Episode 140 - reward: 381\n",
      "Episode 150 - reward: 486\n",
      "Episode 160 - reward: 500\n",
      "Episode 170 - reward: 500\n",
      "Episode 180 - reward: 500\n",
      "Episode 190 - reward: 500\n",
      "Episode 200 - reward: 500\n",
      "Episode 210 - reward: 425\n",
      "Episode 220 - reward: 467\n",
      "Episode 230 - reward: 500\n",
      "Episode 240 - reward: 460\n",
      "Episode 250 - reward: 341\n",
      "Episode 260 - reward: 248\n",
      "Episode 270 - reward: 173\n",
      "Episode 280 - reward: 320\n",
      "Episode 290 - reward: 199\n",
      "Episode 300 - reward: 341\n",
      "Episode 310 - reward: 342\n",
      "Episode 320 - reward: 163\n",
      "Episode 330 - reward: 140\n",
      "Episode 340 - reward: 135\n",
      "Episode 350 - reward: 140\n",
      "Episode 360 - reward: 134\n",
      "Episode 370 - reward: 128\n",
      "Episode 380 - reward: 147\n",
      "Episode 390 - reward: 140\n",
      "Episode 400 - reward: 166\n",
      "Episode 410 - reward: 295\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 500\n",
      "Episode 440 - reward: 306\n",
      "Episode 450 - reward: 360\n",
      "Episode 460 - reward: 500\n",
      "Episode 470 - reward: 490\n",
      "Episode 480 - reward: 442\n",
      "Episode 490 - reward: 353\n",
      "Episode 500 - reward: 470\n",
      "Episode 10 - reward: 26\n",
      "Episode 20 - reward: 23\n",
      "Episode 30 - reward: 30\n",
      "Episode 40 - reward: 31\n",
      "Episode 50 - reward: 25\n",
      "Episode 60 - reward: 45\n",
      "Episode 70 - reward: 49\n",
      "Episode 80 - reward: 45\n",
      "Episode 90 - reward: 63\n",
      "Episode 100 - reward: 73\n",
      "Episode 110 - reward: 90\n",
      "Episode 120 - reward: 101\n",
      "Episode 130 - reward: 339\n",
      "Episode 140 - reward: 267\n",
      "Episode 150 - reward: 253\n",
      "Episode 160 - reward: 382\n",
      "Episode 170 - reward: 496\n",
      "Episode 180 - reward: 385\n",
      "Episode 190 - reward: 155\n",
      "Episode 200 - reward: 153\n",
      "Episode 210 - reward: 432\n",
      "Episode 220 - reward: 275\n",
      "Episode 230 - reward: 302\n",
      "Episode 240 - reward: 16\n",
      "Episode 250 - reward: 17\n",
      "Episode 260 - reward: 50\n",
      "Episode 270 - reward: 61\n",
      "Episode 280 - reward: 101\n",
      "Episode 290 - reward: 147\n",
      "Episode 300 - reward: 205\n",
      "Episode 310 - reward: 242\n",
      "Episode 320 - reward: 297\n",
      "Episode 330 - reward: 369\n",
      "Episode 340 - reward: 500\n",
      "Episode 350 - reward: 500\n",
      "Episode 360 - reward: 500\n",
      "Episode 370 - reward: 500\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 495\n",
      "Episode 400 - reward: 500\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 500\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 500\n",
      "Episode 460 - reward: 404\n",
      "Episode 470 - reward: 500\n",
      "Episode 480 - reward: 500\n",
      "Episode 490 - reward: 500\n",
      "Episode 500 - reward: 500\n",
      "Episode 10 - reward: 20\n",
      "Episode 20 - reward: 15\n",
      "Episode 30 - reward: 19\n",
      "Episode 40 - reward: 16\n",
      "Episode 50 - reward: 25\n",
      "Episode 60 - reward: 25\n",
      "Episode 70 - reward: 22\n",
      "Episode 80 - reward: 29\n",
      "Episode 90 - reward: 34\n",
      "Episode 100 - reward: 40\n",
      "Episode 110 - reward: 68\n",
      "Episode 120 - reward: 56\n",
      "Episode 130 - reward: 71\n",
      "Episode 140 - reward: 66\n",
      "Episode 150 - reward: 64\n",
      "Episode 160 - reward: 64\n",
      "Episode 170 - reward: 64\n",
      "Episode 180 - reward: 53\n",
      "Episode 190 - reward: 56\n",
      "Episode 200 - reward: 68\n",
      "Episode 210 - reward: 72\n",
      "Episode 220 - reward: 98\n",
      "Episode 230 - reward: 74\n",
      "Episode 240 - reward: 74\n",
      "Episode 250 - reward: 105\n",
      "Episode 260 - reward: 162\n",
      "Episode 270 - reward: 360\n",
      "Episode 280 - reward: 371\n",
      "Episode 290 - reward: 336\n",
      "Episode 300 - reward: 495\n",
      "Episode 310 - reward: 500\n",
      "Episode 320 - reward: 256\n",
      "Episode 330 - reward: 323\n",
      "Episode 340 - reward: 500\n",
      "Episode 350 - reward: 500\n",
      "Episode 360 - reward: 500\n",
      "Episode 370 - reward: 500\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 500\n",
      "Episode 400 - reward: 477\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 458\n",
      "Episode 430 - reward: 500\n",
      "Episode 440 - reward: 412\n",
      "Episode 450 - reward: 496\n",
      "Episode 460 - reward: 500\n",
      "Episode 470 - reward: 500\n",
      "Episode 480 - reward: 500\n",
      "Episode 490 - reward: 490\n",
      "Episode 500 - reward: 458\n",
      "Episode 10 - reward: 24\n",
      "Episode 20 - reward: 24\n",
      "Episode 30 - reward: 38\n",
      "Episode 40 - reward: 43\n",
      "Episode 50 - reward: 51\n",
      "Episode 60 - reward: 90\n",
      "Episode 70 - reward: 94\n",
      "Episode 80 - reward: 57\n",
      "Episode 90 - reward: 43\n",
      "Episode 100 - reward: 69\n",
      "Episode 110 - reward: 58\n",
      "Episode 120 - reward: 85\n",
      "Episode 130 - reward: 54\n",
      "Episode 140 - reward: 33\n",
      "Episode 150 - reward: 39\n",
      "Episode 160 - reward: 57\n",
      "Episode 170 - reward: 62\n",
      "Episode 180 - reward: 98\n",
      "Episode 190 - reward: 123\n",
      "Episode 200 - reward: 74\n",
      "Episode 210 - reward: 109\n",
      "Episode 220 - reward: 141\n",
      "Episode 230 - reward: 78\n",
      "Episode 240 - reward: 101\n",
      "Episode 250 - reward: 251\n",
      "Episode 260 - reward: 295\n",
      "Episode 270 - reward: 325\n",
      "Episode 280 - reward: 500\n",
      "Episode 290 - reward: 500\n",
      "Episode 300 - reward: 500\n",
      "Episode 310 - reward: 500\n",
      "Episode 320 - reward: 486\n",
      "Episode 330 - reward: 430\n",
      "Episode 340 - reward: 368\n",
      "Episode 350 - reward: 118\n",
      "Episode 360 - reward: 9\n",
      "Episode 370 - reward: 9\n",
      "Episode 380 - reward: 9\n",
      "Episode 390 - reward: 10\n",
      "Episode 400 - reward: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 410 - reward: 10\n",
      "Episode 420 - reward: 10\n",
      "Episode 430 - reward: 10\n",
      "Episode 440 - reward: 9\n",
      "Episode 450 - reward: 9\n",
      "Episode 460 - reward: 9\n",
      "Episode 470 - reward: 9\n",
      "Episode 480 - reward: 9\n",
      "Episode 490 - reward: 9\n",
      "Episode 500 - reward: 9\n",
      "Episode 10 - reward: 19\n",
      "Episode 20 - reward: 20\n",
      "Episode 30 - reward: 31\n",
      "Episode 40 - reward: 29\n",
      "Episode 50 - reward: 33\n",
      "Episode 60 - reward: 29\n",
      "Episode 70 - reward: 36\n",
      "Episode 80 - reward: 53\n",
      "Episode 90 - reward: 60\n",
      "Episode 100 - reward: 101\n",
      "Episode 110 - reward: 135\n",
      "Episode 120 - reward: 100\n",
      "Episode 130 - reward: 108\n",
      "Episode 140 - reward: 88\n",
      "Episode 150 - reward: 124\n",
      "Episode 160 - reward: 270\n",
      "Episode 170 - reward: 336\n",
      "Episode 180 - reward: 468\n",
      "Episode 190 - reward: 276\n",
      "Episode 200 - reward: 125\n",
      "Episode 210 - reward: 103\n",
      "Episode 220 - reward: 136\n",
      "Episode 230 - reward: 114\n",
      "Episode 240 - reward: 102\n",
      "Episode 250 - reward: 81\n",
      "Episode 260 - reward: 96\n",
      "Episode 270 - reward: 110\n",
      "Episode 280 - reward: 144\n",
      "Episode 290 - reward: 136\n",
      "Episode 300 - reward: 150\n",
      "Episode 310 - reward: 154\n",
      "Episode 320 - reward: 203\n",
      "Episode 330 - reward: 272\n",
      "Episode 340 - reward: 449\n",
      "Episode 350 - reward: 413\n",
      "Episode 360 - reward: 207\n",
      "Episode 370 - reward: 121\n",
      "Episode 380 - reward: 60\n",
      "Episode 390 - reward: 73\n",
      "Episode 400 - reward: 109\n",
      "Episode 410 - reward: 179\n",
      "Episode 420 - reward: 324\n",
      "Episode 430 - reward: 313\n",
      "Episode 440 - reward: 222\n",
      "Episode 450 - reward: 184\n",
      "Episode 460 - reward: 186\n",
      "Episode 470 - reward: 289\n",
      "Episode 480 - reward: 333\n",
      "Episode 490 - reward: 252\n",
      "Episode 500 - reward: 232\n",
      "Episode 10 - reward: 26\n",
      "Episode 20 - reward: 31\n",
      "Episode 30 - reward: 36\n",
      "Episode 40 - reward: 73\n",
      "Episode 50 - reward: 59\n",
      "Episode 60 - reward: 86\n",
      "Episode 70 - reward: 47\n",
      "Episode 80 - reward: 132\n",
      "Episode 90 - reward: 140\n",
      "Episode 100 - reward: 161\n",
      "Episode 110 - reward: 167\n",
      "Episode 120 - reward: 202\n",
      "Episode 130 - reward: 167\n",
      "Episode 140 - reward: 210\n",
      "Episode 150 - reward: 274\n",
      "Episode 160 - reward: 200\n",
      "Episode 170 - reward: 172\n",
      "Episode 180 - reward: 195\n",
      "Episode 190 - reward: 157\n",
      "Episode 200 - reward: 127\n",
      "Episode 210 - reward: 151\n",
      "Episode 220 - reward: 161\n",
      "Episode 230 - reward: 350\n",
      "Episode 240 - reward: 153\n",
      "Episode 250 - reward: 36\n",
      "Episode 260 - reward: 33\n",
      "Episode 270 - reward: 58\n",
      "Episode 280 - reward: 91\n",
      "Episode 290 - reward: 139\n",
      "Episode 300 - reward: 236\n",
      "Episode 310 - reward: 321\n",
      "Episode 320 - reward: 293\n",
      "Episode 330 - reward: 162\n",
      "Episode 340 - reward: 111\n",
      "Episode 350 - reward: 106\n",
      "Episode 360 - reward: 123\n",
      "Episode 370 - reward: 158\n",
      "Episode 380 - reward: 145\n",
      "Episode 390 - reward: 163\n",
      "Episode 400 - reward: 172\n",
      "Episode 410 - reward: 172\n",
      "Episode 420 - reward: 123\n",
      "Episode 430 - reward: 100\n",
      "Episode 440 - reward: 127\n",
      "Episode 450 - reward: 136\n",
      "Episode 460 - reward: 115\n",
      "Episode 470 - reward: 114\n",
      "Episode 480 - reward: 112\n",
      "Episode 490 - reward: 106\n",
      "Episode 500 - reward: 92\n",
      "Episode 10 - reward: 15\n",
      "Episode 20 - reward: 19\n",
      "Episode 30 - reward: 12\n",
      "Episode 40 - reward: 12\n",
      "Episode 50 - reward: 11\n",
      "Episode 60 - reward: 11\n",
      "Episode 70 - reward: 12\n",
      "Episode 80 - reward: 16\n",
      "Episode 90 - reward: 19\n",
      "Episode 100 - reward: 18\n",
      "Episode 110 - reward: 26\n",
      "Episode 120 - reward: 25\n",
      "Episode 130 - reward: 30\n",
      "Episode 140 - reward: 30\n",
      "Episode 150 - reward: 25\n",
      "Episode 160 - reward: 39\n",
      "Episode 170 - reward: 32\n",
      "Episode 180 - reward: 48\n",
      "Episode 190 - reward: 28\n",
      "Episode 200 - reward: 33\n",
      "Episode 210 - reward: 44\n",
      "Episode 220 - reward: 53\n",
      "Episode 230 - reward: 40\n",
      "Episode 240 - reward: 40\n",
      "Episode 250 - reward: 41\n",
      "Episode 260 - reward: 42\n",
      "Episode 270 - reward: 42\n",
      "Episode 280 - reward: 76\n",
      "Episode 290 - reward: 73\n",
      "Episode 300 - reward: 62\n",
      "Episode 310 - reward: 77\n",
      "Episode 320 - reward: 96\n",
      "Episode 330 - reward: 103\n",
      "Episode 340 - reward: 82\n",
      "Episode 350 - reward: 143\n",
      "Episode 360 - reward: 176\n",
      "Episode 370 - reward: 190\n",
      "Episode 380 - reward: 97\n",
      "Episode 390 - reward: 100\n",
      "Episode 400 - reward: 128\n",
      "Episode 410 - reward: 74\n",
      "Episode 420 - reward: 81\n",
      "Episode 430 - reward: 114\n",
      "Episode 440 - reward: 144\n",
      "Episode 450 - reward: 142\n",
      "Episode 460 - reward: 290\n",
      "Episode 470 - reward: 169\n",
      "Episode 480 - reward: 126\n",
      "Episode 490 - reward: 106\n",
      "Episode 500 - reward: 253\n",
      "Episode 10 - reward: 21\n",
      "Episode 20 - reward: 21\n",
      "Episode 30 - reward: 24\n",
      "Episode 40 - reward: 29\n",
      "Episode 50 - reward: 31\n",
      "Episode 60 - reward: 19\n",
      "Episode 70 - reward: 27\n",
      "Episode 80 - reward: 33\n",
      "Episode 90 - reward: 132\n",
      "Episode 100 - reward: 146\n",
      "Episode 110 - reward: 142\n",
      "Episode 120 - reward: 124\n",
      "Episode 130 - reward: 180\n",
      "Episode 140 - reward: 76\n",
      "Episode 150 - reward: 97\n",
      "Episode 160 - reward: 141\n",
      "Episode 170 - reward: 177\n",
      "Episode 180 - reward: 284\n",
      "Episode 190 - reward: 471\n",
      "Episode 200 - reward: 371\n",
      "Episode 210 - reward: 371\n",
      "Episode 220 - reward: 247\n",
      "Episode 230 - reward: 367\n",
      "Episode 240 - reward: 433\n",
      "Episode 250 - reward: 475\n",
      "Episode 260 - reward: 494\n",
      "Episode 270 - reward: 491\n",
      "Episode 280 - reward: 234\n",
      "Episode 290 - reward: 155\n",
      "Episode 300 - reward: 107\n",
      "Episode 310 - reward: 144\n",
      "Episode 320 - reward: 214\n",
      "Episode 330 - reward: 253\n",
      "Episode 340 - reward: 262\n",
      "Episode 350 - reward: 256\n",
      "Episode 360 - reward: 397\n",
      "Episode 370 - reward: 453\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 500\n",
      "Episode 400 - reward: 500\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 500\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 432\n",
      "Episode 460 - reward: 241\n",
      "Episode 470 - reward: 158\n",
      "Episode 480 - reward: 146\n",
      "Episode 490 - reward: 156\n",
      "Episode 500 - reward: 167\n"
     ]
    }
   ],
   "source": [
    "n_runs = 30\n",
    "results_v0 = []\n",
    "for i in range(n_runs):\n",
    "    trained_agentPG, cumulative_rewardPG, lossesPG = train_cartpole(n_episodes = 500, lr=5e-3)\n",
    "    results_v0.append(cumulative_rewardPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Results/REINFORCE_perf', results_v0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "episodes = np.arange(1,len(cumulative_rewardPG)+1)\n",
    "plt.plot(episodes, cumulative_rewardPG)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episodes, lossesPG)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_test_episode(agent):\n",
    "    # Create environment\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    observation_space = env.observation_space.shape[0]\n",
    "    action_space = env.action_space.n\n",
    "    state = env.reset()\n",
    "    while True:\n",
    "        env.render()\n",
    "        action = agent.get_action(state, return_log = False, greedy=False)\n",
    "        new_state, reward, terminal, info = env.step(action) # gym standard step's output\n",
    "        if terminal: \n",
    "            break\n",
    "        else: \n",
    "            state = new_state\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_test_episode(trained_agentPG) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advantage Actor-Critic - Step update version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'agents' from '/home/nicola/Nicola_unipd/MasterThesis/Policy-based-RL/agents.py'>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cartpole_A2C_v0(n_epochs = 100, lr_actor = 0.01, lr_critic = 0.01, gamma = 0.99, greedy=False):\n",
    "    # Create environment\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    observation_space = env.observation_space.shape[0]\n",
    "    action_space = env.action_space.n\n",
    "    # Init agent\n",
    "    agent = agents.A2C_v0(observation_space, action_space, lr_actor, lr_critic, gamma)\n",
    "    performance = []\n",
    "    for e in range(n_epochs):\n",
    "        # Reset environment (start of an episode)\n",
    "        state = env.reset()\n",
    "        rewards = []\n",
    "\n",
    "        steps = 0\n",
    "        while True:\n",
    "            action, log_prob = agent.get_action(state, return_log = True, greedy=greedy)\n",
    "            new_state, reward, terminal, info = env.step(action) # gym standard step's output\n",
    "\n",
    "            #if terminal and 'TimeLimit.truncated' not in info:\n",
    "            #    reward = -1\n",
    "\n",
    "            rewards.append(reward)\n",
    "            agent.update(reward, log_prob, state, new_state, terminal)\n",
    "            \n",
    "            if terminal:\n",
    "                break\n",
    "\n",
    "            state = new_state\n",
    "            \n",
    "            \n",
    "        rewards = np.array(rewards)\n",
    "        performance.append(np.sum(rewards))\n",
    "        if (e+1)%10 == 0:\n",
    "            print(\"Episode %d - reward: %.0f\"%(e+1, np.mean(performance[-10:])))\n",
    "\n",
    "    return agent, np.array(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.9597, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9540, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9546, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9569, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0408, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9540, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9569, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9518, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0464, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9376, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0509, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2408, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0757, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0498, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9510, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0356, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9638, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0238, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0102, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9887, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9915, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9788, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0162, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7202, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0211, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9687, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9393, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9256, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0658, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0605, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9229, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9202, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9104, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0766, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9021, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9195, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0555, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9185, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0464, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7716, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8959, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0868, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0490, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0188, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0094, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9787, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9696, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9388, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9032, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8974, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9024, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0872, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8937, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8934, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0911, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8824, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0934, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0956, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8700, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8861, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9234, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6353, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8709, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1146, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8726, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1094, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0614, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0314, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0151, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9650, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9613, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9524, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9154, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8899, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0994, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8888, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8859, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1058, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8784, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1080, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8767, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1047, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0803, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0374, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9391, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9153, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0545, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0202, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9548, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9328, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9180, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8965, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9042, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9072, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9239, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0610, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0928, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8742, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0913, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0980, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8667, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0860, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0815, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0670, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9019, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0582, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0471, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9262, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9255, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9244, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0332, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9250, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0303, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0359, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0356, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0301, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9458, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0244, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9989, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9826, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0148, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9836, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9645, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0014, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9634, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9644, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4041, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9484, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9268, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9295, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9268, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9272, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0266, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0452, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8966, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9016, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9249, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0177, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1825, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8624, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8471, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8488, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1180, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1322, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1229, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8384, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8242, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1297, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8201, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1278, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1173, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0924, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0534, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0363, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0248, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0148, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0018, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0034, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9953, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9750, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9338, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0382, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9389, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9007, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0712, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9031, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8846, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0850, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8823, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8742, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0878, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8671, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8730, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0748, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0909, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0839, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0699, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8940, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0639, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9000, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8841, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8725, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0692, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0655, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0587, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9013, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0534, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0221, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0007, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9922, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0095, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0010, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9751, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9689, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9671, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0402, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9503, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9560, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9552, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3022, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9148, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8550, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1485, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8058, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7736, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2237, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7379, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6991, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2783, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6672, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6537, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2716, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8881, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0576, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9138, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0484, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0271, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9341, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9323, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8722, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0979, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0327, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0180, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0029, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9473, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9468, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9449, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0142, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.9458, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9387, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0279, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9380, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0245, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0050, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9849, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.6034, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9964, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9720, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9850, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9533, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9375, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9289, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9105, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0361, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8870, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0456, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0485, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0587, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0534, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8668, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8591, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0448, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1724, grad_fn=<SubBackward0>)\n",
      "Episode 10 - reward: 25\n",
      "A  tensor(0.9060, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8835, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8645, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8603, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0729, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0839, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0787, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0705, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8617, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8463, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0667, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0611, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0429, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0045, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9486, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9310, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9124, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1007, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0905, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0200, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9563, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0028, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9678, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9875, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9795, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9705, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9218, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8947, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8764, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8658, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0181, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2017, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9091, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0629, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9715, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9030, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8722, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8717, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8629, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1413, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8431, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8342, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1605, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1664, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8858, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8020, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7494, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2432, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2024, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7515, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7179, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2447, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7040, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7008, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7090, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6959, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6790, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9450, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8923, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0318, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0216, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9245, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7780, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7449, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2429, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7521, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7174, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2648, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7210, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6818, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2887, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2432, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2000, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1561, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0892, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9741, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9743, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8540, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0777, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8575, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8432, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8203, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8077, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1245, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1048, grad_fn=<SubBackward0>)\n",
      "A  tensor(-1.3139, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8993, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0565, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9264, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9065, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8955, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0389, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8914, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0375, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8872, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0345, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0310, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8875, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0266, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8844, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1686, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8618, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1019, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8559, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1068, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8505, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1107, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8450, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8210, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8097, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8206, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1256, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8077, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1220, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2727, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8532, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8185, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1540, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1237, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9785, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9922, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9723, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8955, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0678, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8880, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8718, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0784, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8601, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8568, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0702, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8404, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0664, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8126, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0669, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0716, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0247, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9195, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0451, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9282, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0351, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8483, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1142, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9679, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9921, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8386, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8116, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7959, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1535, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7832, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7735, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1514, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7706, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7715, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4161, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8552, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1074, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8834, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0718, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8748, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7936, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1696, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7888, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7566, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1958, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1667, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1168, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9613, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9931, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8325, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1131, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8304, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1116, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8298, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7892, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1422, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1119, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8205, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7841, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7683, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1403, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7570, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1353, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7470, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3878, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8442, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7864, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1699, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1269, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9494, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0044, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8179, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7602, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7207, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2130, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7043, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2110, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6923, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2039, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.6836, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1930, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6769, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1789, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2430, grad_fn=<SubBackward0>)\n",
      "Episode 20 - reward: 20\n",
      "A  tensor(0.7826, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7191, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6918, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2216, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6777, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2156, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6675, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2050, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1976, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1796, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1458, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0549, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8599, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0668, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8432, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0805, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8253, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7566, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1184, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4566, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8466, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8015, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7790, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7656, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7649, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7557, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7340, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7599, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8533, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0682, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9444, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8469, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8297, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1299, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8076, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1361, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1359, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7923, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7816, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7707, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7545, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1288, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7216, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1127, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1410, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7529, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1801, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7294, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1925, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7146, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6575, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6441, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6477, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6219, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7162, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0969, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5579, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7174, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6413, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6141, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6228, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2541, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2725, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5957, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2338, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2291, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6246, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6632, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1434, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1458, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6791, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1138, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1009, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0830, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7543, grad_fn=<SubBackward0>)\n",
      "A  tensor(-1.2793, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9729, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8606, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0928, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9724, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9785, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8590, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0953, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9938, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8163, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1155, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0004, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8721, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8381, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1106, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0947, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8511, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0914, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8512, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0881, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8502, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0853, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0777, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8635, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0756, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8638, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8472, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8302, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0844, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0812, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8282, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8376, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0599, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4504, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8651, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8371, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0872, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8285, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0829, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8230, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0763, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8192, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0673, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8160, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8236, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8357, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9906, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0013, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0236, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0421, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0447, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8276, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0318, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0297, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9830, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9664, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9938, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9222, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9988, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9050, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8660, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8607, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3410, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9283, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0335, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9320, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0271, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9346, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0241, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8773, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8912, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8733, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9961, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0165, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0437, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0302, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8935, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0342, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8861, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8576, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0267, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0327, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9778, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9275, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8805, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1220, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0670, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9064, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0698, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9041, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0720, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9706, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9028, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8847, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0025, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8668, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0025, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8503, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9983, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8343, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9914, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0052, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8231, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9911, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9994, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8237, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2324, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9744, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9609, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9851, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8800, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0940, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9651, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8508, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0551, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0058, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8973, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0800, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9395, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0070, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8933, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8270, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1440, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7829, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7722, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1387, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7683, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7594, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1284, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7427, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1226, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1174, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7383, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5183, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8647, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(1.0931, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8429, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1124, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9228, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8970, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8782, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9744, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8467, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9817, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8261, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9710, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8236, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8010, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7661, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7130, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2421, grad_fn=<SubBackward0>)\n",
      "Episode 30 - reward: 23\n",
      "A  tensor(0.8546, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0847, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8339, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0982, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8163, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1344, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7974, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7066, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2098, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6980, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2077, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1898, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9798, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9703, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9763, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9692, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9768, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9684, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9769, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9678, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7705, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1482, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0056, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8940, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0637, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9617, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9804, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9600, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9810, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8722, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0729, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9893, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8047, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7702, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7267, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6986, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6584, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6498, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1301, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1434, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1556, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5362, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8644, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7779, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0957, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0924, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8986, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0447, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8214, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7890, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7509, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0602, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7084, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0478, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7115, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6803, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6418, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5914, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5661, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7994, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7521, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0817, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0855, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9533, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9546, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9549, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9479, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9518, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9451, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9496, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9408, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8336, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8067, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9796, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9934, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9890, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8442, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9735, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8394, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9606, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8185, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7758, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9253, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9327, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7877, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9162, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7930, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.7001, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5431, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4574, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4183, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3701, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4146, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3454, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3381, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3150, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5330, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2783, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2410, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6443, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6085, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1934, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1842, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1573, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7615, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7158, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7002, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0940, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.8117, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7433, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6746, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6380, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1406, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1698, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1793, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6668, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6380, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6651, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6365, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5931, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9778, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9846, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9121, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7875, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1186, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8850, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7613, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1492, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1268, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9227, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0346, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9185, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8671, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8213, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0001, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7755, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7189, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9574, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9677, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9961, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7083, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9627, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7043, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7300, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7202, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0582, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7937, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7444, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6793, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1306, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6598, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6182, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1091, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1239, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6211, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5818, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0770, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0870, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5123, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8955, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8518, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0685, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0749, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8740, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7188, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1592, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0797, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8386, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7202, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6173, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1793, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6007, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5464, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1497, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5280, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1336, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1505, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1667, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1622, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1709, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1308, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1210, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0747, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0670, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0107, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0484, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9522, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1557, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8942, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1697, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1304, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0637, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9080, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0816, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9376, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9967, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.9347, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0009, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9058, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0849, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9443, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8647, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8331, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7850, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7459, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9617, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9773, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0052, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0250, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0415, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8597, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8065, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7688, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9643, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7524, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9515, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9776, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4527, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8431, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0757, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9986, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9129, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0056, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8992, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0223, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8763, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0425, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8460, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7566, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0773, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7459, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0560, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7285, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0393, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0623, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7411, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0444, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0120, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9739, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9333, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8463, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7863, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9758, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7773, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9534, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7663, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7226, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8898, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7055, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7186, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3980, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9861, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9759, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7776, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7198, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0551, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6941, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0584, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0930, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7322, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6679, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0349, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6525, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0153, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0631, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6848, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6405, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5705, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4927, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2656, grad_fn=<SubBackward0>)\n",
      "Episode 40 - reward: 27\n",
      "A  tensor(0.6747, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5854, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4717, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1116, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1691, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4469, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1670, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2167, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4719, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4035, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1093, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4297, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0376, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1441, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9922, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9565, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9151, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7904, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7107, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8901, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8799, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6055, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5256, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5505, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7516, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0631, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0407, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9425, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8203, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0079, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0030, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9680, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9821, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8792, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3890, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.6226, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4284, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0271, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9259, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5446, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3961, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0779, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8779, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8177, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0045, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0227, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8527, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9953, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0061, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9346, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8346, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5403, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3916, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3026, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1928, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0682, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8803, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0673, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8851, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8196, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0134, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0339, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8456, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8113, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0001, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0100, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8239, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0041, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0208, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8819, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0124, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8734, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0063, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0197, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9333, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8529, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7974, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9309, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7773, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9145, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7808, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4449, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5597, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2637, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1644, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9539, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8781, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9465, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9679, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8960, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8314, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9151, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9606, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9932, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9298, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9863, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9316, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9777, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9677, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0420, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9522, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8989, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7406, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2659, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2315, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2139, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0134, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9481, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9194, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9249, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8610, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7788, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8609, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8994, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9406, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9878, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0012, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9864, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1057, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0219, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9677, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9679, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8939, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7612, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2076, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4676, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3359, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0647, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0744, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0820, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0759, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1005, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4640, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4119, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2941, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8326, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7871, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1780, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1478, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7874, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(1.1473, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0122, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9004, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9874, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9246, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9599, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9044, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8474, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7179, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6323, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5489, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4606, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3741, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2253, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8302, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7639, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6248, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0440, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0768, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6448, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5529, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4674, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3739, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3245, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4063, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3742, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9716, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8724, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8404, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6741, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9474, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9600, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9883, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5697, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9626, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5375, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9258, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9621, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5520, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4886, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3841, grad_fn=<SubBackward0>)\n",
      "A  tensor(-1.3111, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8463, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0962, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7810, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1529, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9169, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8414, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7206, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6265, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5479, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5181, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8749, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5592, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6262, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6146, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5529, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2791, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4467, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2395, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4319, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.5095, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4117, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1169, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9646, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8854, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7757, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6390, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9652, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0032, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0374, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0483, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7833, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0323, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0602, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8457, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0315, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0127, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9573, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8750, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8014, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9515, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7886, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7485, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8818, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9182, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9462, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9704, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.8545, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9154, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9711, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9525, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0113, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9181, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9604, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9562, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8808, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1420, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7866, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1644, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6304, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2829, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1001, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1659, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1915, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2016, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2767, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4128, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4090, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0766, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4939, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0149, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6115, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7404, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8115, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8938, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.6727, grad_fn=<SubBackward0>)\n",
      "Episode 50 - reward: 26\n",
      "A  tensor(1.1245, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8277, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6466, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5714, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4779, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3580, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8176, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8590, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9164, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9760, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0222, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6844, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6714, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8952, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7208, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7665, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8623, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8890, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7594, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6755, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9401, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6605, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8952, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9591, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0127, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8144, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9876, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9732, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0250, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9603, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2912, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2292, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8180, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8280, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2694, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7424, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9513, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9538, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9636, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8191, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7391, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6522, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8183, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8574, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6989, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6191, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5893, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.8390, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9265, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7004, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1349, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6357, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4729, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1250, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1547, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4964, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3691, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2696, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0151, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0705, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1247, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4974, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4998, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7288, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8510, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0295, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6037, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5219, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1756, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5582, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5187, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4399, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3779, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8659, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4680, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8291, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5498, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7108, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4540, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1782, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0881, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0507, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9792, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0645, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.8706, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0747, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8431, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0813, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0732, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9853, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8897, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8242, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7709, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8540, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7001, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7999, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6580, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8170, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6450, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5885, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7107, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7515, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5485, grad_fn=<SubBackward0>)\n",
      "A  tensor(-1.1938, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9969, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9840, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1115, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9048, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1566, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0240, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9022, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0216, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8843, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7730, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8697, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7588, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8577, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7885, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8452, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7969, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7179, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7069, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7287, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7745, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7526, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3551, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6641, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5091, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3689, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8729, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3186, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8207, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3361, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3631, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6172, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8890, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7187, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1341, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9643, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0116, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6808, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5361, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3815, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0241, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0985, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1453, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5890, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4605, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0255, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5080, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9540, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5552, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9021, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5914, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8578, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5776, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8073, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0493, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8593, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7758, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1445, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7375, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5735, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9190, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0013, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0960, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1205, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1176, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0510, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8518, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6248, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2276, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0230, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1697, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3539, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5676, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7148, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8594, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0582, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8084, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0240, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8073, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7312, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9063, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6703, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5417, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7111, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4658, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3194, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5501, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2325, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4796, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5405, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5068, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0909, grad_fn=<SubBackward0>)\n",
      "Episode 60 - reward: 20\n",
      "A  tensor(0.6770, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0218, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6527, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0141, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0504, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0420, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9590, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2305, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7613, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0718, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6647, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8764, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8259, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7288, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8097, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8947, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9362, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9594, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1802, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0358, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8701, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9030, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8644, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3548, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7397, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7244, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6767, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5301, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1595, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4161, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3007, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4404, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0090, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5081, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3207, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2516, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5931, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4599, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3182, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2894, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5829, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4177, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2342, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1019, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0337, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1183, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1992, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2553, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4545, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3424, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2387, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1185, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6643, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7337, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8055, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8679, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9347, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6477, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8420, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6716, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7571, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6702, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5292, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5336, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1632, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8132, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9182, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8106, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7493, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6150, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4030, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3952, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4550, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5544, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4609, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4943, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3967, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4284, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3128, grad_fn=<SubBackward0>)\n",
      "A  tensor(-2.0689, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9276, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8475, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7134, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6310, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2573, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2349, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6565, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1928, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6866, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1807, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7044, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3555, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0630, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1429, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2774, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.8531, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3643, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8977, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7806, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8175, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8464, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.9857, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5407, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2675, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4785, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2175, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0124, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1382, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8523, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1013, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6991, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8283, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8683, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3160, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0002, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8871, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8523, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7741, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7114, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7726, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8549, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9183, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9895, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9411, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9638, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9447, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9414, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9885, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0682, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9660, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9589, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9870, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3678, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2822, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1260, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8813, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0786, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9205, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0319, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9096, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9534, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8928, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9614, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9703, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8538, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7542, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1989, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6617, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1027, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0692, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0708, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0168, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0235, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9286, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1226, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7724, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0888, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6908, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9460, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9887, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7107, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6510, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5091, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3952, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3148, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7163, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2587, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9753, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9713, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7845, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7878, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4123, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3178, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4920, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0702, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3969, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0428, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0972, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4833, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0675, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1133, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6019, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4861, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9652, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0275, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0891, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1406, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1563, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0056, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8849, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7746, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9189, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9889, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8793, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9413, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8809, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8999, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9776, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9746, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8690, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7468, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6202, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6284, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0420, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8979, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8130, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7491, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6271, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4997, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5695, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6593, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7434, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4839, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3395, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5887, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5452, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3750, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5717, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1020, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5309, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3654, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1713, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7550, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8581, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2423, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1502, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0804, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6116, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6765, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8834, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9646, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9609, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8684, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3394, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1958, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9631, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8323, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9460, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9633, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9200, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9628, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9187, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9614, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9184, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8118, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9522, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7975, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7139, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6295, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5379, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3048, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1154, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0381, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0661, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0978, grad_fn=<SubBackward0>)\n",
      "Episode 70 - reward: 26\n",
      "A  tensor(0.7259, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1495, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6677, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5237, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4194, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1626, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3004, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0539, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1417, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2206, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2580, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2148, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9322, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1644, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9783, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1115, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8636, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7634, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1076, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1152, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9621, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8992, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6993, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8642, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6658, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5079, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6833, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7378, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8590, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9231, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9706, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2744, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0354, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8873, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9331, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2800, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9268, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2791, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9340, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8210, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7421, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6749, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5956, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9731, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7504, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7802, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1497, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0027, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1245, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1074, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7938, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7627, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5719, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6527, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7426, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8362, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9431, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7401, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9240, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.9645, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9797, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7253, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8862, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9645, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9183, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9558, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9041, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6936, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5156, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3242, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1043, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2956, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1707, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3229, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1898, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2167, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8166, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6949, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1223, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6015, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8897, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3936, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7760, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8533, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9601, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9831, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0662, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2020, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0242, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9151, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9171, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7258, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7027, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3859, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2102, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0494, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6460, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7229, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0434, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1172, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1993, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1606, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4320, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3012, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1912, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3293, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3200, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1571, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2067, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3223, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2821, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0942, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1388, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0757, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0611, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0811, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9647, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0587, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1549, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4675, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0372, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1367, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2268, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3069, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1224, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1938, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1763, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0943, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2059, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0534, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8338, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0357, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7891, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0022, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7512, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9549, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7608, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5580, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4082, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3899, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8401, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6431, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7813, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5866, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3585, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7073, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2337, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0183, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5343, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0482, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4440, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9377, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0373, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6374, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0441, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6882, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9829, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0433, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9606, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7368, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5743, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7674, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9006, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7389, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8685, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0008, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0222, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1128, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4099, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2681, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8480, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2908, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0001, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7889, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9457, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7788, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9327, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9082, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8476, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7589, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7411, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0952, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2361, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0010, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1810, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2561, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3812, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1532, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0857, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8838, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7630, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6497, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5858, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4863, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6229, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6594, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4810, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2741, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2555, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3838, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5223, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6814, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6310, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6214, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1620, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5649, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4383, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1025, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1891, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3903, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1676, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2278, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5884, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1800, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6022, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3660, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0312, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3580, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1909, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7715, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8851, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3259, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7966, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3186, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2611, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1214, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1399, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3179, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9588, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9348, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9141, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9386, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9020, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9251, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6667, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5116, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3944, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8533, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2082, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6125, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7586, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8978, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0362, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6933, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9746, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6883, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4728, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2598, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4878, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6312, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7437, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5996, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6440, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5613, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5523, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.5556, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5197, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0013, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8818, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7371, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4147, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1371, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9539, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8163, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9218, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8204, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8752, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8328, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7468, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0905, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8742, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7566, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7505, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7265, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6567, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7096, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4990, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6505, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4521, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2473, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0385, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2203, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4339, grad_fn=<SubBackward0>)\n",
      "A  tensor(-1.5043, grad_fn=<SubBackward0>)\n",
      "Episode 80 - reward: 28\n",
      "A  tensor(0.4382, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1189, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1921, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1124, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4141, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1903, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3899, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.5810, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2718, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0827, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0529, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0881, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1638, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4405, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.8064, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3546, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7912, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1228, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8448, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0428, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0972, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1654, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2602, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9331, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1875, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9451, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9136, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9474, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9241, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9415, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9592, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9353, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9129, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.6427, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1313, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2688, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7589, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0635, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7770, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0220, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8662, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9062, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9215, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9078, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8923, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8747, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3413, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0185, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7292, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8970, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7391, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7104, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6526, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4586, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1346, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7408, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0684, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7822, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8005, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2471, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9804, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8326, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9371, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7636, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7461, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7458, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7144, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7328, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9106, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9421, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9542, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9212, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9426, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9956, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6075, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3287, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6273, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2587, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0951, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4558, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0025, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7626, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8444, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9335, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9426, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9312, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9178, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7506, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.5596, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6204, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4178, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9498, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6734, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7999, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4038, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2927, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2619, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7084, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8174, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9052, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4269, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4155, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1386, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3362, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1750, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2889, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4216, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4353, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3563, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3243, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2310, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0728, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1982, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9921, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0303, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9687, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9663, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9647, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9281, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9837, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7917, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5529, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2725, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1814, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9035, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6820, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9582, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9835, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7988, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9919, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9083, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9468, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9542, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3693, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5512, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3670, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0834, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3480, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0587, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1699, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5076, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1456, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5482, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5641, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9937, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6775, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7823, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7588, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9706, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9845, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8984, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9775, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2838, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1677, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8955, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6023, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1382, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6028, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1231, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1498, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2003, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0694, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9814, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5057, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6971, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7852, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8297, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4265, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6082, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7507, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7837, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8441, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1751, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9673, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6911, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4739, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2101, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0852, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4581, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2404, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.8563, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2880, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3800, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6033, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8914, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7052, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9134, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9013, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2286, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9117, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8832, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0689, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9397, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8390, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9370, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8714, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0451, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7695, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6118, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8374, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8908, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7073, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5505, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4044, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6225, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4500, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6633, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6055, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6135, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2959, grad_fn=<SubBackward0>)\n",
      "Episode 90 - reward: 21\n",
      "A  tensor(1.0253, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9833, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9249, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1942, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5411, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8763, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9771, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0550, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5503, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3981, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2395, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7375, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8277, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9167, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9117, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6892, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8414, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7068, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8034, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8745, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9443, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9848, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2086, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9581, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2378, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9323, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2577, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9182, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9689, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0580, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.6570, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4986, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2744, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0464, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8904, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7762, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7787, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7893, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8920, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8975, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8864, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9522, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0340, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8132, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6970, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7974, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6761, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5562, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6718, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6363, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6829, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8217, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7301, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8874, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7962, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1814, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0671, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9099, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9252, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8336, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5576, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1754, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1601, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9557, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9313, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9296, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8339, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8544, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9061, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9170, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8930, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1212, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9849, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8817, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9673, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7673, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5130, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3647, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7081, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7951, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3936, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2358, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0632, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1284, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2988, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2302, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5981, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4161, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8768, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3899, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1424, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0680, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6675, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3153, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5919, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8112, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6843, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1606, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7754, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0058, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7067, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4357, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2296, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0472, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4812, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6096, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7515, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8800, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5410, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8540, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6916, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8175, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6666, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5455, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6923, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6617, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0340, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9589, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7313, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0561, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5059, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3419, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7591, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2268, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0465, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3222, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0537, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0302, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5647, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5241, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3439, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9272, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9981, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9575, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6011, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0947, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0500, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1529, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1913, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1461, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6982, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0989, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7323, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4255, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2322, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0631, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7757, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8528, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1884, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0110, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1529, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1982, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3637, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8849, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9373, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8885, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6910, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9812, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9335, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7334, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5137, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3062, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6177, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2509, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0267, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2782, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5352, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6892, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6255, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6491, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6326, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5644, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4695, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8047, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9314, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7879, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5615, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8033, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5418, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2942, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0350, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.3361, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0351, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1900, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0521, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4391, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3102, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0099, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8306, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4834, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1024, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3905, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0548, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0035, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0238, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2475, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4773, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5247, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4833, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4514, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1035, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9246, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9345, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2059, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8864, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0094, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9712, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7581, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0180, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6682, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0601, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9575, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8668, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9561, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8633, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9555, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9678, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9086, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8848, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8952, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9680, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8540, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9587, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8544, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7427, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8680, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9501, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9463, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0575, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8741, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9232, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9208, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0868, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9031, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1123, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8186, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4896, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9940, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3297, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8069, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8243, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9597, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6801, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4022, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7301, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3720, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6688, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3371, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0493, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0851, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0667, grad_fn=<SubBackward0>)\n",
      "A  tensor(-1.0329, grad_fn=<SubBackward0>)\n",
      "Episode 100 - reward: 25\n",
      "A  tensor(0.9180, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9967, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9044, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9713, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9974, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2473, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1031, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2866, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9159, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2377, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0511, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3520, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5956, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1793, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5614, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4981, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8694, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1226, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9549, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0612, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9678, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0250, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9921, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6184, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0876, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4552, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0341, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3915, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1465, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2992, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4511, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5716, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3618, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9351, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8555, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4338, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7723, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9157, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0559, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1392, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8042, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5819, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3914, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7965, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3632, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1414, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5283, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0861, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1292, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1519, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2487, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1519, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5281, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2911, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0270, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3042, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4974, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0321, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2534, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6773, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5469, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4744, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1026, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4639, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0793, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4611, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0487, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4542, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2012, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7733, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9616, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4145, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9055, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0628, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6729, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4086, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7816, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9294, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6602, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8589, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0450, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2294, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1373, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9011, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9196, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8874, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8685, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0629, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1046, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0133, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1762, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3673, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1246, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3706, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0864, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3641, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0699, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9101, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0569, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2483, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3503, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0624, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1339, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9986, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9329, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8147, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9314, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7838, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9377, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9603, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8519, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9601, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9779, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9984, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0340, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8178, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6036, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5120, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2491, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1879, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0956, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1140, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4781, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6133, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4106, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9725, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1362, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2251, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2517, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9017, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6023, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2979, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1667, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2616, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1323, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2285, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0875, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1581, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5305, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(1.0800, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5701, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0023, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5935, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9349, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6074, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3402, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0473, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5120, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5735, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6896, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6755, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6358, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7591, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7914, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7519, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4572, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7817, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7185, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9056, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5595, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3284, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5138, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5311, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4799, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2175, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2656, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3659, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3809, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2818, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3237, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1808, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4283, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6264, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7897, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2733, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8535, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9588, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7635, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9541, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8550, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8579, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7879, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8476, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4392, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7963, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3841, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5870, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5633, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4732, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2285, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2875, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1726, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1066, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3972, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2348, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0482, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8846, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9733, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6763, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2475, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6087, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0180, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1639, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1703, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0442, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1719, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2683, grad_fn=<SubBackward0>)\n",
      "A  tensor(-1.6152, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9469, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0695, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0464, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3235, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0201, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7565, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8924, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9652, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8044, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6649, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4262, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2539, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0795, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0237, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2039, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0281, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2940, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3147, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4520, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7555, grad_fn=<SubBackward0>)\n",
      "Episode 110 - reward: 23\n",
      "A  tensor(0.8237, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1762, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8581, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5981, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5411, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5508, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3130, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0737, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0620, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0908, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1317, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3405, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2887, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0673, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9573, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9493, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5547, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1838, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9446, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9581, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6043, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1220, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9295, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9694, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9130, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6611, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3546, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8040, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2587, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0038, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2489, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3353, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0901, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1958, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5423, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5332, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3172, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9869, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0504, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4248, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0482, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1260, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7295, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3869, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1467, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7646, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9133, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3654, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1091, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0648, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3937, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5611, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4398, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7189, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7209, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6403, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9861, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5661, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1320, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1445, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7528, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8180, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0188, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2498, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4659, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2127, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4883, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6335, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0989, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7906, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0125, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8158, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5296, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5579, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6283, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7629, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5956, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7199, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9929, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7095, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5210, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6780, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8968, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6181, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2802, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0914, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0341, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0725, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2436, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5019, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6500, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9241, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0417, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9165, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5973, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9393, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0697, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9908, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2307, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7417, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3873, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7537, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1592, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1096, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4068, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1657, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3692, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0599, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0995, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0607, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0308, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9164, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9678, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9163, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6153, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3045, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1256, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2108, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3414, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3220, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2043, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1410, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(-0.3506, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0753, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3414, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7180, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5973, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3667, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7008, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8519, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9368, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0323, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7181, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4646, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2227, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0276, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0130, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0060, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0017, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1270, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1374, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.7375, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5890, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4054, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6626, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3289, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4932, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6642, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8038, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7984, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7585, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7812, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7139, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9110, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0796, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2033, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3945, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.9844, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0987, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4915, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0762, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1921, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6304, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4764, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.6054, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4190, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1758, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2252, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8690, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0004, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6801, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4047, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6031, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7505, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8686, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8460, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5513, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2740, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0112, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2263, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1212, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2422, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3738, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2676, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4952, grad_fn=<SubBackward0>)\n",
      "Episode 120 - reward: 18\n",
      "A  tensor(0.6026, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8744, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9951, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8469, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5631, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8420, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9823, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7959, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5154, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7802, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4826, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1847, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0853, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2821, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4411, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5451, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4155, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5056, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3831, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4090, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3511, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4390, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2987, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6045, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8448, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6046, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2544, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5964, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7463, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8918, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8508, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8477, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0549, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1924, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3880, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.7213, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4259, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8818, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1187, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8367, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0615, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0302, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7467, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4914, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1835, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8145, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0960, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0525, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1717, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3452, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0046, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1612, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3985, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2347, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5714, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3818, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9675, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9026, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9480, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9933, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2466, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9113, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8752, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9188, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5897, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3673, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1354, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2663, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4167, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2377, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3604, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5564, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3868, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1999, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0422, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0498, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.7561, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1708, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0710, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8284, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5446, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0767, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9863, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0466, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2196, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4041, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3251, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5729, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1015, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3486, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4903, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1927, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5532, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0387, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9535, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7698, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1647, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6374, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2942, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0587, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3816, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.6219, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1331, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0718, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2610, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2614, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4596, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9744, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4241, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9476, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4018, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1666, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0834, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3430, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4937, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4852, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1912, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6071, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5298, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3717, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1689, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0934, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4841, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1073, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2611, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0470, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1559, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4187, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5304, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0786, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0887, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1014, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8969, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5424, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0877, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6571, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5992, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4577, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3195, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3792, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4775, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4417, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3046, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9329, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7522, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6319, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1341, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9026, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3470, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5924, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5433, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(-0.4613, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1775, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2155, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8235, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0689, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8063, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7692, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3543, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6550, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6406, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1955, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1539, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3173, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9984, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0375, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0229, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9931, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9723, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9387, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2378, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7087, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5417, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1098, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1167, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3821, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7942, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8365, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9366, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9829, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1468, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4230, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1764, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8104, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7940, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0425, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6939, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4101, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0495, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3129, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2144, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1936, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1588, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0800, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.6573, grad_fn=<SubBackward0>)\n",
      "Episode 130 - reward: 20\n",
      "A  tensor(0.9162, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9000, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9173, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8898, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9275, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8771, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7165, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6379, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3407, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0954, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7483, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2739, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6607, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6832, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8118, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1093, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0709, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3023, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7149, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5605, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7230, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9788, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8770, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9427, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8932, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9276, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9037, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7539, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4503, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1139, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7030, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7770, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0754, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6405, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7876, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8884, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0582, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8761, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6250, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4253, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5456, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6806, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8382, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8614, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6352, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5480, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7096, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7876, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6436, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7417, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5748, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7278, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8904, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6860, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8462, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6525, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7986, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6214, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7496, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8809, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5697, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7788, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5662, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8799, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7448, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6353, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6888, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6125, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6498, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8183, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8512, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7865, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8343, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7562, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8096, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5234, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1949, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2540, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4327, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6474, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6833, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5948, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6298, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3761, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0959, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0403, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1796, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3646, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6522, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4812, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3151, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1607, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1332, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2273, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0885, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0176, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2147, grad_fn=<SubBackward0>)\n",
      "A  tensor(-1.7069, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4469, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1309, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7680, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0552, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7959, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0619, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8536, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0539, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2343, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9820, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5673, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9593, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0108, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7743, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8268, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8776, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.7156, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9175, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5619, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7646, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8158, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7179, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7744, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6987, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7494, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9259, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0174, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8972, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9691, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4562, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9436, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6766, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.5722, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1677, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5278, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8287, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.6652, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7776, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8877, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3263, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6184, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8498, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8882, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8600, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0605, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4640, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5043, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4181, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1600, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8598, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8898, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8989, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5241, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8387, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3741, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0214, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3701, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5768, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7826, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4106, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2784, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1131, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1042, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4518, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7331, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8298, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4784, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7593, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5026, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2205, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2672, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4659, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.2926, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0286, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1955, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1995, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2939, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4019, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4637, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5052, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3130, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7036, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2798, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7095, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2497, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7078, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3602, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0693, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2163, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5165, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3652, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6668, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7937, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9121, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0019, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1198, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7889, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0580, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7804, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6042, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6102, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7348, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7448, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7475, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0293, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0678, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8779, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0206, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9218, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0339, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8992, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9473, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8395, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7117, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1231, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6986, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5228, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1993, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1851, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9875, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8638, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9537, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8771, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7133, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3649, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6364, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3915, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5243, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7004, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5657, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6527, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5262, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5959, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7185, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9084, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0895, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3317, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0728, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8292, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0333, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3074, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0472, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7533, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5879, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6745, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5685, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5913, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5344, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7220, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7437, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6815, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7210, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6896, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7321, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6913, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8237, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9503, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9809, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9153, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0473, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0947, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0127, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0791, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9730, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1098, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2208, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0565, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8828, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0186, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8431, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9799, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1117, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2810, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9639, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9203, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0060, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0596, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9829, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8210, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6304, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5334, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7226, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9305, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6444, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5864, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7638, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6452, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2475, grad_fn=<SubBackward0>)\n",
      "Episode 140 - reward: 29\n",
      "A  tensor(0.7798, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6631, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0872, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6070, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3078, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7670, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6111, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3254, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0278, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2560, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3753, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0419, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2232, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0951, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2186, grad_fn=<SubBackward0>)\n",
      "A  tensor(-2.3483, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4600, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1005, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2889, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4262, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5308, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4264, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1285, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6157, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7528, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5599, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8827, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0069, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1273, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7153, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4364, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1280, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2106, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3231, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1681, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2793, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3659, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6757, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2141, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1422, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2564, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0356, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1648, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3570, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0154, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0401, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5442, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6127, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5757, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6175, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4940, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8509, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0002, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7438, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0697, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1312, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8833, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8736, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7277, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8222, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5359, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5112, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7203, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9817, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2793, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2453, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0969, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8255, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0110, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7217, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4738, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3883, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5783, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6176, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5522, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8241, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2093, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0445, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8650, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7170, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1494, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3472, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.5811, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3980, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.6842, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9742, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0896, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6175, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4480, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0194, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3698, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2130, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5510, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6414, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.9643, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4703, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2909, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0869, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6082, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1125, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1020, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3323, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5227, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2161, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3055, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2564, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1433, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6794, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0909, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7685, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5225, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3824, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0151, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0415, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2893, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5098, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1969, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6067, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5010, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6422, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0635, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5461, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3095, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6964, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2645, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5874, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2511, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5530, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7824, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4461, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7262, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4000, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1601, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0369, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3177, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3611, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4345, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7504, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0334, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7001, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0370, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8240, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9999, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7959, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7828, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4330, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0473, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9294, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4337, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8302, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9817, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1322, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0096, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2434, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9450, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6879, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8871, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0105, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9431, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2719, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8607, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7268, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2918, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1112, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3516, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5593, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2956, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4988, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1385, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3283, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0286, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7576, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5931, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2113, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0421, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8981, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8080, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6988, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5998, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6642, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4169, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5056, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2221, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1225, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1282, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0530, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2289, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1898, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3359, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1524, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1711, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6519, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1153, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9095, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6435, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0826, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4808, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9925, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0766, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6069, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4403, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1585, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2437, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1988, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4030, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1134, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3300, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5359, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3447, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5737, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7123, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8167, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7883, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5546, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5935, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5982, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6994, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3012, grad_fn=<SubBackward0>)\n",
      "Episode 150 - reward: 22\n",
      "A  tensor(0.7147, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0540, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9107, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8846, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8667, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6452, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5017, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1879, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2451, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3479, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1481, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2628, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2429, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1505, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.7833, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8382, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0869, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5130, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9629, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8331, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7213, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2932, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2094, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1815, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1198, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0928, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3593, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.8013, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.7778, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0597, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5559, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6839, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8675, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8578, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3097, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2879, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3035, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2882, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8314, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4564, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7487, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4739, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1139, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3645, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1433, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3386, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0610, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4881, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3489, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6362, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1146, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3958, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9859, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0747, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3129, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2198, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9052, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9276, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6948, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7781, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5421, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7605, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5154, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7414, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7789, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9556, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8635, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9085, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0256, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2171, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0008, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0811, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2590, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.6954, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4413, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3291, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8293, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.8529, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0065, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5526, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2656, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6447, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2330, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0504, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2615, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4747, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2791, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4019, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5976, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4797, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3039, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2280, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4412, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0325, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8703, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9619, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6535, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9593, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9188, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9191, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8924, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9185, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6676, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9053, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6063, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4919, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3116, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3318, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4296, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6214, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4289, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1792, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0913, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0681, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1082, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0561, grad_fn=<SubBackward0>)\n",
      "A  tensor(-1.5007, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7450, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4966, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2090, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2362, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1421, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1096, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3515, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4718, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2336, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1322, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5157, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5167, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6140, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3615, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6181, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3302, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0821, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0313, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8908, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4729, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2423, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0066, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9582, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5953, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1322, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5971, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1084, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9333, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0139, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7249, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0144, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7477, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5001, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2231, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7733, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8972, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0760, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1333, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0498, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1710, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9060, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2149, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8271, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5446, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0655, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2197, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0325, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0591, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2109, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0329, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1654, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0513, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0962, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4904, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3361, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4921, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8896, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0447, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8326, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0070, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1755, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1406, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0188, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0751, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8657, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7936, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8728, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8271, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8242, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7403, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0945, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1816, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9029, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7682, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2245, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3869, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6105, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4747, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5445, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7221, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7233, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6398, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6859, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5565, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6321, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4732, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6048, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3993, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5270, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1759, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2245, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3044, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8101, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8257, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5186, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0903, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7588, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0745, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0663, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1310, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0643, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2841, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2375, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0163, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5755, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6727, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7263, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9398, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8829, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6068, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2986, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4073, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2241, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3511, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5193, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4477, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4425, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6945, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9066, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8897, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5999, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5634, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7809, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8064, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7182, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9389, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1211, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3746, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0593, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2172, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.7269, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1954, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.7192, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0547, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.6445, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9857, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4152, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7524, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5750, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4179, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4900, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4727, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1571, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5044, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1313, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0218, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5292, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0257, grad_fn=<SubBackward0>)\n",
      "Episode 160 - reward: 26\n",
      "A  tensor(0.3655, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1090, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1970, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3356, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5909, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.7371, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.7208, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2362, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1619, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9746, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8099, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7248, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4247, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0713, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2158, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8911, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0037, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1546, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2719, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2423, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9252, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0030, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9309, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9400, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0572, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3852, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1101, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3739, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0528, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2003, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3350, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0848, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(-0.0925, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.6360, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6544, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4216, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2634, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3169, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4061, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4632, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3338, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4253, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2637, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0461, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3809, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5379, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.6672, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7488, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4485, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1680, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0312, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2692, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4856, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3628, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1485, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2993, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4887, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7045, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1304, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8575, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7414, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9738, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4711, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9343, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1366, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8686, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0548, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3290, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1030, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7333, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8985, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0255, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1932, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8883, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1269, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9394, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6943, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4773, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5939, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7969, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6632, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7320, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9174, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8907, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6562, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6104, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8063, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8443, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7530, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9453, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0640, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8129, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6593, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8565, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0305, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1593, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.5695, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3304, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0082, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7925, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9500, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7809, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8877, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6179, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5328, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5202, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4875, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7057, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9096, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1090, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2047, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3275, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4378, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1356, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9117, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8067, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1365, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1475, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8266, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0850, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7742, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5867, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6001, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4890, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8062, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8314, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9928, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1170, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9337, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9410, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8494, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6877, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7317, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6239, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6239, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3380, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0734, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1745, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1375, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1507, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2967, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.7139, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9143, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4355, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9320, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1033, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3677, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0615, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9846, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1838, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2890, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3061, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2398, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2496, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6892, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7471, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1895, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0119, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2787, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2035, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1930, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1217, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3058, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0483, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2931, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9915, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2881, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0591, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3163, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6104, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7767, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0096, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0758, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6922, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6299, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7996, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9050, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7899, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6787, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4483, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4334, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4045, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3610, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0746, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2325, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1457, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6625, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7550, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1571, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5623, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6679, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8107, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9593, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0676, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2243, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3175, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4241, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1202, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1549, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1139, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9981, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6895, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4809, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2700, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3201, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6377, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7775, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8039, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2734, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7931, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8404, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8037, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0489, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8059, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6633, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4259, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2241, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6779, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3324, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1238, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0752, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1158, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2931, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1664, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1593, grad_fn=<SubBackward0>)\n",
      "Episode 170 - reward: 22\n",
      "A  tensor(0.6346, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8105, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6108, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7777, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5756, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7355, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9031, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9702, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1746, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8829, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2449, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7741, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2919, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7324, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8249, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5339, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.4324, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0520, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5264, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1473, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2522, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0052, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0946, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5969, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2721, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5523, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2233, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8714, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6681, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1910, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2153, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3225, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3285, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2151, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3755, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2542, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1266, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4759, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4573, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9504, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4420, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1999, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5990, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8334, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4820, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4298, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5175, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4185, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1978, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1012, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3217, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1081, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7862, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4648, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0177, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7550, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0860, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6022, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6119, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8109, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0291, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1096, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2929, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.6901, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2105, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.7051, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3915, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9349, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2256, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7068, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1673, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6174, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3268, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0146, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0724, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3217, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0331, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7089, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8038, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1981, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6742, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8470, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4540, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2186, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0339, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2201, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4973, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2218, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2512, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4904, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4866, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6902, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1122, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8632, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8563, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6858, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1439, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6801, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5258, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4604, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0558, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1851, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3022, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2992, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1461, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0705, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1995, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4638, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1679, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1003, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0772, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8280, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8007, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6538, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3000, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3204, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2366, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1665, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2877, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5147, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6881, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8764, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6013, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3302, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0490, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0580, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2943, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4490, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6330, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1070, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3572, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1032, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9036, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0817, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3569, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1190, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0962, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3650, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0207, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3733, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1256, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2892, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4437, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2496, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3921, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6165, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3275, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8970, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8656, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3720, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0464, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6661, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7210, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9247, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8707, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9240, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8325, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2705, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8395, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2685, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7384, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0910, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5232, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3669, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8097, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2550, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0564, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1831, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0094, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0227, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1620, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0147, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3015, grad_fn=<SubBackward0>)\n",
      "A  tensor(-1.4136, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5717, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3978, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6119, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2494, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0011, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2259, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0418, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0354, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2425, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1234, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2422, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1736, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3575, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1128, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0165, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3003, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9343, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2076, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4984, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3176, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4000, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.5385, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.7322, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1961, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9380, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3118, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9883, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5787, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2245, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0772, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3290, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1645, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1971, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2722, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0698, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6430, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9409, grad_fn=<SubBackward0>)\n",
      "Episode 180 - reward: 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.8453, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9707, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8193, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6748, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5105, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6193, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6935, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8207, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5218, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3203, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0782, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2901, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4429, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6038, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7858, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5613, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3381, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5572, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7325, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5377, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6381, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5672, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4960, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6335, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7385, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8088, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6427, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3563, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0283, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2761, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1106, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0546, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0240, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0638, grad_fn=<SubBackward0>)\n",
      "A  tensor(-1.3275, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9367, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0763, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6845, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3860, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4848, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6909, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8576, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0647, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8178, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9104, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.5083, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0996, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7490, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0790, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6554, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3581, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3348, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5514, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7659, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9033, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5793, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3200, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3210, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3967, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3386, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4268, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7931, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8228, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6830, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1411, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4380, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0785, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1178, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3764, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.6294, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.6694, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2531, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9002, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9110, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9110, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8703, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8884, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8019, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8958, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7932, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9071, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8362, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1243, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7935, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1626, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2180, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2595, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2334, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1995, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2875, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1194, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9201, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2994, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0895, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2436, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3632, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5263, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3385, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4426, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6020, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7790, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9553, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8694, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7887, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6822, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7804, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8891, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8853, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8302, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8132, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5559, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0431, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8163, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5849, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8798, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8039, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2644, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7617, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2250, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0482, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4083, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1111, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2499, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3990, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6311, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5143, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7220, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4990, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8785, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9812, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7480, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0099, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7511, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0610, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7469, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9570, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6220, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4398, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5189, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7332, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5644, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6804, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5415, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6100, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7689, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7978, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5117, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2523, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0068, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1501, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3013, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2060, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3571, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4271, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0431, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4654, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1988, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6791, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8364, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0347, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7596, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9894, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7521, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4466, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1355, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1022, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0926, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0698, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0220, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0958, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2825, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7718, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7951, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8028, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0578, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7296, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7005, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8539, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9999, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8435, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9989, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7101, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4320, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3524, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5988, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5796, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3043, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0010, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0106, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3821, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5489, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4347, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4701, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3791, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1241, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3620, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0696, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6689, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7742, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6343, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3423, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4770, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7202, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9297, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0888, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2087, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0477, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2525, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8842, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5947, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6305, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8710, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0342, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9617, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5567, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2859, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.5252, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4786, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4269, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2565, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5117, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0658, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1455, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0311, grad_fn=<SubBackward0>)\n",
      "Episode 190 - reward: 22\n",
      "A  tensor(0.7201, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4206, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1170, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0041, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2144, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4445, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4880, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3025, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0367, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0466, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1973, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1077, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2751, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1975, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4903, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2933, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1161, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1733, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4300, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0942, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8368, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1610, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6264, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1728, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1303, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1768, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2877, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5547, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3500, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0070, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2171, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7072, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8646, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7191, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8371, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9807, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9840, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4519, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1776, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8482, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6258, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3341, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3672, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1214, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2126, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0759, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1762, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0636, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0761, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1749, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2312, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2087, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3613, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9219, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0402, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7116, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4983, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8908, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2256, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2661, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3251, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.6362, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1803, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1570, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2803, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4104, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5372, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6117, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5249, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2831, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6444, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8402, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5281, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7793, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9568, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8498, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9049, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0247, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2719, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9719, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7534, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.6009, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3449, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3218, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1042, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1587, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5679, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1159, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1632, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9654, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0823, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5494, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2548, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1644, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4646, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3431, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0630, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2336, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0601, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2656, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5839, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7070, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0795, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9537, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6534, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7522, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3773, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5361, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3069, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0022, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2997, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0398, grad_fn=<SubBackward0>)\n",
      "A  tensor(-2.8133e-05, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0893, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0671, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2665, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6101, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6223, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0164, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9879, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8214, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5675, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2098, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9642, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8483, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7604, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9139, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6703, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8259, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8701, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0610, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6364, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7843, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6146, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7116, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7997, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0585, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5770, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2652, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3663, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2167, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0690, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0252, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2724, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4708, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5693, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2976, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1384, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3267, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5086, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8001, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2969, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3297, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5565, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2762, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0766, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2797, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0394, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6756, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0206, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5708, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0114, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2747, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3081, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1398, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1677, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2982, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4322, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3198, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4393, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7172, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4616, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9531, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1545, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3317, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4004, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9057, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8880, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0321, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1947, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2729, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4000, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1948, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1061, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2908, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0339, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1083, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2476, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0793, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5806, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5762, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3085, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0214, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0619, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1858, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8550, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5176, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2702, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0183, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3273, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0767, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2250, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4994, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8048, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4006, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7213, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9165, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6173, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3732, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.1294, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0440, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3216, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8656, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8208, grad_fn=<SubBackward0>)\n",
      "Episode 200 - reward: 21\n",
      "A  tensor(0.8927, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6236, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0365, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4191, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2272, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4441, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1096, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1940, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1707, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0239, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0587, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1820, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4614, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1989, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0839, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9517, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1107, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2429, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8375, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2928, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5273, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5741, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2020, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3728, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0873, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2315, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.7665, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6651, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3229, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9027, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6462, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2961, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4660, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8661, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5837, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1632, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3731, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7354, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3445, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5481, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7824, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2537, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7877, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9076, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1208, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.9300, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.6214, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9483, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.5590, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2334, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8342, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7614, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9310, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0272, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9111, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9685, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8683, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0132, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6736, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9600, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6147, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9651, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0383, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6616, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4135, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2212, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3180, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4859, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3635, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5213, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2125, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4429, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5265, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7687, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0030, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6188, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9642, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9860, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9910, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8359, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4585, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2326, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0038, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4254, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5359, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1281, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1353, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4297, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5738, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1251, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5449, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0160, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8357, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9865, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8407, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2769, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0214, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3218, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4930, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0086, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4284, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0140, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0575, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2489, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0965, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4346, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2266, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7778, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1858, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6594, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1449, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5787, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8141, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9674, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5547, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2727, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6225, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8217, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5733, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3547, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5486, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7065, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5037, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3060, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4175, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6097, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3804, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9717, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9946, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9327, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6941, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5867, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1046, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4359, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1405, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.6306, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0238, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3299, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0249, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4786, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7470, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6346, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3559, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0327, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2067, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5112, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.6085, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1649, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4150, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1781, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5269, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0596, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4088, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2581, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0137, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3764, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6944, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3530, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3476, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4444, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0550, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0420, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2157, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3155, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5671, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2883, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3322, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6726, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2671, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4271, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1924, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0614, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4455, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4397, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1080, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1463, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0807, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1562, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0302, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1327, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2823, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5073, grad_fn=<SubBackward0>)\n",
      "Episode 210 - reward: 18\n",
      "A  tensor(0.8254, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9780, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7945, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0077, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7750, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0297, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6028, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3781, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7623, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2492, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0006, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4284, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0969, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2724, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.4136, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0924, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4461, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5932, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8022, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3667, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3524, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6572, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8274, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9332, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9846, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0620, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8856, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8872, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9335, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9485, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7728, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6002, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4690, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9396, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9503, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6309, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3034, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2711, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1125, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2559, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0167, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4153, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1745, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2484, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4412, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2957, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4397, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6504, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3249, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0882, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2765, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3878, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0442, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1048, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2336, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0050, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2861, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1806, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2320, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1248, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9348, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1179, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2858, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4162, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0246, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2485, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0020, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1048, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4127, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3337, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9737, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8070, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0336, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6528, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8729, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8745, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8613, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1568, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7162, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5303, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5990, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5197, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4734, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4950, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3853, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4312, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1435, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0598, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0429, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0599, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3520, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4392, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3169, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6613, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8623, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9207, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9740, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9441, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9554, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9321, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8657, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8663, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9117, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8911, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8232, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4208, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8739, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0760, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8262, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9345, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5452, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2678, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0355, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0375, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3866, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0909, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1808, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3304, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4222, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5424, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5884, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3920, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.9603, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7740, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3280, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3045, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0566, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8995, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1939, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4788, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5277, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2157, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4090, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1772, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4955, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1736, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5979, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7013, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2070, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2030, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2201, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0877, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3282, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4715, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1059, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2021, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4488, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4184, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2384, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1438, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1849, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1325, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0933, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6765, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9434, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6732, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2814, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0630, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2551, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0986, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0695, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0778, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0960, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.7305, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8939, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0215, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8457, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0094, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8176, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0184, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8031, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0053, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8106, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9751, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8327, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7397, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1733, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5693, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1722, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1975, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8596, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8964, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7253, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6359, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1338, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1254, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8121, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9190, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5312, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9417, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9530, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8607, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0239, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8586, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0219, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9448, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5190, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2521, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1462, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1156, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1658, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1451, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0380, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1298, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0828, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.6572, grad_fn=<SubBackward0>)\n",
      "Episode 220 - reward: 21\n",
      "A  tensor(0.7037, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3855, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6906, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8197, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4740, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7642, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4582, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.6901, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8026, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9484, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9684, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7130, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4405, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4825, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3742, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2101, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2480, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2816, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1983, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0084, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3071, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4203, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5831, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2261, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0425, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7731, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0239, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0773, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3891, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0776, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2736, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5364, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7681, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5098, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5557, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7276, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8501, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7022, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1516, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9635, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2059, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6503, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0351, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0850, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7790, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6052, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0483, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0995, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0123, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6601, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3230, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7199, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6567, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8780, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0585, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1567, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3333, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9706, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9126, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0968, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0479, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0695, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9757, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6521, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9189, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9977, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5818, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9640, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5424, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3666, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0888, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1010, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0100, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0165, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3473, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5483, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5457, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2917, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1775, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1997, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1813, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3586, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0389, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2136, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1406, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8606, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7596, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7290, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0847, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5731, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6793, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1099, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1706, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2570, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4453, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0293, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4602, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0308, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0109, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1834, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0835, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6922, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9931, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6635, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4003, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1553, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4917, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5962, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8243, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4328, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2179, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3929, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6332, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3733, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5375, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3440, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4988, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3924, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1612, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0777, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0832, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1401, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1915, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7983, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8666, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8345, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7944, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6703, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2457, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5542, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2010, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4884, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3293, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0124, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2361, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1381, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0826, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3888, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0724, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0468, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0071, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0372, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3365, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3358, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1080, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8350, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7004, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5564, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8171, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5930, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4087, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1465, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0901, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0121, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3603, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.7080, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.8304, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4570, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4877, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4485, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8188, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0941, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2572, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3680, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0821, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4566, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2070, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2782, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3915, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6403, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9040, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6349, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3137, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0710, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1052, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4187, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4111, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4073, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3695, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3359, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3140, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3536, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4475, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5352, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7372, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6764, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6030, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9456, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9311, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0336, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6240, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9055, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6356, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3975, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0763, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0005, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0627, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1203, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2045, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3691, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1419, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1582, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3023, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4064, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7031, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1033, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6147, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3919, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6389, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8385, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0804, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1386, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0085, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1276, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7425, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7292, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9712, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2232, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3544, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6960, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2516, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.8011, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0847, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9677, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9439, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9815, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3705, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0799, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7296, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0992, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8870, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7174, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7770, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4394, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6692, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2566, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0174, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2630, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4967, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1294, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1745, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4951, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4129, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1231, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2073, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1162, grad_fn=<SubBackward0>)\n",
      "Episode 230 - reward: 25\n",
      "A  tensor(1.0857, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1710, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0533, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1989, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9216, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4979, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0499, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2760, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.6390, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4324, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4622, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3684, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1541, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1306, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0102, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0218, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9731, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0112, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5430, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2004, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5025, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1673, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0722, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0515, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0075, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2010, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1743, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0635, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4077, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0227, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8996, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9536, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9860, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2248, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9096, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4764, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1122, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2798, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3756, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0422, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2495, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0433, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2987, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0704, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1463, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1569, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8119, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0576, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8058, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0584, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7225, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8144, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6918, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2861, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0155, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2596, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0508, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3303, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1963, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0072, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2002, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3996, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9425, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8683, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1959, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0379, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7156, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1172, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7074, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4707, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0893, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4164, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3968, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.6194, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3436, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5886, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7133, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1942, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0017, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4513, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5955, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3474, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4950, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0453, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0672, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8161, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5335, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1757, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0454, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4137, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1605, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2355, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4266, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0677, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4284, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6201, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7890, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5455, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6936, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6102, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6281, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7470, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8834, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9732, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7716, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5670, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4417, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5060, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7837, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5844, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7927, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6911, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2908, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2533, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1655, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0714, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2553, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2196, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0560, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0165, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0092, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2370, grad_fn=<SubBackward0>)\n",
      "A  tensor(-1.7098, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5025, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1599, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1384, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5477, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.8818, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0731, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2587, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6168, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7989, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6396, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8502, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1450, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9216, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9242, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7821, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8286, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7209, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7429, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8831, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0132, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5628, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2317, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0212, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0422, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2962, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5585, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8022, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0101, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2024, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4474, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.6507, grad_fn=<SubBackward0>)\n",
      "A  tensor(2.0594, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.7584, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9779, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.5050, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4681, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0680, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5185, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.7508, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1502, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5286, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5177, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8557, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6707, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4226, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4365, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0298, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2454, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0719, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2787, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9575, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1549, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0586, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0512, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0567, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0945, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6585, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8361, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9444, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5547, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9584, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0009, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8293, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9765, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8220, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9512, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9923, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(1.0362, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0763, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0926, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1489, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2916, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3283, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3681, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3672, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0050, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1279, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1608, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2308, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2025, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1460, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6699, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1163, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1549, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6489, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7613, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0081, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9218, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9062, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8887, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0196, grad_fn=<SubBackward0>)\n",
      "Episode 240 - reward: 21\n",
      "A  tensor(1.2298, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9895, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9206, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6186, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3762, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1768, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3756, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0305, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0336, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5869, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3990, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2133, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2170, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7339, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1852, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0114, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9899, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0677, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8583, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5415, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3077, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1083, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0250, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0782, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3329, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8523, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8008, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1781, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9657, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6265, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9491, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6021, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6871, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2042, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9053, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6428, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3799, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6142, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2783, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5365, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3970, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6754, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8281, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7583, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8034, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2305, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7423, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7719, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8185, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8392, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9909, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.5921, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.4333, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6756, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5862, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4479, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1552, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6737, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5263, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5296, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1836, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4932, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5193, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6566, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7233, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7895, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7878, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3682, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9450, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7810, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2855, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9080, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8253, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9824, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7328, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9962, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7664, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6444, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6939, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5629, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3022, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6424, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0822, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4832, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1611, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1853, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3717, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2842, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0288, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0021, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6505, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9608, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4721, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5156, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6102, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7663, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6896, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7184, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8480, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9646, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6482, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3883, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1163, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0996, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1105, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1505, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4803, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6705, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0859, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8919, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9177, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8512, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9606, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6180, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5876, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1012, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0470, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4599, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2359, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0425, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6437, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6586, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1674, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4190, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1301, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1339, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0289, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4169, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6342, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0049, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6973, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5893, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0855, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4068, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8570, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9576, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9348, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9802, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6225, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3572, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1882, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3850, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4092, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5837, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5320, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2986, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0252, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1267, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1180, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5857, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7708, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9036, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8798, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9350, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9880, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9275, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9723, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9166, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8532, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8892, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9319, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9762, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0224, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0378, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0771, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1345, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0713, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1185, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2298, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2334, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1129, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9463, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9802, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8846, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8525, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8020, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9977, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0161, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8109, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7376, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9212, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.9677, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8997, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8010, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4110, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0607, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1217, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4088, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1668, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7424, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9007, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3355, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8247, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9851, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0838, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0805, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6984, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8254, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6835, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7610, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6522, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2954, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4720, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6239, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5886, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5464, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5268, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1356, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1995, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3565, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5754, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8023, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8441, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5202, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3123, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8679, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6098, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5907, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5767, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5740, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5409, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3356, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0956, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1597, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2908, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3060, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3410, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3271, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3922, grad_fn=<SubBackward0>)\n",
      "Episode 250 - reward: 23\n",
      "A  tensor(0.6301, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4307, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7510, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4087, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1960, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0450, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2909, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5476, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3527, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0749, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.7998, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7068, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6248, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3520, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0046, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4297, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4767, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5732, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1736, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2755, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3295, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6065, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1775, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7676, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7572, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5419, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.3490, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5477, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2574, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6909, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6628, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6572, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0922, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6720, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0186, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6955, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9384, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7009, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8197, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7847, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5802, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2338, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2914, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0904, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0507, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6890, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0972, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3113, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5628, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0040, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2665, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3913, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1978, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8078, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1975, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5908, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3311, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7934, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3256, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1512, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4235, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0993, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1281, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0987, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1721, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1412, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2493, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3261, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0615, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9288, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8483, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6579, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5299, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5115, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8882, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8031, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4907, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7141, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4821, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6700, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8474, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7758, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1814, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7244, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4839, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2573, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0087, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0023, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0638, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1463, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0908, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3776, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5613, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5106, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0231, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5755, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0139, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4987, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0745, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2389, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5599, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.9031, grad_fn=<SubBackward0>)\n",
      "A  tensor(-1.2125, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.8942, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4338, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7281, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9145, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6444, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4236, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0784, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3933, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6208, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4998, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6739, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9270, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1649, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5819, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0767, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5911, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2511, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0686, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2553, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0469, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3719, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8736, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5262, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0247, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6963, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5260, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0412, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0335, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2863, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5673, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4326, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.4089, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0050, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1355, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6287, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3955, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7505, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2428, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0084, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2613, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0497, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1002, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1125, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3150, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3954, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2603, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5250, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1655, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8068, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0475, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5919, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8153, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6034, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2865, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5761, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2841, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4306, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5846, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4315, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  tensor(0.1549, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1634, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1699, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1222, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4068, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5906, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3006, grad_fn=<SubBackward0>)\n",
      "Episode 260 - reward: 17\n",
      "A  tensor(0.6655, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1289, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6394, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4522, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0371, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4673, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0244, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2498, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.5306, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2327, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1013, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3019, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.2314, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5384, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.2018, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5601, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1313, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9760, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9653, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8866, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9381, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7123, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5230, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0567, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0604, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6539, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9864, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9027, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1424, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6934, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.9808, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7082, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5077, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6976, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4918, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2909, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4118, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2333, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0284, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3208, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.3152, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0371, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2764, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4173, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.1143, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.7750, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.0449, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6076, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3317, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5333, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6125, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.5418, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2942, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0240, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.0700, grad_fn=<SubBackward0>)\n",
      "A  tensor(-0.1125, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0572, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.2283, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3979, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.3662, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0733, grad_fn=<SubBackward0>)\n",
      "A  tensor(1.1471, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.8640, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.4013, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0867, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.6450, grad_fn=<SubBackward0>)\n",
      "A  tensor(0.0972, grad_fn=<SubBackward0>)\n",
      "A  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-85db75028b3a>\u001b[0m in \u001b[0;36mtrain_cartpole_A2C_v0\u001b[0;34m(n_epochs, lr_actor, lr_critic, gamma, greedy)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/MasterThesis/Policy-based-RL/agents.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, reward, log_prob, state, new_state, done)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Update critic and then actor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/MasterThesis/Policy-based-RL/agents.py\u001b[0m in \u001b[0;36mupdate_actor\u001b[0;34m(self, reward, log_prob, new_state, old_state, done)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# compute advantage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;31m# compute gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mpolicy_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mnonzero_finite_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "agent, performance = train_cartpole_A2C_v0(n_epochs=500, lr_actor=5e-2, lr_critic=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb0e3e4f790>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAe6klEQVR4nO3df8wd1X3n8fc3/AiEEn7ZdRx+GbZ2EKJbpzwqsI1QmppCq6jkj4hNWgXvypL/2NXKUSsSZ1ebBW2lUrHb1Lup0rXitqBlA7QpgqVaXONQsVkJJ88DTsIPY8OWp4Bs/Dgx0CQsa+C7fzxzvdeXuffOj3Nm5sz9vKSr59659858z5lzzzPnzDkz5u6IiEh63td2ACIiUo0qcBGRRKkCFxFJlCpwEZFEqQIXEUnUyU1ubMWKFb5mzZomNykikryFhYUj7r5ydHmjFfiaNWuYn59vcpMiIskzs8W85epCERFJlCpwEZFEqQIXEUmUKnARkUSpAhcRSZQqcBGRRKkCFxFJlCpwEemthcWj3LxjDwuLR9sOJQpV4CLSW9se2c9jB46w7ZH9bYcSRaMzMUVEmrRlw7oT/vaNKnAR6a0rLz6HuzZd1XYY0agLRUQkUarARUQSpQpcRCRRqsBFRBKlClxEJFGqwEVEEqUKXEQkUarARUQSpQpcRCRRqsBFRBKlClxEJFGqwEVEEjW1Ajezj5jZ3qHHG2b2eTM718x2mdmB7O85TQQsIiLLplbg7v6cu6939/XAlcBPgfuBrcBud18L7M5ei4hIQ8p2ofwq8IK7LwI3Andmy+8EPhUyMBERmaxsBf4Z4BvZ81XufjB7fghYlfcFM9tsZvNmNr+0tFQxTBERGVW4AjezU4HfBP5i9D13d8Dzvufu2919zt3nVq5cWTlQERE5UZkj8F8HnnD3V7PXr5rZaoDs7+HQwYmIyHhlKvDP8v+7TwAeBDZmzzcCD4QKSkREpitUgZvZGcB1wF8NLb4duM7MDgAbstciItKQQjc1dvefAOeNLPshy6NSRESkBZqJKSKSKFXgIiKJUgUuIpIoVeAiIolSBS4ikihV4CIiiVIFLiKSKFXgIiKJUgUuIpIoVeAiIolSBS4ikihV4CIiiVIFLiKSKFXgIiKJUgUuIpIoVeAiIolSBS4ikihV4CIiiVIFLiKSKFXgIlLKwuJRbt6xh4XFo22HMvOK3pX+bDP7SzPbZ2bPmtk1Znaume0yswPZ33NiBysi7dv2yH4eO3CEbY/sbzuUmVf0CHwb8LC7Xwb8AvAssBXY7e5rgd3ZaxHpuS0b1nHt2hVs2bCu7VBmnrn75A+YnQXsBS71oQ+b2XPAx939oJmtBv7W3T8yaV1zc3M+Pz8fIGwRkdlhZgvuPje6vMgR+CXAEvBnZvakmX3dzM4AVrn7wewzh4BVYza82czmzWx+aWmpavwiIjKiSAV+MvCLwNfc/aPATxjpLsmOzHMP5d19u7vPufvcypUr68YrIiKZIhX4y8DL7r4ne/2XLFfor2ZdJ2R/D8cJUUQkPU2M1plagbv7IeAlMxv0b/8q8AzwILAxW7YReCBKhCIiCWpitM7JBT/3r4C7zexU4H8D/5zlyv8+M9sELAI3xQlRRCQ9g1E6MUfrTB2FEpJGoYiIlFdnFIqIiHSQKnARkUSpAhcRSZQqcBGRRKkCl8boKnYiYakCl8boKnYiYRUdBy5SWxPjYkVmiSpwacyVF5/DXZuuajsMkd5QF4qISKJUgYuIJEoVeE9ohIfI7FEF3hMa4SEye3QSsyc0wkNk9ugIvCcGIzyuvPictkORlqgbbfaoAhfpCXWjzR51oYj0hLrRZo8qcJGe0ESp2aMuFBGRRKkCFxFJlCpwEZFEFeoDN7MXgX8A3gHedvc5MzsXuBdYA7wI3OTuGr8kItKQMkfgv+Lu64fujLwV2O3ua4Hd2WsREWlInS6UG4E7s+d3Ap+qH47IbNCkm/qUh8UrcAf+xswWzGxztmyVux/Mnh8CVuV90cw2m9m8mc0vLS3VDFekHzTppj7lYfFx4B9z91fM7GeBXWa2b/hNd3cz87wvuvt2YDvA3Nxc7mdEZo0m3dSnPCx4BO7ur2R/DwP3A78EvGpmqwGyv4djBSnNS6V5mkqco3TtmuoG+xxoLA+7Ws6mVuBmdoaZnTl4Dvwa8BTwILAx+9hG4IFYQUrzUmmephKnhNPGPu9qOSvShbIKuN/MBp//b+7+sJl9F7jPzDYBi8BN8cKUpqXSPE0lTgmnjX3e1XJm7s11S8/Nzfn8/Hxj2+uDhcWjbHtkP1s2rFNzu0P6vF/6nLZUmdnC0BDu4zQTs+O62nSbdX3eL31OW9/oaoQd19Wm26zr837pc9r6Rl0oIiIdpy4UEZGeUQUuIsF1ddx0TG2kWRW4iAQ3iydC20izTmKKSHCzeCK0jTTrJOYM0LhekbTpJOYMm8XmrMgsUBfKDJjF5qzILEj6CHwWz3RXkdqV75rYryo79SkP25d0Ba6ugX5qYr+q7NSnPGxf0l0o6hropyb2q8pOfcrD9vVmFIpGWkhfqCzLqN6PQlFzTvpCZVmKSroLZZiac9IXKstSVG+6UERCUPeFhBaiTPW+C0UkBHVfSGgxy1RvulBEQlD3hYQWs0wldwSuyQPlxMqvvu6H1CY9SXVNleGYZapwBW5mJ5nZk2b2UPb6EjPbY2bPm9m9ZnZq8OhyqIlbTqz80n6Q1PWhDJfpQtkCPAt8MHv9B8BX3P0eM/sTYBPwtcDxvTcINXFLiZVf2g+Sul6UYXef+gAuAHYDnwAeAgw4ApycvX8NsHPaeq688krvu/kXf+Sf+/rjPv/ij3q5vVT0IV/6kIZRXUhTF2IoC5j3nDq1aBfKHwFfAN7NXp8HvObub2evXwbOz/uimW02s3kzm19aWir9DyY1TTfL+tAMjKEP+dKHNIzqQpq6EEMoU7tQzOyTwGF3XzCzj5fdgLtvB7bD8jjw0hEmpulmWS+agRH0IV/6kIZRXUhTF2IIZepEHjP7feBzwNvAaSz3gd8PXA98yN3fNrNrgFvd/fpJ69JEHoHpExsmva+JNjKLKk/kcfcvufsF7r4G+AzwLXf/beBR4NPZxzYCDwSMV3psWhN20vt9av6K1FVnIs8XgXvM7PeAJ4EdYUKSvpvWhJ30fp+avyJ16Voo0roUukVSiLGKmOnqa561QddCkc5KoVskhRiriJmuvuZZl+haKNK6FLpFUoixipjp6muedYmOwHuor9cpCaVK/vT1Gikx03XlxeewZcM6tj2yX2UxElXgPZRa01WTn/pLeR2XulB6KLWmqyY/9ZfyOrK8+fWxHnWuhZLi9QtGVUlDU+nuQ/52xWheppy3KcfeJ9S8Fkrr+tAUq5KGptLdh/ztitG8TDlvU459FiTThdKHpliVNDSV7knbyRvPqzG+443mZcplN1bsscrPrJVLTeSRqW7esYfHDhzh2rUruGvTVWOXiRQVq/z0tVyOm8iTzBG4tCfvKCzlo0ppn240EoaOwKWUWWuiigy02ZWoqfQShE5qyazKK/tt/x7UhSKlzFoTVWSgi12J6kIZo42ughS7J2LHPFj/DVes5uGnDla6CUQqFhaP8u//+9Ngxr/95OXJpkPCUxdKSW00jdpujlURO+bB+u/Yua/yTSBSse2R/ex9+XX2vvRa0umQ5qgLZYw2mkZtN8eqiB3zYL3DR+BtxNGELRvW8cabx8As6XRIg/KmZ8Z61JlKX1SbU3817bi4lKabD2K7+/HF3BjzYu9SetqOpe3t9wGpT6Uvqs2mdB+a8U1Jabr5tG6cLo5OGNZ2LG1vv89614XSZlO6D834pqQ03XxaN04XRycMazuWtrffa3mH5bEesbtQut6U7arU8qgL8XYhhmGh4xm3vq6le1ZQtQvFzE4zs++Y2ffM7Gkzuy1bfomZ7TGz583sXjM7Nfp/mym63pTtqtTyqAvxdiGGYaHjGbe+rqV71hXpQnkL+IS7/9jMTgG+bWb/A/gd4Cvufo+Z/QmwCfhaxFin6npTtqtSy6MuxNuFGIaFjmfc+rqW7pmXd1g+7gF8AHgCuAo4ApycLb8G2Dnt+02MQplk2miCJmMIMfpCzdlua2P/pFImUomzK6gzCsXMTjKzvcBhYBfwAvCau7+dfeRl4Pwx391sZvNmNr+0tFT9P00ARSeFNBFDiNEXas52myaDjZdKnF1XaBSKu78DrDezs4H7gcuKbsDdtwPbYXkqfZUgQyk6KaSJGEKMvlBztts0GWy8VOLsvLzD8kkP4MvALSTchdJUs03NxPGK5I3y70Qx8qPJPO7y/uxybO71RqGszI68MbPTgeuAZ4FHgU9nH9sIPBD4f0twTTfb1Ewcr0jeKP9OFCM/mszjLu/PLsc2SZEulNXAnWZ2EssXv7rP3R8ys2eAe8zs94AngR0R4wyi6WabmonjFckb5d+JYuRHk3nc5f3Z5dgm0eVkZ0QfLrc6qi9p6ks6UjCa16nkvS4nO+NSbSJO0pc09SUdKUjpGjxF9O5aKJIv1SbiJH1JU1/SkYKUrsFTSN6ZzViPtkehjCp65rnrZ6ibUiYfquRZ25cCvvE//0+/8avfnvn93LRp+334/Vn9LTJmFMpMH4EPmk8Ad226qvbn+q5MPlTJszbzeXA3nMHzWd7PTZu234ffB/RbHDLTFXjR5lPyzaxAyuRDlTxr+1LAuhtOO6bt90nXOJp5eYflsR51ulCqNt9npck1K+mcVdPKdOwyn9IdlPqI1LtQqjbfYTaaXOrm6bdpZTp2mR8tXypv3ZDMMMItG9Zx7doVbNmwjoXFo9y8Yw8Li0dPeJ732eHnbcmLMbTQ6Qwdc931Ff1+E3ndhNF0TCvTg2U3XLGaN948xvoLz65cFqb9pvJed1mdMrGweJRPffXbfOqP/9cJ3+9KOUtyIs/NO/bw2IEjXLt2BcDx5109EhiOt6sxjgodc931Ff1+inmdp2o6QqS/L3k4UCc9g+8CJ3y/6TwaN5EnmS6UYamd1EjxJGhTNwgI/f0U8zpP1XSESH9f8nCg7hU/805udyaP8jrGYz26Ng7cPc74X40prn6Sq+8nx7p6MrCtOEKcfO1KHg4LHRN1bujQZ4Pxv3tfei3o/QRDrzM1Vacopz61eZquTuVuK47h7fapzDQVU5JdKCHFGP+rMcXtdgF0WVencrcVR4ju0K7k4bDGYso7LI/16FIXSuzmWhebdX0yK/nbp3SG7FpM5YYgoWJAXSgnit1c62Kzrk9mJX/7lM6QXYup3BAkdgwz24USu4nfxWZdn8xK/vYpnSG7FlO5IUj0GPIOy2M9muxC6ULzqYqYcXftnqAxurG6tN+7FIvEEauMj2LWulC60HyqImbcXbsnaIxurC7t9y7FInHEKuNF9bYLpQvNpypixt10nlS5ylzd9XZpv3cpFokjVhkvLO+wPNYjdBdKE03Utm8y8LmvP+53P75Yu6th0hXsJq2/690AMW4y0fU0u7cT47TydPfji77+tp1+9+OLQbbRlCq/s6avCEnVqxGa2YXAXcAqwIHt7r7NzM4F7gXWAC8CN7l7o1d2aeKKaG3fZOCxA0f4wSuvc/Snx0rHUPQKdpPW3/WrzsW4yUTX0wztxDitPN2xcx9Hf3qMO3bu47euuqj2NppOV5nfWV6cbVwFtUgXytvA77r7E2Z2JrBgZruAfwbsdvfbzWwrsBX4YrRIczTRRG37JgMAN1yxmoefOhikqyHv+aT1d70bIMZNJrqeZmgnxmnl6ZbrL+OOnfu45frLgm4jtiq/s0l50eg1mvIOyyc9gAeA64DngNXZstXAc9O+26WJPHlSaDqHUqc7oYnreZSd9DFL+24ghTQXHTHUxk0qqmojFkLc0MHM1gAfBfYAq9z9YPbWIZa7WPK+sxnYDHDRRdWaVU1JoekcSp3uhCYu7l/2HpWztO8GUkjzpBjbvklFVV3K98IVuJn9DPBN4PPu/oaZHX/P3d3Mci8s7u7bge2wfD3weuHGlULTOZQ63QlNXM+j7KSPWdp3AymkueyIoda7JAroVL7nHZaPPoBTgJ3A7wwta7ULpalLT477fKj1VBUqrrrb7ftIoBjqpKdu/rddbqsoe92TUDE3VccUQdWJPLZ8qL0DeNbd/3DorQeBjdnzjSz3jTemqUtPjvt8qPVUFSquutttYrJK3ybE1ElP3fxvu9xWUfa6J6FiTuHytkW6UH4Z+BzwAzPbmy3718DtwH1mtglYBG6KE2K+pi5XOu7zodZTVai46m637yOBYqiTnrr533a5raLqdU+auN5KyO9VkndYHuvR9CiULjT/RoWIqWyTctLy4ckXdZrXVdLVVFO37oSovqmb701041TtIhy3r7tYF5RBiFEoqenS2eKBEDEVWce4z4wuH5588fPnn1UqtrqjBELtn2nrqTshqm/q5nvdUUghy++4743u6y7WBSH0ugLvQvNvVIiY6lxKc3T58OSLj3zozFKx1W22hto/Ra9HUXVCVN/UzfcmunGqdhGO29ddrAuCyDssj/WI1YXSVLdEle8XnciQtyzFZl+RiT8xt5WqOl1QRa5lc/fji0ncaLsL+7SLv0H63IXSVLdEle8XncjQ9ckLRRWZ+BNzW6mqkpYy17IZ/kyRiVFt6cI+Tek32IsKvKluiSrfrzqRoWuTF4oqmqZY20pVlbQU6Roa/sx93/37zt9ouwv7NKnfYN5heaxHm9dCqXPmO/R6816PNm/LnOnv0iiLGE3Ook3aJiYZFV1n0dESbeyrLk1QqaLOPsj7rTUVTx3M2h15RsW6CWqV9ea9Hr3Za5kJG4P37ti5L4lJF3XWWSQfYk4yKrrOaZ9rc4JMChNUQsSR97m831pT8cTQiy6UIuqc+Q693ry/o9f9KHOmv0ujLGI0gYs2aZuYZFR0nUVHS7Sxr5KYoBIgjnHlJtSNlcvGE0XeYXmsR90ulGl3/Jg0EmRSs2naCJJpXRMhJjKEPPNddxJE6GZ/2ZE4TZmU56HSWrXJHqKpXzZ9435fZfIi5P6sk3exylRb5ZU+dKEMTzrJM+n6IJOaTdOuKzKtayLE9SVCXsuh6nVSYjX7y3R7NGlSnodKa9Ume4imftn0jft9lcmLkPuzTt7FKlNd6UYaOOnWW29tbGPbt2+/dfPmzZW//8HTTuGJvz/KLddfxs9fcNZ73r/ovDM49PqbbNmwjg+fffoJy/cfeoMPnXU6X7jhshPeW1g8yq6nD73nveHlm6/9Rxx75933rHdh8Shbv/l9Ll/9QV5Y+jEb/8kluXENf/ai887g6kvPe0+cw7HnvT9Yx7/4rwvc892XWLvqTD589uknrPfg6/+Hrd/8PjdcsZpj77zLDVes5o6d+7jovDP48Nmnj82faflX9P1xhr83iLFoTFUM58mkdQ7KxVvvODeuP/+EffzmsXf5zt/9EDBOft/7TsjHomkdpG//oTc487RTcDi+34bjfPPYu8fXP7wPf/jjt8aW2WnpGy3XV1963vG0rl11Zm4ZG/f7mrSPRtMwiHuwndEyOin/xq0rLw/K7IO8fBvk83DeD8c6unx43cP5WCZ9ddx2220Hb7311u2jy2356LwZc3NzPj8/39j2irh5xx4eO3CEa9euOGGc57jled895wOncPSnxwp9dtJnisYKHF/P8HqBE7YRYpuhNRFTmW1M2/9Aof1bJaa88gMULndlPxMj74ukoeh2y/ye6sQ6HOPotorEMJqeJsq0mS24+9zo8pk5iTlO1Sm7w+8VOXkYaqz6tJOdecvaPuk0rImYymxj0v4f5PVNcxfWPjk8aT/llZ+6Zamp8fhF0lD2pGOsk/F5cYybcl/mPrE6iVlD1RN2Zdc3/F6b05JDnEQpelK36Ljytk5ylRFyjPhoOdjwH/82elkoU85jzWcIEW/IdXbpZGXsE/X04SRmnqon7Mqub/i9O3buCz6WNER8ZdZR5KRu0XHlbZ3kKiPkGPHRcnDg8I+jl4Uy5TzWfIYQ8YZcZ5dOVrZ1oj75LpQ6XSBl1je8rM1pybG6YvK2UbQpG6LLIraQzd7RcvCT//sOZ7z/5Fa6hUJ1lYTeL02MwY9Zlsquu0i9EaV85B2Wx3o0NZW+bvM4r3shVFO1SJyhpmuHiLHOtsqMbQ89frjoOPu8/V2lS6hKt1rIsf/T1h/r+yG6oup2B4Yq31XmisSKZxR9vhrhqEGTBcpfQWzQvTB4PumKenW2M+n7Rddb5HN1Y6yzreHXMPmqbqHiHLeucbEA79nfZWIZfLbK1f7K5E8VscpnqG2E2Ochy3fe777sdkKW4yJ6WYHXbR7ndS/EOKtft/un6miEKqpsa1KexYpz2nbzlhUZ2TNtW1W61crkTxWxymeobYTqDqy7jsH3i3QrhuxODCLvsDzWI1QXSldGMnR9vVXFGLHRRtrmX/yRb/gPj/oVX3547OUXpsmbXt61/VXVIG2//9fPNNYVV3TdTYykKduF2WY3ClVHoZjZn5rZYTN7amjZuWa2y8wOZH/PifpfZkRXRjJ0fb1VxRix0dZU+QNLP+Ef3np77OUXpsmbXt61/VXVIG1f//bflb6iZkhtjaQpO4Kt6PqbLB9FulD+HPgqcNfQsq3Abne/3cy2Zq+/GD68fF0ZydD19VYVY8RGG2nbsmEdB197k0NvvMUt119WaR3D9wwdXu/w31QN0vZP5y7kmYNvNNIVV3TdTYykKduF2clulLzD8tEHsAZ4auj1c8Dq7Plq4Lki66nahdLkaIs6sYyeyY41uL+rTfjhERkx0hZ71ELdkTLT3p92Nc0iMcfe91X2YRPlsW656OIonzIIPApllbsfzJ4fAlaN+6CZbQY2A1x00UWVNtbkaIs6sYyeyYbxIwvaPnsfQ96IjJBpiz1qYdr6674/3B3zW1cV/y3EHq2St60y+7CJ8li3XMSIsQu/w9qjUNzdzWzsFbHcfTuwHZYvZlVlG02OtqgTy7QRLEXXUyeGNg2PyKh6LYvYEyLqrL/u+3ndMVVjjrXvq+zDJspj3XIRI8ZO/A7zDstHH7TchRJaV7sgJok90SXGduS9mhhdEeq7VdQdwZHadptC4GuhPAhszJ5vBB6o8T+kcSmOIggZc1vXbZDmr1PS9P6sO4Ijte22bWoXipl9A/g4sMLMXgb+HXA7cJ+ZbQIWgZtiBhlaJ5o+JcWe6BJjO/JeTYyuCPXdKuqO4Ehtu22b2Rs6LCweZdsj+9myYR1XXtzoMHbpMZUriWHcDR2Sv5xsVX1vWkk7VK6kSb28FkoRfW9aSTtUrqRJM9uFIiKSCnWhiIj0jCpwEZFEqQIXEUmUKnARkUSpAhcRSZQqcBGRRKkCFxFJVKPjwM1sieVrp5S1Ajgy9VP9ojTPBqV5NtRN88XuvnJ0YaMVeFVmNp83iL3PlObZoDTPhlhpVheKiEiiVIGLiCQqlQp8e9sBtEBpng1K82yIkuYk+sBFROS9UjkCFxGREarARUQS1fkK3MxuMLPnzOx5M9vadjyhmNmfmtlhM3tqaNm5ZrbLzA5kf8/JlpuZ/acsD75vZr/YXuTVmdmFZvaomT1jZk+b2ZZseW/TbWanmdl3zOx7WZpvy5ZfYmZ7srTda2anZsvfn71+Pnt/TZvxV2VmJ5nZk2b2UPa61+kFMLMXzewHZrbXzOazZVHLdqcrcDM7Cfhj4NeBy4HPmtnl7UYVzJ8DN4ws2wrsdve1wO7sNSynf2322Ax8raEYQ3sb+F13vxy4GviX2f7sc7rfAj7h7r8ArAduMLOrgT8AvuLuPwccBTZln98EHM2WfyX7XIq2AM8Ove57egd+xd3XD435jlu23b2zD+AaYOfQ6y8BX2o7roDpWwM8NfT6OWB19nw18Fz2/L8An837XMoP4AHgullJN/AB4AngKpZn5Z2cLT9ezoGdwDXZ85Ozz1nbsZdM5wVZZfUJ4CHA+pzeoXS/CKwYWRa1bHf6CBw4H3hp6PXL2bK+WuXuB7Pnh4BV2fPe5UPWVP4osIeepzvrTtgLHAZ2AS8Ar7n729lHhtN1PM3Z+68D5zUbcW1/BHwBeDd7fR79Tu+AA39jZgtmtjlbFrVsz+xNjbvO3d3MejnG08x+Bvgm8Hl3f8PMjr/Xx3S7+zvAejM7G7gfuKzlkKIxs08Ch919wcw+3nY8DfuYu79iZj8L7DKzfcNvxijbXT8CfwW4cOj1BdmyvnrVzFYDZH8PZ8t7kw9mdgrLlffd7v5X2eLepxvA3V8DHmW5C+FsMxscQA2n63ias/fPAn7YcKh1/DLwm2b2InAPy90o2+hveo9z91eyv4dZ/kf9S0Qu212vwL8LrM3OYJ8KfAZ4sOWYYnoQ2Jg938hyH/Fg+c3ZmeurgdeHmmXJsOVD7R3As+7+h0Nv9TbdZrYyO/LGzE5nuc//WZYr8k9nHxtN8yAvPg18y7NO0hS4+5fc/QJ3X8Py7/Vb7v7b9DS9A2Z2hpmdOXgO/BrwFLHLdtsd/wVODPwGsJ/lfsN/03Y8AdP1DeAgcIzl/q9NLPf97QYOAI8A52afNZZH47wA/ACYazv+imn+GMv9hN8H9maP3+hzuoF/DDyZpfkp4MvZ8kuB7wDPA38BvD9bflr2+vns/UvbTkONtH8ceGgW0pul73vZ4+lBXRW7bGsqvYhIorrehSIiImOoAhcRSZQqcBGRRKkCFxFJlCpwEZFEqQIXEUmUKnARkUT9P4FO9BFAVdCIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "episodes = np.arange(1,len(performance)+1)\n",
    "plt.scatter(episodes, performance, s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_test_episode(agent) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advantage Actor-Critic - trajectory version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'agents' from '/home/nicola/Nicola_unipd/MasterThesis/Policy-based-RL/agents.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, r_list, logp_list, s_list, done_list):\n",
    "        self.r_list = r_list\n",
    "        self.logp_list = logp_list\n",
    "        self.s_list = s_list\n",
    "        self.done_list = done_list\n",
    "    \n",
    "    def get_exp(self):\n",
    "        L = np.min([len(r) for r in self.r_list])\n",
    "        r_list_final = np.array([x[-L:] for x in self.r_list])\n",
    "        logp_list_final = np.array([x[-L:] for x in self.logp_list])\n",
    "        s_list_final = np.array([x[-L-1:] for x in self.s_list])\n",
    "        done_list_final = np.array([x[-L:] for x in self.done_list])\n",
    "        return r_list_final, logp_list_final, s_list_final, done_list_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cartpole_A2C_v1(n_epochs = 100, n_batches = 1, lr = 0.01, gamma = 0.99):\n",
    "    # Create environment\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    observation_space = env.observation_space.shape[0]\n",
    "    action_space = env.action_space.n\n",
    "    # Init agent\n",
    "    agent = agents.A2C_v1(observation_space, action_space, lr, gamma)\n",
    "    performance = []\n",
    "    for e in range(n_epochs):\n",
    "        r_list = []\n",
    "        logp_list = []\n",
    "        s_list = []\n",
    "        done_list = []\n",
    "        score = []\n",
    "        \n",
    "        for b in range(n_batches):\n",
    "            rewards, log_probs, states, done = play_episode(agent, env, return_states=True, greedy=False)\n",
    "            r_list.append(rewards)\n",
    "            logp_list.append(log_probs)\n",
    "            s_list.append(states)\n",
    "            done_list.append(done)\n",
    "            score.append(np.sum(rewards))\n",
    "            \n",
    "        performance.append(np.mean(score))\n",
    "        print(\"Epoch %d - mean reward: %.0f\"%(e+1, performance[-1]))\n",
    "        exp_buff = experience_buffer(r_list, logp_list, s_list, done_list)\n",
    "        rewards, log_probs, states, done = exp_buff.get_exp()\n",
    "        #print(\"rewards.shape \", rewards.shape)\n",
    "        #print(\"log_probs.shape \", log_probs.shape)\n",
    "        #print(\"states.shape \", states.shape)\n",
    "        #print(\"done.shape \", done.shape)\n",
    "        #print(\"done \", done)\n",
    "        agent.update(rewards, log_probs, states, done)\n",
    "        \n",
    "    return agent, np.array(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - mean reward: 33\n",
      "Epoch 2 - mean reward: 9\n",
      "Epoch 3 - mean reward: 26\n",
      "Epoch 4 - mean reward: 13\n",
      "Epoch 5 - mean reward: 49\n",
      "Epoch 6 - mean reward: 43\n",
      "Epoch 7 - mean reward: 17\n",
      "Epoch 8 - mean reward: 13\n",
      "Epoch 9 - mean reward: 10\n",
      "Epoch 10 - mean reward: 22\n",
      "Epoch 11 - mean reward: 11\n",
      "Epoch 12 - mean reward: 25\n",
      "Epoch 13 - mean reward: 15\n",
      "Epoch 14 - mean reward: 23\n",
      "Epoch 15 - mean reward: 24\n",
      "Epoch 16 - mean reward: 12\n",
      "Epoch 17 - mean reward: 19\n",
      "Epoch 18 - mean reward: 11\n",
      "Epoch 19 - mean reward: 17\n",
      "Epoch 20 - mean reward: 14\n",
      "Epoch 21 - mean reward: 13\n",
      "Epoch 22 - mean reward: 37\n",
      "Epoch 23 - mean reward: 31\n",
      "Epoch 24 - mean reward: 19\n",
      "Epoch 25 - mean reward: 16\n",
      "Epoch 26 - mean reward: 24\n",
      "Epoch 27 - mean reward: 47\n",
      "Epoch 28 - mean reward: 12\n",
      "Epoch 29 - mean reward: 16\n",
      "Epoch 30 - mean reward: 16\n",
      "Epoch 31 - mean reward: 20\n",
      "Epoch 32 - mean reward: 20\n",
      "Epoch 33 - mean reward: 15\n",
      "Epoch 34 - mean reward: 16\n",
      "Epoch 35 - mean reward: 32\n",
      "Epoch 36 - mean reward: 20\n",
      "Epoch 37 - mean reward: 20\n",
      "Epoch 38 - mean reward: 41\n",
      "Epoch 39 - mean reward: 21\n",
      "Epoch 40 - mean reward: 50\n",
      "Epoch 41 - mean reward: 19\n",
      "Epoch 42 - mean reward: 18\n",
      "Epoch 43 - mean reward: 18\n",
      "Epoch 44 - mean reward: 25\n",
      "Epoch 45 - mean reward: 22\n",
      "Epoch 46 - mean reward: 15\n",
      "Epoch 47 - mean reward: 12\n",
      "Epoch 48 - mean reward: 45\n",
      "Epoch 49 - mean reward: 18\n",
      "Epoch 50 - mean reward: 10\n",
      "Epoch 51 - mean reward: 17\n",
      "Epoch 52 - mean reward: 27\n",
      "Epoch 53 - mean reward: 23\n",
      "Epoch 54 - mean reward: 29\n",
      "Epoch 55 - mean reward: 15\n",
      "Epoch 56 - mean reward: 37\n",
      "Epoch 57 - mean reward: 29\n",
      "Epoch 58 - mean reward: 19\n",
      "Epoch 59 - mean reward: 12\n",
      "Epoch 60 - mean reward: 17\n",
      "Epoch 61 - mean reward: 44\n",
      "Epoch 62 - mean reward: 11\n",
      "Epoch 63 - mean reward: 25\n",
      "Epoch 64 - mean reward: 23\n",
      "Epoch 65 - mean reward: 13\n",
      "Epoch 66 - mean reward: 12\n",
      "Epoch 67 - mean reward: 21\n",
      "Epoch 68 - mean reward: 20\n",
      "Epoch 69 - mean reward: 42\n",
      "Epoch 70 - mean reward: 31\n",
      "Epoch 71 - mean reward: 24\n",
      "Epoch 72 - mean reward: 27\n",
      "Epoch 73 - mean reward: 17\n",
      "Epoch 74 - mean reward: 15\n",
      "Epoch 75 - mean reward: 43\n",
      "Epoch 76 - mean reward: 13\n",
      "Epoch 77 - mean reward: 22\n",
      "Epoch 78 - mean reward: 22\n",
      "Epoch 79 - mean reward: 20\n",
      "Epoch 80 - mean reward: 25\n",
      "Epoch 81 - mean reward: 10\n",
      "Epoch 82 - mean reward: 10\n",
      "Epoch 83 - mean reward: 12\n",
      "Epoch 84 - mean reward: 39\n",
      "Epoch 85 - mean reward: 82\n",
      "Epoch 86 - mean reward: 27\n",
      "Epoch 87 - mean reward: 28\n",
      "Epoch 88 - mean reward: 36\n",
      "Epoch 89 - mean reward: 13\n",
      "Epoch 90 - mean reward: 21\n",
      "Epoch 91 - mean reward: 63\n",
      "Epoch 92 - mean reward: 36\n",
      "Epoch 93 - mean reward: 16\n",
      "Epoch 94 - mean reward: 15\n",
      "Epoch 95 - mean reward: 32\n",
      "Epoch 96 - mean reward: 11\n",
      "Epoch 97 - mean reward: 28\n",
      "Epoch 98 - mean reward: 16\n",
      "Epoch 99 - mean reward: 14\n",
      "Epoch 100 - mean reward: 26\n",
      "Epoch 101 - mean reward: 41\n",
      "Epoch 102 - mean reward: 21\n",
      "Epoch 103 - mean reward: 19\n",
      "Epoch 104 - mean reward: 18\n",
      "Epoch 105 - mean reward: 30\n",
      "Epoch 106 - mean reward: 23\n",
      "Epoch 107 - mean reward: 12\n",
      "Epoch 108 - mean reward: 23\n",
      "Epoch 109 - mean reward: 13\n",
      "Epoch 110 - mean reward: 57\n",
      "Epoch 111 - mean reward: 14\n",
      "Epoch 112 - mean reward: 21\n",
      "Epoch 113 - mean reward: 26\n",
      "Epoch 114 - mean reward: 24\n",
      "Epoch 115 - mean reward: 42\n",
      "Epoch 116 - mean reward: 15\n",
      "Epoch 117 - mean reward: 21\n",
      "Epoch 118 - mean reward: 29\n",
      "Epoch 119 - mean reward: 23\n",
      "Epoch 120 - mean reward: 12\n",
      "Epoch 121 - mean reward: 15\n",
      "Epoch 122 - mean reward: 15\n",
      "Epoch 123 - mean reward: 24\n",
      "Epoch 124 - mean reward: 43\n",
      "Epoch 125 - mean reward: 21\n",
      "Epoch 126 - mean reward: 30\n",
      "Epoch 127 - mean reward: 15\n",
      "Epoch 128 - mean reward: 15\n",
      "Epoch 129 - mean reward: 34\n",
      "Epoch 130 - mean reward: 21\n",
      "Epoch 131 - mean reward: 36\n",
      "Epoch 132 - mean reward: 20\n",
      "Epoch 133 - mean reward: 19\n",
      "Epoch 134 - mean reward: 65\n",
      "Epoch 135 - mean reward: 19\n",
      "Epoch 136 - mean reward: 14\n",
      "Epoch 137 - mean reward: 15\n",
      "Epoch 138 - mean reward: 15\n",
      "Epoch 139 - mean reward: 16\n",
      "Epoch 140 - mean reward: 9\n",
      "Epoch 141 - mean reward: 17\n",
      "Epoch 142 - mean reward: 12\n",
      "Epoch 143 - mean reward: 29\n",
      "Epoch 144 - mean reward: 25\n",
      "Epoch 145 - mean reward: 34\n",
      "Epoch 146 - mean reward: 14\n",
      "Epoch 147 - mean reward: 17\n",
      "Epoch 148 - mean reward: 17\n",
      "Epoch 149 - mean reward: 26\n",
      "Epoch 150 - mean reward: 24\n",
      "Epoch 151 - mean reward: 28\n",
      "Epoch 152 - mean reward: 11\n",
      "Epoch 153 - mean reward: 36\n",
      "Epoch 154 - mean reward: 8\n",
      "Epoch 155 - mean reward: 25\n",
      "Epoch 156 - mean reward: 20\n",
      "Epoch 157 - mean reward: 30\n",
      "Epoch 158 - mean reward: 54\n",
      "Epoch 159 - mean reward: 20\n",
      "Epoch 160 - mean reward: 9\n",
      "Epoch 161 - mean reward: 10\n",
      "Epoch 162 - mean reward: 19\n",
      "Epoch 163 - mean reward: 74\n",
      "Epoch 164 - mean reward: 22\n",
      "Epoch 165 - mean reward: 19\n",
      "Epoch 166 - mean reward: 14\n",
      "Epoch 167 - mean reward: 16\n",
      "Epoch 168 - mean reward: 23\n",
      "Epoch 169 - mean reward: 17\n",
      "Epoch 170 - mean reward: 47\n",
      "Epoch 171 - mean reward: 17\n",
      "Epoch 172 - mean reward: 17\n",
      "Epoch 173 - mean reward: 13\n",
      "Epoch 174 - mean reward: 16\n",
      "Epoch 175 - mean reward: 18\n",
      "Epoch 176 - mean reward: 17\n",
      "Epoch 177 - mean reward: 22\n",
      "Epoch 178 - mean reward: 25\n",
      "Epoch 179 - mean reward: 47\n",
      "Epoch 180 - mean reward: 25\n",
      "Epoch 181 - mean reward: 35\n",
      "Epoch 182 - mean reward: 16\n",
      "Epoch 183 - mean reward: 12\n",
      "Epoch 184 - mean reward: 20\n",
      "Epoch 185 - mean reward: 17\n",
      "Epoch 186 - mean reward: 16\n",
      "Epoch 187 - mean reward: 18\n",
      "Epoch 188 - mean reward: 18\n",
      "Epoch 189 - mean reward: 31\n",
      "Epoch 190 - mean reward: 17\n",
      "Epoch 191 - mean reward: 12\n",
      "Epoch 192 - mean reward: 44\n",
      "Epoch 193 - mean reward: 28\n",
      "Epoch 194 - mean reward: 25\n",
      "Epoch 195 - mean reward: 18\n",
      "Epoch 196 - mean reward: 35\n",
      "Epoch 197 - mean reward: 12\n",
      "Epoch 198 - mean reward: 25\n",
      "Epoch 199 - mean reward: 15\n",
      "Epoch 200 - mean reward: 25\n",
      "Epoch 201 - mean reward: 61\n",
      "Epoch 202 - mean reward: 53\n",
      "Epoch 203 - mean reward: 9\n",
      "Epoch 204 - mean reward: 44\n",
      "Epoch 205 - mean reward: 17\n",
      "Epoch 206 - mean reward: 30\n",
      "Epoch 207 - mean reward: 17\n",
      "Epoch 208 - mean reward: 20\n",
      "Epoch 209 - mean reward: 17\n",
      "Epoch 210 - mean reward: 13\n",
      "Epoch 211 - mean reward: 21\n",
      "Epoch 212 - mean reward: 10\n",
      "Epoch 213 - mean reward: 13\n",
      "Epoch 214 - mean reward: 14\n",
      "Epoch 215 - mean reward: 41\n",
      "Epoch 216 - mean reward: 16\n",
      "Epoch 217 - mean reward: 35\n",
      "Epoch 218 - mean reward: 15\n",
      "Epoch 219 - mean reward: 39\n",
      "Epoch 220 - mean reward: 17\n",
      "Epoch 221 - mean reward: 15\n",
      "Epoch 222 - mean reward: 24\n",
      "Epoch 223 - mean reward: 48\n",
      "Epoch 224 - mean reward: 30\n",
      "Epoch 225 - mean reward: 15\n",
      "Epoch 226 - mean reward: 14\n",
      "Epoch 227 - mean reward: 14\n",
      "Epoch 228 - mean reward: 34\n",
      "Epoch 229 - mean reward: 20\n",
      "Epoch 230 - mean reward: 15\n",
      "Epoch 231 - mean reward: 31\n",
      "Epoch 232 - mean reward: 13\n",
      "Epoch 233 - mean reward: 24\n",
      "Epoch 234 - mean reward: 8\n",
      "Epoch 235 - mean reward: 15\n",
      "Epoch 236 - mean reward: 12\n",
      "Epoch 237 - mean reward: 32\n",
      "Epoch 238 - mean reward: 14\n",
      "Epoch 239 - mean reward: 9\n",
      "Epoch 240 - mean reward: 19\n",
      "Epoch 241 - mean reward: 16\n",
      "Epoch 242 - mean reward: 10\n",
      "Epoch 243 - mean reward: 27\n",
      "Epoch 244 - mean reward: 22\n",
      "Epoch 245 - mean reward: 22\n",
      "Epoch 246 - mean reward: 22\n",
      "Epoch 247 - mean reward: 13\n",
      "Epoch 248 - mean reward: 26\n",
      "Epoch 249 - mean reward: 23\n",
      "Epoch 250 - mean reward: 12\n",
      "Epoch 251 - mean reward: 9\n",
      "Epoch 252 - mean reward: 37\n",
      "Epoch 253 - mean reward: 13\n",
      "Epoch 254 - mean reward: 22\n",
      "Epoch 255 - mean reward: 31\n",
      "Epoch 256 - mean reward: 24\n",
      "Epoch 257 - mean reward: 19\n",
      "Epoch 258 - mean reward: 11\n",
      "Epoch 259 - mean reward: 18\n",
      "Epoch 260 - mean reward: 24\n",
      "Epoch 261 - mean reward: 43\n",
      "Epoch 262 - mean reward: 34\n",
      "Epoch 263 - mean reward: 16\n",
      "Epoch 264 - mean reward: 16\n",
      "Epoch 265 - mean reward: 13\n",
      "Epoch 266 - mean reward: 12\n",
      "Epoch 267 - mean reward: 25\n",
      "Epoch 268 - mean reward: 19\n",
      "Epoch 269 - mean reward: 21\n",
      "Epoch 270 - mean reward: 15\n",
      "Epoch 271 - mean reward: 49\n",
      "Epoch 272 - mean reward: 32\n",
      "Epoch 273 - mean reward: 29\n",
      "Epoch 274 - mean reward: 14\n",
      "Epoch 275 - mean reward: 23\n",
      "Epoch 276 - mean reward: 21\n",
      "Epoch 277 - mean reward: 8\n",
      "Epoch 278 - mean reward: 19\n",
      "Epoch 279 - mean reward: 16\n",
      "Epoch 280 - mean reward: 16\n",
      "Epoch 281 - mean reward: 12\n",
      "Epoch 282 - mean reward: 19\n",
      "Epoch 283 - mean reward: 9\n",
      "Epoch 284 - mean reward: 16\n",
      "Epoch 285 - mean reward: 11\n",
      "Epoch 286 - mean reward: 15\n",
      "Epoch 287 - mean reward: 24\n",
      "Epoch 288 - mean reward: 22\n",
      "Epoch 289 - mean reward: 9\n",
      "Epoch 290 - mean reward: 74\n",
      "Epoch 291 - mean reward: 25\n",
      "Epoch 292 - mean reward: 18\n",
      "Epoch 293 - mean reward: 18\n",
      "Epoch 294 - mean reward: 13\n",
      "Epoch 295 - mean reward: 16\n",
      "Epoch 296 - mean reward: 39\n",
      "Epoch 297 - mean reward: 9\n",
      "Epoch 298 - mean reward: 42\n",
      "Epoch 299 - mean reward: 14\n",
      "Epoch 300 - mean reward: 11\n",
      "Epoch 301 - mean reward: 38\n",
      "Epoch 302 - mean reward: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303 - mean reward: 13\n",
      "Epoch 304 - mean reward: 36\n",
      "Epoch 305 - mean reward: 41\n",
      "Epoch 306 - mean reward: 23\n",
      "Epoch 307 - mean reward: 13\n",
      "Epoch 308 - mean reward: 13\n",
      "Epoch 309 - mean reward: 25\n",
      "Epoch 310 - mean reward: 20\n",
      "Epoch 311 - mean reward: 11\n",
      "Epoch 312 - mean reward: 15\n",
      "Epoch 313 - mean reward: 15\n",
      "Epoch 314 - mean reward: 26\n",
      "Epoch 315 - mean reward: 32\n",
      "Epoch 316 - mean reward: 13\n",
      "Epoch 317 - mean reward: 25\n",
      "Epoch 318 - mean reward: 17\n",
      "Epoch 319 - mean reward: 14\n",
      "Epoch 320 - mean reward: 12\n",
      "Epoch 321 - mean reward: 26\n",
      "Epoch 322 - mean reward: 22\n",
      "Epoch 323 - mean reward: 11\n",
      "Epoch 324 - mean reward: 17\n",
      "Epoch 325 - mean reward: 17\n",
      "Epoch 326 - mean reward: 18\n",
      "Epoch 327 - mean reward: 17\n",
      "Epoch 328 - mean reward: 37\n",
      "Epoch 329 - mean reward: 29\n",
      "Epoch 330 - mean reward: 17\n",
      "Epoch 331 - mean reward: 16\n",
      "Epoch 332 - mean reward: 16\n",
      "Epoch 333 - mean reward: 13\n",
      "Epoch 334 - mean reward: 13\n",
      "Epoch 335 - mean reward: 43\n",
      "Epoch 336 - mean reward: 31\n",
      "Epoch 337 - mean reward: 24\n",
      "Epoch 338 - mean reward: 15\n",
      "Epoch 339 - mean reward: 13\n",
      "Epoch 340 - mean reward: 30\n",
      "Epoch 341 - mean reward: 30\n",
      "Epoch 342 - mean reward: 13\n",
      "Epoch 343 - mean reward: 21\n",
      "Epoch 344 - mean reward: 26\n",
      "Epoch 345 - mean reward: 44\n",
      "Epoch 346 - mean reward: 18\n",
      "Epoch 347 - mean reward: 16\n",
      "Epoch 348 - mean reward: 47\n",
      "Epoch 349 - mean reward: 34\n",
      "Epoch 350 - mean reward: 15\n",
      "Epoch 351 - mean reward: 57\n",
      "Epoch 352 - mean reward: 16\n",
      "Epoch 353 - mean reward: 23\n",
      "Epoch 354 - mean reward: 19\n",
      "Epoch 355 - mean reward: 23\n",
      "Epoch 356 - mean reward: 15\n",
      "Epoch 357 - mean reward: 28\n",
      "Epoch 358 - mean reward: 41\n",
      "Epoch 359 - mean reward: 17\n",
      "Epoch 360 - mean reward: 10\n",
      "Epoch 361 - mean reward: 26\n",
      "Epoch 362 - mean reward: 27\n",
      "Epoch 363 - mean reward: 9\n",
      "Epoch 364 - mean reward: 14\n",
      "Epoch 365 - mean reward: 25\n",
      "Epoch 366 - mean reward: 26\n",
      "Epoch 367 - mean reward: 23\n",
      "Epoch 368 - mean reward: 21\n",
      "Epoch 369 - mean reward: 21\n",
      "Epoch 370 - mean reward: 15\n",
      "Epoch 371 - mean reward: 16\n",
      "Epoch 372 - mean reward: 12\n",
      "Epoch 373 - mean reward: 11\n",
      "Epoch 374 - mean reward: 15\n",
      "Epoch 375 - mean reward: 24\n",
      "Epoch 376 - mean reward: 11\n",
      "Epoch 377 - mean reward: 14\n",
      "Epoch 378 - mean reward: 9\n",
      "Epoch 379 - mean reward: 38\n",
      "Epoch 380 - mean reward: 45\n",
      "Epoch 381 - mean reward: 20\n",
      "Epoch 382 - mean reward: 22\n",
      "Epoch 383 - mean reward: 14\n",
      "Epoch 384 - mean reward: 19\n",
      "Epoch 385 - mean reward: 42\n",
      "Epoch 386 - mean reward: 14\n",
      "Epoch 387 - mean reward: 13\n",
      "Epoch 388 - mean reward: 21\n",
      "Epoch 389 - mean reward: 29\n",
      "Epoch 390 - mean reward: 21\n",
      "Epoch 391 - mean reward: 19\n",
      "Epoch 392 - mean reward: 22\n",
      "Epoch 393 - mean reward: 16\n",
      "Epoch 394 - mean reward: 10\n",
      "Epoch 395 - mean reward: 21\n",
      "Epoch 396 - mean reward: 10\n",
      "Epoch 397 - mean reward: 16\n",
      "Epoch 398 - mean reward: 22\n",
      "Epoch 399 - mean reward: 12\n",
      "Epoch 400 - mean reward: 34\n",
      "Epoch 401 - mean reward: 29\n",
      "Epoch 402 - mean reward: 23\n",
      "Epoch 403 - mean reward: 37\n",
      "Epoch 404 - mean reward: 12\n",
      "Epoch 405 - mean reward: 17\n",
      "Epoch 406 - mean reward: 18\n",
      "Epoch 407 - mean reward: 15\n",
      "Epoch 408 - mean reward: 53\n",
      "Epoch 409 - mean reward: 28\n",
      "Epoch 410 - mean reward: 20\n",
      "Epoch 411 - mean reward: 37\n",
      "Epoch 412 - mean reward: 36\n",
      "Epoch 413 - mean reward: 16\n",
      "Epoch 414 - mean reward: 10\n",
      "Epoch 415 - mean reward: 48\n",
      "Epoch 416 - mean reward: 11\n",
      "Epoch 417 - mean reward: 38\n",
      "Epoch 418 - mean reward: 19\n",
      "Epoch 419 - mean reward: 26\n",
      "Epoch 420 - mean reward: 15\n",
      "Epoch 421 - mean reward: 23\n",
      "Epoch 422 - mean reward: 21\n",
      "Epoch 423 - mean reward: 20\n",
      "Epoch 424 - mean reward: 14\n",
      "Epoch 425 - mean reward: 26\n",
      "Epoch 426 - mean reward: 13\n",
      "Epoch 427 - mean reward: 11\n",
      "Epoch 428 - mean reward: 22\n",
      "Epoch 429 - mean reward: 14\n",
      "Epoch 430 - mean reward: 16\n",
      "Epoch 431 - mean reward: 18\n",
      "Epoch 432 - mean reward: 14\n",
      "Epoch 433 - mean reward: 12\n",
      "Epoch 434 - mean reward: 29\n",
      "Epoch 435 - mean reward: 10\n",
      "Epoch 436 - mean reward: 35\n",
      "Epoch 437 - mean reward: 11\n",
      "Epoch 438 - mean reward: 26\n",
      "Epoch 439 - mean reward: 38\n",
      "Epoch 440 - mean reward: 32\n",
      "Epoch 441 - mean reward: 14\n",
      "Epoch 442 - mean reward: 9\n",
      "Epoch 443 - mean reward: 18\n",
      "Epoch 444 - mean reward: 27\n",
      "Epoch 445 - mean reward: 10\n",
      "Epoch 446 - mean reward: 12\n",
      "Epoch 447 - mean reward: 12\n",
      "Epoch 448 - mean reward: 18\n",
      "Epoch 449 - mean reward: 28\n",
      "Epoch 450 - mean reward: 17\n",
      "Epoch 451 - mean reward: 10\n",
      "Epoch 452 - mean reward: 24\n",
      "Epoch 453 - mean reward: 23\n",
      "Epoch 454 - mean reward: 20\n",
      "Epoch 455 - mean reward: 25\n",
      "Epoch 456 - mean reward: 11\n",
      "Epoch 457 - mean reward: 23\n",
      "Epoch 458 - mean reward: 24\n",
      "Epoch 459 - mean reward: 27\n",
      "Epoch 460 - mean reward: 14\n",
      "Epoch 461 - mean reward: 27\n",
      "Epoch 462 - mean reward: 57\n",
      "Epoch 463 - mean reward: 24\n",
      "Epoch 464 - mean reward: 17\n",
      "Epoch 465 - mean reward: 25\n",
      "Epoch 466 - mean reward: 12\n",
      "Epoch 467 - mean reward: 16\n",
      "Epoch 468 - mean reward: 15\n",
      "Epoch 469 - mean reward: 12\n",
      "Epoch 470 - mean reward: 13\n",
      "Epoch 471 - mean reward: 12\n",
      "Epoch 472 - mean reward: 19\n",
      "Epoch 473 - mean reward: 10\n",
      "Epoch 474 - mean reward: 26\n",
      "Epoch 475 - mean reward: 36\n",
      "Epoch 476 - mean reward: 15\n",
      "Epoch 477 - mean reward: 22\n",
      "Epoch 478 - mean reward: 25\n",
      "Epoch 479 - mean reward: 14\n",
      "Epoch 480 - mean reward: 23\n",
      "Epoch 481 - mean reward: 25\n",
      "Epoch 482 - mean reward: 21\n",
      "Epoch 483 - mean reward: 19\n",
      "Epoch 484 - mean reward: 17\n",
      "Epoch 485 - mean reward: 14\n",
      "Epoch 486 - mean reward: 13\n",
      "Epoch 487 - mean reward: 17\n",
      "Epoch 488 - mean reward: 16\n",
      "Epoch 489 - mean reward: 28\n",
      "Epoch 490 - mean reward: 16\n",
      "Epoch 491 - mean reward: 17\n",
      "Epoch 492 - mean reward: 18\n",
      "Epoch 493 - mean reward: 34\n",
      "Epoch 494 - mean reward: 41\n",
      "Epoch 495 - mean reward: 28\n",
      "Epoch 496 - mean reward: 15\n",
      "Epoch 497 - mean reward: 52\n",
      "Epoch 498 - mean reward: 20\n",
      "Epoch 499 - mean reward: 12\n",
      "Epoch 500 - mean reward: 22\n",
      "CPU times: user 13.4 s, sys: 168 ms, total: 13.6 s\n",
      "Wall time: 9.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "agent_v1, performance_v1 = train_cartpole_A2C_v1(n_epochs=500, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb0f1905f50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "episodes = np.arange(1,len(performance_v1)+1)\n",
    "plt.scatter(episodes, performance_v1, s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_test_episode(agent_v1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward shaping\n",
    "\n",
    "Try to make a more informative reward.\n",
    "Idea: store the whole trajectory, then subtract $-\\frac{eps \\cdot t}{T}$ to all rewards, where $t$ is the step at which the reward was obtained and $T$ the total number of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'agents' from '/home/nicola/Nicola_unipd/MasterThesis/Policy-based-RL/agents.py'>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_rewards(r, eps, power=1):\n",
    "    T = len(r)\n",
    "    t = np.arange(1,T+1)\n",
    "    r -= eps*(t/T)**power\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cartpole_A2C_v2(n_epochs = 100, n_batches = 1, lr = 0.01, gamma = 0.99, eps=1, power=1):\n",
    "    # Create environment\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    observation_space = env.observation_space.shape[0]\n",
    "    action_space = env.action_space.n\n",
    "    # Init agent\n",
    "    agent = agents.A2C_v1(observation_space, action_space, lr, gamma)\n",
    "    performance = []\n",
    "    for e in range(n_epochs):\n",
    "        r_list = []\n",
    "        logp_list = []\n",
    "        s_list = []\n",
    "        done_list = []\n",
    "        score = []\n",
    "        \n",
    "        for b in range(n_batches):\n",
    "            rewards, log_probs, states, done = play_episode(agent, env, return_states=True, greedy=False)\n",
    "            if done[-1] == True:\n",
    "                rewards = shape_rewards(rewards, eps, power)\n",
    "            #print(\"rewards \", rewards)\n",
    "            r_list.append(rewards)\n",
    "            logp_list.append(log_probs)\n",
    "            s_list.append(states)\n",
    "            done_list.append(done)\n",
    "            score.append(np.sum(rewards))\n",
    "            \n",
    "        performance.append(np.mean(score))\n",
    "        if (e+1)%10 == 0:\n",
    "            print(\"Epoch %d - mean reward: %.0f\"%(e+1, np.mean(performance[-10:])))\n",
    "        exp_buff = experience_buffer(r_list, logp_list, s_list, done_list)\n",
    "        rewards, log_probs, states, done = exp_buff.get_exp()\n",
    "        #print(\"rewards.shape \", rewards.shape)\n",
    "        #print(\"log_probs.shape \", log_probs.shape)\n",
    "        #print(\"states.shape \", states.shape)\n",
    "        #print(\"done.shape \", done.shape)\n",
    "        #print(\"done \", done)\n",
    "        agent.update(rewards, log_probs, states, done)\n",
    "        \n",
    "    return agent, np.array(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - mean reward: 13\n",
      "Epoch 20 - mean reward: 12\n",
      "Epoch 30 - mean reward: 10\n",
      "Epoch 40 - mean reward: 10\n",
      "Epoch 50 - mean reward: 10\n",
      "Epoch 60 - mean reward: 10\n",
      "Epoch 70 - mean reward: 12\n",
      "Epoch 80 - mean reward: 9\n",
      "Epoch 90 - mean reward: 12\n",
      "Epoch 100 - mean reward: 11\n",
      "Epoch 110 - mean reward: 14\n",
      "Epoch 120 - mean reward: 14\n",
      "Epoch 130 - mean reward: 11\n",
      "Epoch 140 - mean reward: 15\n",
      "Epoch 150 - mean reward: 12\n",
      "Epoch 160 - mean reward: 12\n",
      "Epoch 170 - mean reward: 11\n",
      "Epoch 180 - mean reward: 18\n",
      "Epoch 190 - mean reward: 12\n",
      "Epoch 200 - mean reward: 9\n",
      "Epoch 210 - mean reward: 10\n",
      "Epoch 220 - mean reward: 12\n",
      "Epoch 230 - mean reward: 12\n",
      "Epoch 240 - mean reward: 18\n",
      "Epoch 250 - mean reward: 11\n",
      "Epoch 260 - mean reward: 13\n",
      "Epoch 270 - mean reward: 10\n",
      "Epoch 280 - mean reward: 10\n",
      "Epoch 290 - mean reward: 17\n",
      "Epoch 300 - mean reward: 15\n",
      "Epoch 310 - mean reward: 11\n",
      "Epoch 320 - mean reward: 11\n",
      "Epoch 330 - mean reward: 15\n",
      "Epoch 340 - mean reward: 10\n",
      "Epoch 350 - mean reward: 13\n",
      "Epoch 360 - mean reward: 14\n",
      "Epoch 370 - mean reward: 11\n",
      "Epoch 380 - mean reward: 16\n",
      "Epoch 390 - mean reward: 12\n",
      "Epoch 400 - mean reward: 10\n",
      "Epoch 410 - mean reward: 12\n",
      "Epoch 420 - mean reward: 10\n",
      "Epoch 430 - mean reward: 15\n",
      "Epoch 440 - mean reward: 12\n",
      "Epoch 450 - mean reward: 12\n",
      "Epoch 460 - mean reward: 12\n",
      "Epoch 470 - mean reward: 11\n",
      "Epoch 480 - mean reward: 15\n",
      "Epoch 490 - mean reward: 11\n",
      "Epoch 500 - mean reward: 11\n",
      "Epoch 510 - mean reward: 13\n",
      "Epoch 520 - mean reward: 10\n",
      "Epoch 530 - mean reward: 11\n",
      "Epoch 540 - mean reward: 12\n",
      "Epoch 550 - mean reward: 13\n",
      "Epoch 560 - mean reward: 14\n",
      "Epoch 570 - mean reward: 13\n",
      "Epoch 580 - mean reward: 14\n",
      "Epoch 590 - mean reward: 13\n",
      "Epoch 600 - mean reward: 12\n",
      "Epoch 610 - mean reward: 11\n",
      "Epoch 620 - mean reward: 11\n",
      "Epoch 630 - mean reward: 15\n",
      "Epoch 640 - mean reward: 13\n",
      "Epoch 650 - mean reward: 16\n",
      "Epoch 660 - mean reward: 13\n",
      "Epoch 670 - mean reward: 14\n",
      "Epoch 680 - mean reward: 13\n",
      "Epoch 690 - mean reward: 11\n",
      "Epoch 700 - mean reward: 12\n",
      "Epoch 710 - mean reward: 12\n",
      "Epoch 720 - mean reward: 12\n",
      "Epoch 730 - mean reward: 11\n",
      "Epoch 740 - mean reward: 9\n",
      "Epoch 750 - mean reward: 10\n",
      "Epoch 760 - mean reward: 14\n",
      "Epoch 770 - mean reward: 10\n",
      "Epoch 780 - mean reward: 14\n",
      "Epoch 790 - mean reward: 15\n",
      "Epoch 800 - mean reward: 14\n",
      "Epoch 810 - mean reward: 14\n",
      "Epoch 820 - mean reward: 10\n",
      "Epoch 830 - mean reward: 11\n",
      "Epoch 840 - mean reward: 11\n",
      "Epoch 850 - mean reward: 13\n",
      "Epoch 860 - mean reward: 11\n",
      "Epoch 870 - mean reward: 12\n",
      "Epoch 880 - mean reward: 12\n",
      "Epoch 890 - mean reward: 11\n",
      "Epoch 900 - mean reward: 13\n",
      "Epoch 910 - mean reward: 10\n",
      "Epoch 920 - mean reward: 13\n",
      "Epoch 930 - mean reward: 10\n",
      "Epoch 940 - mean reward: 13\n",
      "Epoch 950 - mean reward: 11\n",
      "Epoch 960 - mean reward: 16\n",
      "Epoch 970 - mean reward: 10\n",
      "Epoch 980 - mean reward: 11\n",
      "Epoch 990 - mean reward: 11\n",
      "Epoch 1000 - mean reward: 13\n",
      "Epoch 1010 - mean reward: 13\n",
      "Epoch 1020 - mean reward: 15\n",
      "Epoch 1030 - mean reward: 15\n",
      "Epoch 1040 - mean reward: 10\n",
      "Epoch 1050 - mean reward: 11\n",
      "Epoch 1060 - mean reward: 10\n",
      "Epoch 1070 - mean reward: 10\n",
      "Epoch 1080 - mean reward: 11\n",
      "Epoch 1090 - mean reward: 16\n",
      "Epoch 1100 - mean reward: 11\n",
      "Epoch 1110 - mean reward: 15\n",
      "Epoch 1120 - mean reward: 11\n",
      "Epoch 1130 - mean reward: 14\n",
      "Epoch 1140 - mean reward: 10\n",
      "Epoch 1150 - mean reward: 11\n",
      "Epoch 1160 - mean reward: 11\n",
      "Epoch 1170 - mean reward: 12\n",
      "Epoch 1180 - mean reward: 13\n",
      "Epoch 1190 - mean reward: 11\n",
      "Epoch 1200 - mean reward: 13\n",
      "Epoch 1210 - mean reward: 13\n",
      "Epoch 1220 - mean reward: 13\n",
      "Epoch 1230 - mean reward: 14\n",
      "Epoch 1240 - mean reward: 10\n",
      "Epoch 1250 - mean reward: 15\n",
      "Epoch 1260 - mean reward: 12\n",
      "Epoch 1270 - mean reward: 12\n",
      "Epoch 1280 - mean reward: 15\n",
      "Epoch 1290 - mean reward: 14\n",
      "Epoch 1300 - mean reward: 11\n",
      "Epoch 1310 - mean reward: 11\n",
      "Epoch 1320 - mean reward: 13\n",
      "Epoch 1330 - mean reward: 13\n",
      "Epoch 1340 - mean reward: 18\n",
      "Epoch 1350 - mean reward: 14\n",
      "Epoch 1360 - mean reward: 13\n",
      "Epoch 1370 - mean reward: 16\n",
      "Epoch 1380 - mean reward: 18\n",
      "Epoch 1390 - mean reward: 13\n",
      "Epoch 1400 - mean reward: 12\n",
      "Epoch 1410 - mean reward: 13\n",
      "Epoch 1420 - mean reward: 10\n",
      "Epoch 1430 - mean reward: 11\n",
      "Epoch 1440 - mean reward: 16\n",
      "Epoch 1450 - mean reward: 10\n",
      "Epoch 1460 - mean reward: 12\n",
      "Epoch 1470 - mean reward: 14\n",
      "Epoch 1480 - mean reward: 12\n",
      "Epoch 1490 - mean reward: 12\n",
      "Epoch 1500 - mean reward: 11\n",
      "Epoch 1510 - mean reward: 13\n",
      "Epoch 1520 - mean reward: 12\n",
      "Epoch 1530 - mean reward: 9\n",
      "Epoch 1540 - mean reward: 12\n",
      "Epoch 1550 - mean reward: 10\n",
      "Epoch 1560 - mean reward: 11\n",
      "Epoch 1570 - mean reward: 12\n",
      "Epoch 1580 - mean reward: 12\n",
      "Epoch 1590 - mean reward: 11\n",
      "Epoch 1600 - mean reward: 13\n",
      "Epoch 1610 - mean reward: 10\n",
      "Epoch 1620 - mean reward: 12\n",
      "Epoch 1630 - mean reward: 10\n",
      "Epoch 1640 - mean reward: 13\n",
      "Epoch 1650 - mean reward: 10\n",
      "Epoch 1660 - mean reward: 11\n",
      "Epoch 1670 - mean reward: 11\n",
      "Epoch 1680 - mean reward: 10\n",
      "Epoch 1690 - mean reward: 16\n",
      "Epoch 1700 - mean reward: 12\n",
      "Epoch 1710 - mean reward: 13\n",
      "Epoch 1720 - mean reward: 16\n",
      "Epoch 1730 - mean reward: 11\n",
      "Epoch 1740 - mean reward: 12\n",
      "Epoch 1750 - mean reward: 14\n",
      "Epoch 1760 - mean reward: 10\n",
      "Epoch 1770 - mean reward: 17\n",
      "Epoch 1780 - mean reward: 11\n",
      "Epoch 1790 - mean reward: 16\n",
      "Epoch 1800 - mean reward: 14\n",
      "Epoch 1810 - mean reward: 16\n",
      "Epoch 1820 - mean reward: 13\n",
      "Epoch 1830 - mean reward: 14\n",
      "Epoch 1840 - mean reward: 11\n",
      "Epoch 1850 - mean reward: 11\n",
      "Epoch 1860 - mean reward: 11\n",
      "Epoch 1870 - mean reward: 11\n",
      "Epoch 1880 - mean reward: 12\n",
      "Epoch 1890 - mean reward: 13\n",
      "Epoch 1900 - mean reward: 15\n",
      "Epoch 1910 - mean reward: 9\n",
      "Epoch 1920 - mean reward: 12\n",
      "Epoch 1930 - mean reward: 12\n",
      "Epoch 1940 - mean reward: 11\n",
      "Epoch 1950 - mean reward: 15\n",
      "Epoch 1960 - mean reward: 11\n",
      "Epoch 1970 - mean reward: 12\n",
      "Epoch 1980 - mean reward: 11\n",
      "Epoch 1990 - mean reward: 11\n",
      "Epoch 2000 - mean reward: 10\n",
      "Epoch 2010 - mean reward: 15\n",
      "Epoch 2020 - mean reward: 12\n",
      "Epoch 2030 - mean reward: 15\n",
      "Epoch 2040 - mean reward: 13\n",
      "Epoch 2050 - mean reward: 11\n",
      "Epoch 2060 - mean reward: 13\n",
      "Epoch 2070 - mean reward: 11\n",
      "Epoch 2080 - mean reward: 11\n",
      "Epoch 2090 - mean reward: 12\n",
      "Epoch 2100 - mean reward: 15\n",
      "Epoch 2110 - mean reward: 12\n",
      "Epoch 2120 - mean reward: 11\n",
      "Epoch 2130 - mean reward: 10\n",
      "Epoch 2140 - mean reward: 13\n",
      "Epoch 2150 - mean reward: 15\n",
      "Epoch 2160 - mean reward: 14\n",
      "Epoch 2170 - mean reward: 14\n",
      "Epoch 2180 - mean reward: 12\n",
      "Epoch 2190 - mean reward: 15\n",
      "Epoch 2200 - mean reward: 11\n",
      "Epoch 2210 - mean reward: 12\n",
      "Epoch 2220 - mean reward: 21\n",
      "Epoch 2230 - mean reward: 12\n",
      "Epoch 2240 - mean reward: 10\n",
      "Epoch 2250 - mean reward: 11\n",
      "Epoch 2260 - mean reward: 12\n",
      "Epoch 2270 - mean reward: 12\n",
      "Epoch 2280 - mean reward: 9\n",
      "Epoch 2290 - mean reward: 10\n",
      "Epoch 2300 - mean reward: 11\n",
      "Epoch 2310 - mean reward: 15\n",
      "Epoch 2320 - mean reward: 12\n",
      "Epoch 2330 - mean reward: 13\n",
      "Epoch 2340 - mean reward: 9\n",
      "Epoch 2350 - mean reward: 9\n",
      "Epoch 2360 - mean reward: 15\n",
      "Epoch 2370 - mean reward: 14\n",
      "Epoch 2380 - mean reward: 10\n",
      "Epoch 2390 - mean reward: 16\n",
      "Epoch 2400 - mean reward: 13\n",
      "Epoch 2410 - mean reward: 9\n",
      "Epoch 2420 - mean reward: 11\n",
      "Epoch 2430 - mean reward: 11\n",
      "Epoch 2440 - mean reward: 13\n",
      "Epoch 2450 - mean reward: 11\n",
      "Epoch 2460 - mean reward: 12\n",
      "Epoch 2470 - mean reward: 12\n",
      "Epoch 2480 - mean reward: 10\n",
      "Epoch 2490 - mean reward: 12\n",
      "Epoch 2500 - mean reward: 11\n",
      "Epoch 2510 - mean reward: 13\n",
      "Epoch 2520 - mean reward: 11\n",
      "Epoch 2530 - mean reward: 11\n",
      "Epoch 2540 - mean reward: 14\n",
      "Epoch 2550 - mean reward: 11\n",
      "Epoch 2560 - mean reward: 13\n",
      "Epoch 2570 - mean reward: 11\n",
      "Epoch 2580 - mean reward: 12\n",
      "Epoch 2590 - mean reward: 14\n",
      "Epoch 2600 - mean reward: 15\n",
      "Epoch 2610 - mean reward: 13\n",
      "Epoch 2620 - mean reward: 11\n",
      "Epoch 2630 - mean reward: 10\n",
      "Epoch 2640 - mean reward: 14\n",
      "Epoch 2650 - mean reward: 12\n",
      "Epoch 2660 - mean reward: 9\n",
      "Epoch 2670 - mean reward: 15\n",
      "Epoch 2680 - mean reward: 14\n",
      "Epoch 2690 - mean reward: 14\n",
      "Epoch 2700 - mean reward: 11\n",
      "Epoch 2710 - mean reward: 10\n",
      "Epoch 2720 - mean reward: 14\n",
      "Epoch 2730 - mean reward: 15\n",
      "Epoch 2740 - mean reward: 12\n",
      "Epoch 2750 - mean reward: 14\n",
      "Epoch 2760 - mean reward: 13\n",
      "Epoch 2770 - mean reward: 13\n",
      "Epoch 2780 - mean reward: 13\n",
      "Epoch 2790 - mean reward: 12\n",
      "Epoch 2800 - mean reward: 13\n",
      "Epoch 2810 - mean reward: 11\n",
      "Epoch 2820 - mean reward: 15\n",
      "Epoch 2830 - mean reward: 11\n",
      "Epoch 2840 - mean reward: 13\n",
      "Epoch 2850 - mean reward: 12\n",
      "Epoch 2860 - mean reward: 14\n",
      "Epoch 2870 - mean reward: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2880 - mean reward: 11\n",
      "Epoch 2890 - mean reward: 12\n",
      "Epoch 2900 - mean reward: 17\n",
      "Epoch 2910 - mean reward: 16\n",
      "Epoch 2920 - mean reward: 19\n",
      "Epoch 2930 - mean reward: 14\n",
      "Epoch 2940 - mean reward: 15\n",
      "Epoch 2950 - mean reward: 15\n",
      "Epoch 2960 - mean reward: 17\n",
      "Epoch 2970 - mean reward: 11\n",
      "Epoch 2980 - mean reward: 14\n",
      "Epoch 2990 - mean reward: 10\n",
      "Epoch 3000 - mean reward: 12\n",
      "Epoch 3010 - mean reward: 13\n",
      "Epoch 3020 - mean reward: 10\n",
      "Epoch 3030 - mean reward: 12\n",
      "Epoch 3040 - mean reward: 11\n",
      "Epoch 3050 - mean reward: 13\n",
      "Epoch 3060 - mean reward: 10\n",
      "Epoch 3070 - mean reward: 10\n",
      "Epoch 3080 - mean reward: 10\n",
      "Epoch 3090 - mean reward: 15\n",
      "Epoch 3100 - mean reward: 15\n",
      "Epoch 3110 - mean reward: 11\n",
      "Epoch 3120 - mean reward: 12\n",
      "Epoch 3130 - mean reward: 16\n",
      "Epoch 3140 - mean reward: 14\n",
      "Epoch 3150 - mean reward: 14\n",
      "Epoch 3160 - mean reward: 14\n",
      "Epoch 3170 - mean reward: 14\n",
      "Epoch 3180 - mean reward: 9\n",
      "Epoch 3190 - mean reward: 10\n",
      "Epoch 3200 - mean reward: 12\n",
      "Epoch 3210 - mean reward: 13\n",
      "Epoch 3220 - mean reward: 16\n",
      "Epoch 3230 - mean reward: 11\n",
      "Epoch 3240 - mean reward: 11\n",
      "Epoch 3250 - mean reward: 13\n",
      "Epoch 3260 - mean reward: 13\n",
      "Epoch 3270 - mean reward: 12\n",
      "Epoch 3280 - mean reward: 12\n",
      "Epoch 3290 - mean reward: 13\n",
      "Epoch 3300 - mean reward: 16\n",
      "Epoch 3310 - mean reward: 12\n",
      "Epoch 3320 - mean reward: 11\n",
      "Epoch 3330 - mean reward: 10\n",
      "Epoch 3340 - mean reward: 12\n",
      "Epoch 3350 - mean reward: 13\n",
      "Epoch 3360 - mean reward: 15\n",
      "Epoch 3370 - mean reward: 12\n",
      "Epoch 3380 - mean reward: 14\n",
      "Epoch 3390 - mean reward: 12\n",
      "Epoch 3400 - mean reward: 17\n",
      "Epoch 3410 - mean reward: 10\n",
      "Epoch 3420 - mean reward: 11\n",
      "Epoch 3430 - mean reward: 16\n",
      "Epoch 3440 - mean reward: 9\n",
      "Epoch 3450 - mean reward: 13\n",
      "Epoch 3460 - mean reward: 14\n",
      "Epoch 3470 - mean reward: 11\n",
      "Epoch 3480 - mean reward: 11\n",
      "Epoch 3490 - mean reward: 11\n",
      "Epoch 3500 - mean reward: 15\n",
      "Epoch 3510 - mean reward: 11\n",
      "Epoch 3520 - mean reward: 12\n",
      "Epoch 3530 - mean reward: 9\n",
      "Epoch 3540 - mean reward: 16\n",
      "Epoch 3550 - mean reward: 13\n",
      "Epoch 3560 - mean reward: 11\n",
      "Epoch 3570 - mean reward: 13\n",
      "Epoch 3580 - mean reward: 11\n",
      "Epoch 3590 - mean reward: 12\n",
      "Epoch 3600 - mean reward: 13\n",
      "Epoch 3610 - mean reward: 13\n",
      "Epoch 3620 - mean reward: 12\n",
      "Epoch 3630 - mean reward: 14\n",
      "Epoch 3640 - mean reward: 11\n",
      "Epoch 3650 - mean reward: 12\n",
      "Epoch 3660 - mean reward: 14\n",
      "Epoch 3670 - mean reward: 11\n",
      "Epoch 3680 - mean reward: 13\n",
      "Epoch 3690 - mean reward: 12\n",
      "Epoch 3700 - mean reward: 14\n",
      "Epoch 3710 - mean reward: 10\n",
      "Epoch 3720 - mean reward: 12\n",
      "Epoch 3730 - mean reward: 17\n",
      "Epoch 3740 - mean reward: 15\n",
      "Epoch 3750 - mean reward: 11\n",
      "Epoch 3760 - mean reward: 11\n",
      "Epoch 3770 - mean reward: 15\n",
      "Epoch 3780 - mean reward: 11\n",
      "Epoch 3790 - mean reward: 13\n",
      "Epoch 3800 - mean reward: 16\n",
      "Epoch 3810 - mean reward: 10\n",
      "Epoch 3820 - mean reward: 10\n",
      "Epoch 3830 - mean reward: 14\n",
      "Epoch 3840 - mean reward: 12\n",
      "Epoch 3850 - mean reward: 11\n",
      "Epoch 3860 - mean reward: 12\n",
      "Epoch 3870 - mean reward: 13\n",
      "Epoch 3880 - mean reward: 11\n",
      "Epoch 3890 - mean reward: 16\n",
      "Epoch 3900 - mean reward: 11\n",
      "Epoch 3910 - mean reward: 18\n",
      "Epoch 3920 - mean reward: 15\n",
      "Epoch 3930 - mean reward: 11\n",
      "Epoch 3940 - mean reward: 13\n",
      "Epoch 3950 - mean reward: 14\n",
      "Epoch 3960 - mean reward: 8\n",
      "Epoch 3970 - mean reward: 14\n",
      "Epoch 3980 - mean reward: 10\n",
      "Epoch 3990 - mean reward: 14\n",
      "Epoch 4000 - mean reward: 12\n",
      "Epoch 4010 - mean reward: 12\n",
      "Epoch 4020 - mean reward: 12\n",
      "Epoch 4030 - mean reward: 10\n",
      "Epoch 4040 - mean reward: 9\n",
      "Epoch 4050 - mean reward: 14\n",
      "Epoch 4060 - mean reward: 13\n",
      "Epoch 4070 - mean reward: 9\n",
      "Epoch 4080 - mean reward: 16\n",
      "Epoch 4090 - mean reward: 15\n",
      "Epoch 4100 - mean reward: 13\n",
      "Epoch 4110 - mean reward: 14\n",
      "Epoch 4120 - mean reward: 13\n",
      "Epoch 4130 - mean reward: 17\n",
      "Epoch 4140 - mean reward: 13\n",
      "Epoch 4150 - mean reward: 12\n",
      "Epoch 4160 - mean reward: 14\n",
      "Epoch 4170 - mean reward: 12\n",
      "Epoch 4180 - mean reward: 11\n",
      "Epoch 4190 - mean reward: 16\n",
      "Epoch 4200 - mean reward: 9\n",
      "Epoch 4210 - mean reward: 10\n",
      "Epoch 4220 - mean reward: 10\n",
      "Epoch 4230 - mean reward: 14\n",
      "Epoch 4240 - mean reward: 12\n",
      "Epoch 4250 - mean reward: 11\n",
      "Epoch 4260 - mean reward: 11\n",
      "Epoch 4270 - mean reward: 13\n",
      "Epoch 4280 - mean reward: 10\n",
      "Epoch 4290 - mean reward: 10\n",
      "Epoch 4300 - mean reward: 11\n",
      "Epoch 4310 - mean reward: 10\n",
      "Epoch 4320 - mean reward: 11\n",
      "Epoch 4330 - mean reward: 15\n",
      "Epoch 4340 - mean reward: 11\n",
      "Epoch 4350 - mean reward: 14\n",
      "Epoch 4360 - mean reward: 13\n",
      "Epoch 4370 - mean reward: 14\n",
      "Epoch 4380 - mean reward: 10\n",
      "Epoch 4390 - mean reward: 11\n",
      "Epoch 4400 - mean reward: 14\n",
      "Epoch 4410 - mean reward: 13\n",
      "Epoch 4420 - mean reward: 12\n",
      "Epoch 4430 - mean reward: 13\n",
      "Epoch 4440 - mean reward: 10\n",
      "Epoch 4450 - mean reward: 12\n",
      "Epoch 4460 - mean reward: 12\n",
      "Epoch 4470 - mean reward: 8\n",
      "Epoch 4480 - mean reward: 12\n",
      "Epoch 4490 - mean reward: 13\n",
      "Epoch 4500 - mean reward: 13\n",
      "Epoch 4510 - mean reward: 10\n",
      "Epoch 4520 - mean reward: 10\n",
      "Epoch 4530 - mean reward: 12\n",
      "Epoch 4540 - mean reward: 13\n",
      "Epoch 4550 - mean reward: 15\n",
      "Epoch 4560 - mean reward: 12\n",
      "Epoch 4570 - mean reward: 11\n",
      "Epoch 4580 - mean reward: 12\n",
      "Epoch 4590 - mean reward: 14\n",
      "Epoch 4600 - mean reward: 12\n",
      "Epoch 4610 - mean reward: 9\n",
      "Epoch 4620 - mean reward: 15\n",
      "Epoch 4630 - mean reward: 12\n",
      "Epoch 4640 - mean reward: 12\n",
      "Epoch 4650 - mean reward: 18\n",
      "Epoch 4660 - mean reward: 12\n",
      "Epoch 4670 - mean reward: 14\n",
      "Epoch 4680 - mean reward: 11\n",
      "Epoch 4690 - mean reward: 13\n",
      "Epoch 4700 - mean reward: 12\n",
      "Epoch 4710 - mean reward: 13\n",
      "Epoch 4720 - mean reward: 11\n",
      "Epoch 4730 - mean reward: 12\n",
      "Epoch 4740 - mean reward: 10\n",
      "Epoch 4750 - mean reward: 10\n",
      "Epoch 4760 - mean reward: 12\n",
      "Epoch 4770 - mean reward: 10\n",
      "Epoch 4780 - mean reward: 11\n",
      "Epoch 4790 - mean reward: 13\n",
      "Epoch 4800 - mean reward: 11\n",
      "Epoch 4810 - mean reward: 12\n",
      "Epoch 4820 - mean reward: 15\n",
      "Epoch 4830 - mean reward: 10\n",
      "Epoch 4840 - mean reward: 15\n",
      "Epoch 4850 - mean reward: 10\n",
      "Epoch 4860 - mean reward: 12\n",
      "Epoch 4870 - mean reward: 14\n",
      "Epoch 4880 - mean reward: 10\n",
      "Epoch 4890 - mean reward: 16\n",
      "Epoch 4900 - mean reward: 11\n",
      "Epoch 4910 - mean reward: 12\n",
      "Epoch 4920 - mean reward: 13\n",
      "Epoch 4930 - mean reward: 14\n",
      "Epoch 4940 - mean reward: 12\n",
      "Epoch 4950 - mean reward: 10\n",
      "Epoch 4960 - mean reward: 10\n",
      "Epoch 4970 - mean reward: 9\n",
      "Epoch 4980 - mean reward: 11\n",
      "Epoch 4990 - mean reward: 12\n",
      "Epoch 5000 - mean reward: 12\n",
      "CPU times: user 2min 11s, sys: 957 ms, total: 2min 12s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "agent_v1, performance_v1 = train_cartpole_A2C_v2(n_epochs=5000, lr=5e-3, eps=1, power=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy-regularized Policy-Gradient \n",
    "\n",
    "Problem: if the agent takes a dumb action with 100% probability it won't be penalized, since log(1)=0.\n",
    "\n",
    "Idea: add -Entropy of the action's distribution in order to make it less likely to have such a strong policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'agents' from '/home/nicola/Nicola_unipd/MasterThesis/Policy-based-RL/agents.py'>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_episode_ent(agent, env, return_states=False, greedy=True):\n",
    "    # Reset environment (start of an episode)\n",
    "    state = env.reset()\n",
    "    rewards = []\n",
    "    log_probs = []\n",
    "    distributions = []\n",
    "    done = []\n",
    "    \n",
    "    if return_states:\n",
    "        states = [state]\n",
    "        \n",
    "    steps = 0\n",
    "    while True:\n",
    "        action, log_prob, prob_distr = agent.get_action(state, return_log = True, greedy=greedy)\n",
    "        new_state, reward, terminal, info = env.step(action) # gym standard step's output\n",
    "        \n",
    "        if return_states:\n",
    "            states.append(new_state)\n",
    "            \n",
    "        #if terminal and 'TimeLimit.truncated' not in info:\n",
    "        #    reward = -1\n",
    "            \n",
    "        rewards.append(reward)\n",
    "        log_probs.append(log_prob)\n",
    "        distributions.append(prob_distr)\n",
    "        done.append(terminal)\n",
    "        \n",
    "        if terminal:\n",
    "            break\n",
    "            \n",
    "        state = new_state\n",
    "       \n",
    "    rewards = np.array(rewards)\n",
    "    log_probs = np.array(log_probs)\n",
    "    #distributions = np.array(distributions)\n",
    "    done = np.array(done)\n",
    "    \n",
    "    if return_states:\n",
    "        return rewards, log_probs, np.array(states), distributions, done\n",
    "    else:\n",
    "        return rewards, log_probs, distributions, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cartpole_entropy(n_episodes = 100, lr = 0.01, gamma = 0.99, H=1e-3, greedy=False):\n",
    "    # Create environment\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    observation_space = env.observation_space.shape[0]\n",
    "    action_space = env.action_space.n\n",
    "    # Init agent\n",
    "    agent = agents.PolicyGradEnt(observation_space, action_space, lr, gamma, H)\n",
    "    performance = []\n",
    "    losses = []\n",
    "    steps_log = []\n",
    "    for e in range(n_episodes):\n",
    "        rewards, log_probs, distributions, _ = play_episode_ent(agent, env, greedy=greedy)\n",
    "        steps_log.append(len(rewards))\n",
    "        performance.append(np.sum(rewards))\n",
    "        if (e+1)%10 == 0:\n",
    "            print(\"Episode %d - reward: %.0f\"%(e+1, np.mean(performance[-10:])))\n",
    "        \n",
    "        loss = agent.update(rewards, log_probs, distributions)\n",
    "        losses.append(loss)\n",
    "    return agent, np.array(performance), np.array(losses), np.array(steps_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10 - reward: 22\n",
      "Episode 20 - reward: 18\n",
      "Episode 30 - reward: 18\n",
      "Episode 40 - reward: 19\n",
      "Episode 50 - reward: 20\n",
      "Episode 60 - reward: 18\n",
      "Episode 70 - reward: 20\n",
      "Episode 80 - reward: 17\n",
      "Episode 90 - reward: 19\n",
      "Episode 100 - reward: 23\n",
      "Episode 110 - reward: 33\n",
      "Episode 120 - reward: 35\n",
      "Episode 130 - reward: 43\n",
      "Episode 140 - reward: 88\n",
      "Episode 150 - reward: 105\n",
      "Episode 160 - reward: 204\n",
      "Episode 170 - reward: 398\n",
      "Episode 180 - reward: 406\n",
      "Episode 190 - reward: 432\n",
      "Episode 200 - reward: 378\n",
      "Episode 210 - reward: 425\n",
      "Episode 220 - reward: 500\n",
      "Episode 230 - reward: 500\n",
      "Episode 240 - reward: 417\n",
      "Episode 250 - reward: 372\n",
      "Episode 260 - reward: 424\n",
      "Episode 270 - reward: 464\n",
      "Episode 280 - reward: 317\n",
      "Episode 290 - reward: 73\n",
      "Episode 300 - reward: 83\n",
      "Episode 310 - reward: 172\n",
      "Episode 320 - reward: 467\n",
      "Episode 330 - reward: 500\n",
      "Episode 340 - reward: 500\n",
      "Episode 350 - reward: 472\n",
      "Episode 360 - reward: 414\n",
      "Episode 370 - reward: 390\n",
      "Episode 380 - reward: 399\n",
      "Episode 390 - reward: 406\n",
      "Episode 400 - reward: 220\n",
      "Episode 410 - reward: 163\n",
      "Episode 420 - reward: 207\n",
      "Episode 430 - reward: 475\n",
      "Episode 440 - reward: 479\n",
      "Episode 450 - reward: 418\n",
      "Episode 460 - reward: 298\n",
      "Episode 470 - reward: 469\n",
      "Episode 480 - reward: 475\n",
      "Episode 490 - reward: 499\n",
      "Episode 500 - reward: 477\n",
      "CPU times: user 2min 12s, sys: 383 ms, total: 2min 12s\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trained_agentPG, cumulative_rewardPG, lossesPG, steps_log = train_cartpole_entropy(n_episodes = 500, lr=5e-3, H=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10 - reward: 15\n",
      "Episode 20 - reward: 22\n",
      "Episode 30 - reward: 25\n",
      "Episode 40 - reward: 19\n",
      "Episode 50 - reward: 28\n",
      "Episode 60 - reward: 27\n",
      "Episode 70 - reward: 50\n",
      "Episode 80 - reward: 43\n",
      "Episode 90 - reward: 46\n",
      "Episode 100 - reward: 51\n",
      "Episode 110 - reward: 74\n",
      "Episode 120 - reward: 86\n",
      "Episode 130 - reward: 93\n",
      "Episode 140 - reward: 49\n",
      "Episode 150 - reward: 52\n",
      "Episode 160 - reward: 77\n",
      "Episode 170 - reward: 101\n",
      "Episode 180 - reward: 94\n",
      "Episode 190 - reward: 95\n",
      "Episode 200 - reward: 123\n",
      "Episode 210 - reward: 267\n",
      "Episode 220 - reward: 472\n",
      "Episode 230 - reward: 500\n",
      "Episode 240 - reward: 421\n",
      "Episode 250 - reward: 287\n",
      "Episode 260 - reward: 91\n",
      "Episode 270 - reward: 89\n",
      "Episode 280 - reward: 106\n",
      "Episode 290 - reward: 184\n",
      "Episode 300 - reward: 221\n",
      "Episode 310 - reward: 252\n",
      "Episode 320 - reward: 206\n",
      "Episode 330 - reward: 248\n",
      "Episode 340 - reward: 174\n",
      "Episode 350 - reward: 159\n",
      "Episode 360 - reward: 106\n",
      "Episode 370 - reward: 121\n",
      "Episode 380 - reward: 136\n",
      "Episode 390 - reward: 129\n",
      "Episode 400 - reward: 119\n",
      "Episode 410 - reward: 134\n",
      "Episode 420 - reward: 228\n",
      "Episode 430 - reward: 442\n",
      "Episode 440 - reward: 443\n",
      "Episode 450 - reward: 463\n",
      "Episode 460 - reward: 197\n",
      "Episode 470 - reward: 158\n",
      "Episode 480 - reward: 135\n",
      "Episode 490 - reward: 130\n",
      "Episode 500 - reward: 99\n",
      "Episode 10 - reward: 21\n",
      "Episode 20 - reward: 44\n",
      "Episode 30 - reward: 40\n",
      "Episode 40 - reward: 62\n",
      "Episode 50 - reward: 84\n",
      "Episode 60 - reward: 157\n",
      "Episode 70 - reward: 146\n",
      "Episode 80 - reward: 69\n",
      "Episode 90 - reward: 232\n",
      "Episode 100 - reward: 161\n",
      "Episode 110 - reward: 339\n",
      "Episode 120 - reward: 431\n",
      "Episode 130 - reward: 470\n",
      "Episode 140 - reward: 500\n",
      "Episode 150 - reward: 379\n",
      "Episode 160 - reward: 396\n",
      "Episode 170 - reward: 329\n",
      "Episode 180 - reward: 381\n",
      "Episode 190 - reward: 500\n",
      "Episode 200 - reward: 500\n",
      "Episode 210 - reward: 491\n",
      "Episode 220 - reward: 292\n",
      "Episode 230 - reward: 162\n",
      "Episode 240 - reward: 135\n",
      "Episode 250 - reward: 176\n",
      "Episode 260 - reward: 228\n",
      "Episode 270 - reward: 240\n",
      "Episode 280 - reward: 139\n",
      "Episode 290 - reward: 124\n",
      "Episode 300 - reward: 130\n",
      "Episode 310 - reward: 126\n",
      "Episode 320 - reward: 133\n",
      "Episode 330 - reward: 172\n",
      "Episode 340 - reward: 263\n",
      "Episode 350 - reward: 465\n",
      "Episode 360 - reward: 500\n",
      "Episode 370 - reward: 500\n",
      "Episode 380 - reward: 497\n",
      "Episode 390 - reward: 430\n",
      "Episode 400 - reward: 455\n",
      "Episode 410 - reward: 420\n",
      "Episode 420 - reward: 480\n",
      "Episode 430 - reward: 466\n",
      "Episode 440 - reward: 392\n",
      "Episode 450 - reward: 500\n",
      "Episode 460 - reward: 464\n",
      "Episode 470 - reward: 470\n",
      "Episode 480 - reward: 440\n",
      "Episode 490 - reward: 460\n",
      "Episode 500 - reward: 500\n",
      "Episode 10 - reward: 25\n",
      "Episode 20 - reward: 30\n",
      "Episode 30 - reward: 38\n",
      "Episode 40 - reward: 59\n",
      "Episode 50 - reward: 74\n",
      "Episode 60 - reward: 173\n",
      "Episode 70 - reward: 131\n",
      "Episode 80 - reward: 324\n",
      "Episode 90 - reward: 437\n",
      "Episode 100 - reward: 443\n",
      "Episode 110 - reward: 475\n",
      "Episode 120 - reward: 357\n",
      "Episode 130 - reward: 124\n",
      "Episode 140 - reward: 102\n",
      "Episode 150 - reward: 96\n",
      "Episode 160 - reward: 91\n",
      "Episode 170 - reward: 86\n",
      "Episode 180 - reward: 88\n",
      "Episode 190 - reward: 121\n",
      "Episode 200 - reward: 100\n",
      "Episode 210 - reward: 76\n",
      "Episode 220 - reward: 62\n",
      "Episode 230 - reward: 73\n",
      "Episode 240 - reward: 75\n",
      "Episode 250 - reward: 77\n",
      "Episode 260 - reward: 78\n",
      "Episode 270 - reward: 84\n",
      "Episode 280 - reward: 121\n",
      "Episode 290 - reward: 139\n",
      "Episode 300 - reward: 169\n",
      "Episode 310 - reward: 500\n",
      "Episode 320 - reward: 500\n",
      "Episode 330 - reward: 500\n",
      "Episode 340 - reward: 500\n",
      "Episode 350 - reward: 491\n",
      "Episode 360 - reward: 500\n",
      "Episode 370 - reward: 487\n",
      "Episode 380 - reward: 470\n",
      "Episode 390 - reward: 440\n",
      "Episode 400 - reward: 493\n",
      "Episode 410 - reward: 422\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 325\n",
      "Episode 440 - reward: 300\n",
      "Episode 450 - reward: 290\n",
      "Episode 460 - reward: 234\n",
      "Episode 470 - reward: 222\n",
      "Episode 480 - reward: 462\n",
      "Episode 490 - reward: 114\n",
      "Episode 500 - reward: 68\n",
      "Episode 10 - reward: 25\n",
      "Episode 20 - reward: 33\n",
      "Episode 30 - reward: 44\n",
      "Episode 40 - reward: 54\n",
      "Episode 50 - reward: 47\n",
      "Episode 60 - reward: 70\n",
      "Episode 70 - reward: 97\n",
      "Episode 80 - reward: 36\n",
      "Episode 90 - reward: 78\n",
      "Episode 100 - reward: 395\n",
      "Episode 110 - reward: 316\n",
      "Episode 120 - reward: 122\n",
      "Episode 130 - reward: 65\n",
      "Episode 140 - reward: 119\n",
      "Episode 150 - reward: 142\n",
      "Episode 160 - reward: 135\n",
      "Episode 170 - reward: 82\n",
      "Episode 180 - reward: 40\n",
      "Episode 190 - reward: 65\n",
      "Episode 200 - reward: 101\n",
      "Episode 210 - reward: 125\n",
      "Episode 220 - reward: 174\n",
      "Episode 230 - reward: 190\n",
      "Episode 240 - reward: 93\n",
      "Episode 250 - reward: 51\n",
      "Episode 260 - reward: 79\n",
      "Episode 270 - reward: 127\n",
      "Episode 280 - reward: 178\n",
      "Episode 290 - reward: 201\n",
      "Episode 300 - reward: 192\n",
      "Episode 310 - reward: 181\n",
      "Episode 320 - reward: 332\n",
      "Episode 330 - reward: 427\n",
      "Episode 340 - reward: 192\n",
      "Episode 350 - reward: 157\n",
      "Episode 360 - reward: 238\n",
      "Episode 370 - reward: 272\n",
      "Episode 380 - reward: 239\n",
      "Episode 390 - reward: 280\n",
      "Episode 400 - reward: 358\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 439\n",
      "Episode 430 - reward: 435\n",
      "Episode 440 - reward: 367\n",
      "Episode 450 - reward: 207\n",
      "Episode 460 - reward: 147\n",
      "Episode 470 - reward: 121\n",
      "Episode 480 - reward: 24\n",
      "Episode 490 - reward: 21\n",
      "Episode 500 - reward: 13\n",
      "Episode 10 - reward: 23\n",
      "Episode 20 - reward: 18\n",
      "Episode 30 - reward: 35\n",
      "Episode 40 - reward: 32\n",
      "Episode 50 - reward: 53\n",
      "Episode 60 - reward: 111\n",
      "Episode 70 - reward: 88\n",
      "Episode 80 - reward: 205\n",
      "Episode 90 - reward: 305\n",
      "Episode 100 - reward: 421\n",
      "Episode 110 - reward: 432\n",
      "Episode 120 - reward: 341\n",
      "Episode 130 - reward: 220\n",
      "Episode 140 - reward: 157\n",
      "Episode 150 - reward: 105\n",
      "Episode 160 - reward: 116\n",
      "Episode 170 - reward: 95\n",
      "Episode 180 - reward: 93\n",
      "Episode 190 - reward: 168\n",
      "Episode 200 - reward: 336\n",
      "Episode 210 - reward: 202\n",
      "Episode 220 - reward: 190\n",
      "Episode 230 - reward: 195\n",
      "Episode 240 - reward: 220\n",
      "Episode 250 - reward: 312\n",
      "Episode 260 - reward: 255\n",
      "Episode 270 - reward: 217\n",
      "Episode 280 - reward: 207\n",
      "Episode 290 - reward: 231\n",
      "Episode 300 - reward: 292\n",
      "Episode 310 - reward: 306\n",
      "Episode 320 - reward: 338\n",
      "Episode 330 - reward: 343\n",
      "Episode 340 - reward: 492\n",
      "Episode 350 - reward: 206\n",
      "Episode 360 - reward: 45\n",
      "Episode 370 - reward: 70\n",
      "Episode 380 - reward: 117\n",
      "Episode 390 - reward: 162\n",
      "Episode 400 - reward: 213\n",
      "Episode 410 - reward: 255\n",
      "Episode 420 - reward: 292\n",
      "Episode 430 - reward: 320\n",
      "Episode 440 - reward: 427\n",
      "Episode 450 - reward: 386\n",
      "Episode 460 - reward: 403\n",
      "Episode 470 - reward: 500\n",
      "Episode 480 - reward: 257\n",
      "Episode 490 - reward: 12\n",
      "Episode 500 - reward: 26\n",
      "Episode 10 - reward: 24\n",
      "Episode 20 - reward: 28\n",
      "Episode 30 - reward: 53\n",
      "Episode 40 - reward: 34\n",
      "Episode 50 - reward: 33\n",
      "Episode 60 - reward: 39\n",
      "Episode 70 - reward: 47\n",
      "Episode 80 - reward: 185\n",
      "Episode 90 - reward: 40\n",
      "Episode 100 - reward: 16\n",
      "Episode 110 - reward: 10\n",
      "Episode 120 - reward: 9\n",
      "Episode 130 - reward: 10\n",
      "Episode 140 - reward: 9\n",
      "Episode 150 - reward: 9\n",
      "Episode 160 - reward: 9\n",
      "Episode 170 - reward: 9\n",
      "Episode 180 - reward: 9\n",
      "Episode 190 - reward: 9\n",
      "Episode 200 - reward: 9\n",
      "Episode 210 - reward: 10\n",
      "Episode 220 - reward: 9\n",
      "Episode 230 - reward: 10\n",
      "Episode 240 - reward: 10\n",
      "Episode 250 - reward: 9\n",
      "Episode 260 - reward: 10\n",
      "Episode 270 - reward: 9\n",
      "Episode 280 - reward: 9\n",
      "Episode 290 - reward: 9\n",
      "Episode 300 - reward: 9\n",
      "Episode 310 - reward: 9\n",
      "Episode 320 - reward: 9\n",
      "Episode 330 - reward: 10\n",
      "Episode 340 - reward: 9\n",
      "Episode 350 - reward: 10\n",
      "Episode 360 - reward: 9\n",
      "Episode 370 - reward: 9\n",
      "Episode 380 - reward: 9\n",
      "Episode 390 - reward: 10\n",
      "Episode 400 - reward: 9\n",
      "Episode 410 - reward: 9\n",
      "Episode 420 - reward: 10\n",
      "Episode 430 - reward: 9\n",
      "Episode 440 - reward: 10\n",
      "Episode 450 - reward: 9\n",
      "Episode 460 - reward: 9\n",
      "Episode 470 - reward: 9\n",
      "Episode 480 - reward: 10\n",
      "Episode 490 - reward: 9\n",
      "Episode 500 - reward: 9\n",
      "Episode 10 - reward: 27\n",
      "Episode 20 - reward: 25\n",
      "Episode 30 - reward: 34\n",
      "Episode 40 - reward: 49\n",
      "Episode 50 - reward: 54\n",
      "Episode 60 - reward: 61\n",
      "Episode 70 - reward: 151\n",
      "Episode 80 - reward: 188\n",
      "Episode 90 - reward: 324\n",
      "Episode 100 - reward: 230\n",
      "Episode 110 - reward: 292\n",
      "Episode 120 - reward: 166\n",
      "Episode 130 - reward: 73\n",
      "Episode 140 - reward: 169\n",
      "Episode 150 - reward: 473\n",
      "Episode 160 - reward: 479\n",
      "Episode 170 - reward: 451\n",
      "Episode 180 - reward: 118\n",
      "Episode 190 - reward: 78\n",
      "Episode 200 - reward: 88\n",
      "Episode 210 - reward: 57\n",
      "Episode 220 - reward: 83\n",
      "Episode 230 - reward: 233\n",
      "Episode 240 - reward: 482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 250 - reward: 500\n",
      "Episode 260 - reward: 500\n",
      "Episode 270 - reward: 500\n",
      "Episode 280 - reward: 500\n",
      "Episode 290 - reward: 500\n",
      "Episode 300 - reward: 500\n",
      "Episode 310 - reward: 500\n",
      "Episode 320 - reward: 500\n",
      "Episode 330 - reward: 457\n",
      "Episode 340 - reward: 500\n",
      "Episode 350 - reward: 500\n",
      "Episode 360 - reward: 500\n",
      "Episode 370 - reward: 500\n",
      "Episode 380 - reward: 457\n",
      "Episode 390 - reward: 500\n",
      "Episode 400 - reward: 453\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 500\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 500\n",
      "Episode 460 - reward: 350\n",
      "Episode 470 - reward: 71\n",
      "Episode 480 - reward: 10\n",
      "Episode 490 - reward: 10\n",
      "Episode 500 - reward: 10\n",
      "Episode 10 - reward: 23\n",
      "Episode 20 - reward: 17\n",
      "Episode 30 - reward: 20\n",
      "Episode 40 - reward: 24\n",
      "Episode 50 - reward: 27\n",
      "Episode 60 - reward: 34\n",
      "Episode 70 - reward: 24\n",
      "Episode 80 - reward: 35\n",
      "Episode 90 - reward: 39\n",
      "Episode 100 - reward: 57\n",
      "Episode 110 - reward: 81\n",
      "Episode 120 - reward: 145\n",
      "Episode 130 - reward: 211\n",
      "Episode 140 - reward: 335\n",
      "Episode 150 - reward: 443\n",
      "Episode 160 - reward: 433\n",
      "Episode 170 - reward: 294\n",
      "Episode 180 - reward: 174\n",
      "Episode 190 - reward: 115\n",
      "Episode 200 - reward: 87\n",
      "Episode 210 - reward: 76\n",
      "Episode 220 - reward: 74\n",
      "Episode 230 - reward: 114\n",
      "Episode 240 - reward: 174\n",
      "Episode 250 - reward: 175\n",
      "Episode 260 - reward: 127\n",
      "Episode 270 - reward: 110\n",
      "Episode 280 - reward: 130\n",
      "Episode 290 - reward: 167\n",
      "Episode 300 - reward: 400\n",
      "Episode 310 - reward: 384\n",
      "Episode 320 - reward: 474\n",
      "Episode 330 - reward: 500\n",
      "Episode 340 - reward: 500\n",
      "Episode 350 - reward: 500\n",
      "Episode 360 - reward: 500\n",
      "Episode 370 - reward: 495\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 500\n",
      "Episode 400 - reward: 429\n",
      "Episode 410 - reward: 488\n",
      "Episode 420 - reward: 489\n",
      "Episode 430 - reward: 238\n",
      "Episode 440 - reward: 114\n",
      "Episode 450 - reward: 105\n",
      "Episode 460 - reward: 90\n",
      "Episode 470 - reward: 72\n",
      "Episode 480 - reward: 93\n",
      "Episode 490 - reward: 110\n",
      "Episode 500 - reward: 270\n",
      "Episode 10 - reward: 23\n",
      "Episode 20 - reward: 21\n",
      "Episode 30 - reward: 28\n",
      "Episode 40 - reward: 25\n",
      "Episode 50 - reward: 50\n",
      "Episode 60 - reward: 40\n",
      "Episode 70 - reward: 79\n",
      "Episode 80 - reward: 107\n",
      "Episode 90 - reward: 66\n",
      "Episode 100 - reward: 192\n",
      "Episode 110 - reward: 38\n",
      "Episode 120 - reward: 40\n",
      "Episode 130 - reward: 36\n",
      "Episode 140 - reward: 46\n",
      "Episode 150 - reward: 41\n",
      "Episode 160 - reward: 32\n",
      "Episode 170 - reward: 39\n",
      "Episode 180 - reward: 48\n",
      "Episode 190 - reward: 54\n",
      "Episode 200 - reward: 61\n",
      "Episode 210 - reward: 279\n",
      "Episode 220 - reward: 115\n",
      "Episode 230 - reward: 59\n",
      "Episode 240 - reward: 142\n",
      "Episode 250 - reward: 302\n",
      "Episode 260 - reward: 466\n",
      "Episode 270 - reward: 500\n",
      "Episode 280 - reward: 500\n",
      "Episode 290 - reward: 500\n",
      "Episode 300 - reward: 486\n",
      "Episode 310 - reward: 500\n",
      "Episode 320 - reward: 500\n",
      "Episode 330 - reward: 500\n",
      "Episode 340 - reward: 480\n",
      "Episode 350 - reward: 492\n",
      "Episode 360 - reward: 397\n",
      "Episode 370 - reward: 450\n",
      "Episode 380 - reward: 270\n",
      "Episode 390 - reward: 281\n",
      "Episode 400 - reward: 197\n",
      "Episode 410 - reward: 390\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 500\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 500\n",
      "Episode 460 - reward: 500\n",
      "Episode 470 - reward: 404\n",
      "Episode 480 - reward: 340\n",
      "Episode 490 - reward: 460\n",
      "Episode 500 - reward: 410\n",
      "Episode 10 - reward: 30\n",
      "Episode 20 - reward: 23\n",
      "Episode 30 - reward: 20\n",
      "Episode 40 - reward: 33\n",
      "Episode 50 - reward: 54\n",
      "Episode 60 - reward: 33\n",
      "Episode 70 - reward: 28\n",
      "Episode 80 - reward: 60\n",
      "Episode 90 - reward: 55\n",
      "Episode 100 - reward: 66\n",
      "Episode 110 - reward: 51\n",
      "Episode 120 - reward: 22\n",
      "Episode 130 - reward: 23\n",
      "Episode 140 - reward: 27\n",
      "Episode 150 - reward: 43\n",
      "Episode 160 - reward: 101\n",
      "Episode 170 - reward: 140\n",
      "Episode 180 - reward: 159\n",
      "Episode 190 - reward: 346\n",
      "Episode 200 - reward: 268\n",
      "Episode 210 - reward: 147\n",
      "Episode 220 - reward: 160\n",
      "Episode 230 - reward: 329\n",
      "Episode 240 - reward: 313\n",
      "Episode 250 - reward: 305\n",
      "Episode 260 - reward: 441\n",
      "Episode 270 - reward: 378\n",
      "Episode 280 - reward: 295\n",
      "Episode 290 - reward: 437\n",
      "Episode 300 - reward: 500\n",
      "Episode 310 - reward: 468\n",
      "Episode 320 - reward: 380\n",
      "Episode 330 - reward: 357\n",
      "Episode 340 - reward: 272\n",
      "Episode 350 - reward: 494\n",
      "Episode 360 - reward: 500\n",
      "Episode 370 - reward: 452\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 500\n",
      "Episode 400 - reward: 436\n",
      "Episode 410 - reward: 468\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 432\n",
      "Episode 440 - reward: 450\n",
      "Episode 450 - reward: 415\n",
      "Episode 460 - reward: 219\n",
      "Episode 470 - reward: 125\n",
      "Episode 480 - reward: 258\n",
      "Episode 490 - reward: 420\n",
      "Episode 500 - reward: 459\n",
      "Episode 10 - reward: 26\n",
      "Episode 20 - reward: 17\n",
      "Episode 30 - reward: 18\n",
      "Episode 40 - reward: 26\n",
      "Episode 50 - reward: 24\n",
      "Episode 60 - reward: 37\n",
      "Episode 70 - reward: 65\n",
      "Episode 80 - reward: 75\n",
      "Episode 90 - reward: 43\n",
      "Episode 100 - reward: 47\n",
      "Episode 110 - reward: 98\n",
      "Episode 120 - reward: 74\n",
      "Episode 130 - reward: 79\n",
      "Episode 140 - reward: 81\n",
      "Episode 150 - reward: 62\n",
      "Episode 160 - reward: 112\n",
      "Episode 170 - reward: 127\n",
      "Episode 180 - reward: 167\n",
      "Episode 190 - reward: 194\n",
      "Episode 200 - reward: 350\n",
      "Episode 210 - reward: 397\n",
      "Episode 220 - reward: 101\n",
      "Episode 230 - reward: 308\n",
      "Episode 240 - reward: 418\n",
      "Episode 250 - reward: 330\n",
      "Episode 260 - reward: 279\n",
      "Episode 270 - reward: 402\n",
      "Episode 280 - reward: 491\n",
      "Episode 290 - reward: 479\n",
      "Episode 300 - reward: 500\n",
      "Episode 310 - reward: 500\n",
      "Episode 320 - reward: 380\n",
      "Episode 330 - reward: 136\n",
      "Episode 340 - reward: 354\n",
      "Episode 350 - reward: 460\n",
      "Episode 360 - reward: 381\n",
      "Episode 370 - reward: 86\n",
      "Episode 380 - reward: 99\n",
      "Episode 390 - reward: 76\n",
      "Episode 400 - reward: 135\n",
      "Episode 410 - reward: 175\n",
      "Episode 420 - reward: 204\n",
      "Episode 430 - reward: 223\n",
      "Episode 440 - reward: 176\n",
      "Episode 450 - reward: 182\n",
      "Episode 460 - reward: 161\n",
      "Episode 470 - reward: 122\n",
      "Episode 480 - reward: 179\n",
      "Episode 490 - reward: 162\n",
      "Episode 500 - reward: 189\n",
      "Episode 10 - reward: 16\n",
      "Episode 20 - reward: 12\n",
      "Episode 30 - reward: 16\n",
      "Episode 40 - reward: 16\n",
      "Episode 50 - reward: 16\n",
      "Episode 60 - reward: 19\n",
      "Episode 70 - reward: 13\n",
      "Episode 80 - reward: 23\n",
      "Episode 90 - reward: 24\n",
      "Episode 100 - reward: 33\n",
      "Episode 110 - reward: 25\n",
      "Episode 120 - reward: 30\n",
      "Episode 130 - reward: 34\n",
      "Episode 140 - reward: 54\n",
      "Episode 150 - reward: 71\n",
      "Episode 160 - reward: 45\n",
      "Episode 170 - reward: 37\n",
      "Episode 180 - reward: 84\n",
      "Episode 190 - reward: 62\n",
      "Episode 200 - reward: 130\n",
      "Episode 210 - reward: 119\n",
      "Episode 220 - reward: 261\n",
      "Episode 230 - reward: 162\n",
      "Episode 240 - reward: 192\n",
      "Episode 250 - reward: 472\n",
      "Episode 260 - reward: 274\n",
      "Episode 270 - reward: 103\n",
      "Episode 280 - reward: 275\n",
      "Episode 290 - reward: 450\n",
      "Episode 300 - reward: 500\n",
      "Episode 310 - reward: 500\n",
      "Episode 320 - reward: 418\n",
      "Episode 330 - reward: 317\n",
      "Episode 340 - reward: 500\n",
      "Episode 350 - reward: 485\n",
      "Episode 360 - reward: 438\n",
      "Episode 370 - reward: 187\n",
      "Episode 380 - reward: 92\n",
      "Episode 390 - reward: 122\n",
      "Episode 400 - reward: 232\n",
      "Episode 410 - reward: 485\n",
      "Episode 420 - reward: 477\n",
      "Episode 430 - reward: 500\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 500\n",
      "Episode 460 - reward: 500\n",
      "Episode 470 - reward: 452\n",
      "Episode 480 - reward: 426\n",
      "Episode 490 - reward: 452\n",
      "Episode 500 - reward: 338\n",
      "Episode 10 - reward: 23\n",
      "Episode 20 - reward: 29\n",
      "Episode 30 - reward: 34\n",
      "Episode 40 - reward: 69\n",
      "Episode 50 - reward: 89\n",
      "Episode 60 - reward: 174\n",
      "Episode 70 - reward: 194\n",
      "Episode 80 - reward: 192\n",
      "Episode 90 - reward: 320\n",
      "Episode 100 - reward: 424\n",
      "Episode 110 - reward: 395\n",
      "Episode 120 - reward: 469\n",
      "Episode 130 - reward: 494\n",
      "Episode 140 - reward: 491\n",
      "Episode 150 - reward: 482\n",
      "Episode 160 - reward: 500\n",
      "Episode 170 - reward: 500\n",
      "Episode 180 - reward: 500\n",
      "Episode 190 - reward: 500\n",
      "Episode 200 - reward: 410\n",
      "Episode 210 - reward: 493\n",
      "Episode 220 - reward: 449\n",
      "Episode 230 - reward: 500\n",
      "Episode 240 - reward: 467\n",
      "Episode 250 - reward: 437\n",
      "Episode 260 - reward: 484\n",
      "Episode 270 - reward: 500\n",
      "Episode 280 - reward: 500\n",
      "Episode 290 - reward: 475\n",
      "Episode 300 - reward: 381\n",
      "Episode 310 - reward: 398\n",
      "Episode 320 - reward: 498\n",
      "Episode 330 - reward: 500\n",
      "Episode 340 - reward: 411\n",
      "Episode 350 - reward: 481\n",
      "Episode 360 - reward: 491\n",
      "Episode 370 - reward: 478\n",
      "Episode 380 - reward: 453\n",
      "Episode 390 - reward: 252\n",
      "Episode 400 - reward: 144\n",
      "Episode 410 - reward: 103\n",
      "Episode 420 - reward: 74\n",
      "Episode 430 - reward: 56\n",
      "Episode 440 - reward: 53\n",
      "Episode 450 - reward: 47\n",
      "Episode 460 - reward: 48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 470 - reward: 51\n",
      "Episode 480 - reward: 70\n",
      "Episode 490 - reward: 119\n",
      "Episode 500 - reward: 131\n",
      "Episode 10 - reward: 24\n",
      "Episode 20 - reward: 24\n",
      "Episode 30 - reward: 23\n",
      "Episode 40 - reward: 24\n",
      "Episode 50 - reward: 23\n",
      "Episode 60 - reward: 28\n",
      "Episode 70 - reward: 44\n",
      "Episode 80 - reward: 52\n",
      "Episode 90 - reward: 87\n",
      "Episode 100 - reward: 156\n",
      "Episode 110 - reward: 216\n",
      "Episode 120 - reward: 188\n",
      "Episode 130 - reward: 146\n",
      "Episode 140 - reward: 154\n",
      "Episode 150 - reward: 115\n",
      "Episode 160 - reward: 138\n",
      "Episode 170 - reward: 180\n",
      "Episode 180 - reward: 213\n",
      "Episode 190 - reward: 376\n",
      "Episode 200 - reward: 500\n",
      "Episode 210 - reward: 500\n",
      "Episode 220 - reward: 500\n",
      "Episode 230 - reward: 497\n",
      "Episode 240 - reward: 483\n",
      "Episode 250 - reward: 210\n",
      "Episode 260 - reward: 188\n",
      "Episode 270 - reward: 114\n",
      "Episode 280 - reward: 103\n",
      "Episode 290 - reward: 154\n",
      "Episode 300 - reward: 150\n",
      "Episode 310 - reward: 181\n",
      "Episode 320 - reward: 223\n",
      "Episode 330 - reward: 185\n",
      "Episode 340 - reward: 163\n",
      "Episode 350 - reward: 254\n",
      "Episode 360 - reward: 282\n",
      "Episode 370 - reward: 192\n",
      "Episode 380 - reward: 133\n",
      "Episode 390 - reward: 149\n",
      "Episode 400 - reward: 214\n",
      "Episode 410 - reward: 443\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 473\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 500\n",
      "Episode 460 - reward: 352\n",
      "Episode 470 - reward: 337\n",
      "Episode 480 - reward: 240\n",
      "Episode 490 - reward: 393\n",
      "Episode 500 - reward: 463\n",
      "Episode 10 - reward: 18\n",
      "Episode 20 - reward: 27\n",
      "Episode 30 - reward: 28\n",
      "Episode 40 - reward: 32\n",
      "Episode 50 - reward: 32\n",
      "Episode 60 - reward: 69\n",
      "Episode 70 - reward: 79\n",
      "Episode 80 - reward: 37\n",
      "Episode 90 - reward: 93\n",
      "Episode 100 - reward: 150\n",
      "Episode 110 - reward: 123\n",
      "Episode 120 - reward: 120\n",
      "Episode 130 - reward: 115\n",
      "Episode 140 - reward: 131\n",
      "Episode 150 - reward: 74\n",
      "Episode 160 - reward: 66\n",
      "Episode 170 - reward: 94\n",
      "Episode 180 - reward: 133\n",
      "Episode 190 - reward: 146\n",
      "Episode 200 - reward: 145\n",
      "Episode 210 - reward: 124\n",
      "Episode 220 - reward: 182\n",
      "Episode 230 - reward: 183\n",
      "Episode 240 - reward: 106\n",
      "Episode 250 - reward: 122\n",
      "Episode 260 - reward: 231\n",
      "Episode 270 - reward: 327\n",
      "Episode 280 - reward: 268\n",
      "Episode 290 - reward: 178\n",
      "Episode 300 - reward: 267\n",
      "Episode 310 - reward: 302\n",
      "Episode 320 - reward: 171\n",
      "Episode 330 - reward: 145\n",
      "Episode 340 - reward: 310\n",
      "Episode 350 - reward: 413\n",
      "Episode 360 - reward: 291\n",
      "Episode 370 - reward: 299\n",
      "Episode 380 - reward: 290\n",
      "Episode 390 - reward: 133\n",
      "Episode 400 - reward: 84\n",
      "Episode 410 - reward: 122\n",
      "Episode 420 - reward: 164\n",
      "Episode 430 - reward: 157\n",
      "Episode 440 - reward: 195\n",
      "Episode 450 - reward: 271\n",
      "Episode 460 - reward: 321\n",
      "Episode 470 - reward: 494\n",
      "Episode 480 - reward: 500\n",
      "Episode 490 - reward: 442\n",
      "Episode 500 - reward: 420\n",
      "Episode 10 - reward: 27\n",
      "Episode 20 - reward: 18\n",
      "Episode 30 - reward: 23\n",
      "Episode 40 - reward: 34\n",
      "Episode 50 - reward: 41\n",
      "Episode 60 - reward: 71\n",
      "Episode 70 - reward: 77\n",
      "Episode 80 - reward: 142\n",
      "Episode 90 - reward: 198\n",
      "Episode 100 - reward: 34\n",
      "Episode 110 - reward: 32\n",
      "Episode 120 - reward: 36\n",
      "Episode 130 - reward: 68\n",
      "Episode 140 - reward: 119\n",
      "Episode 150 - reward: 234\n",
      "Episode 160 - reward: 295\n",
      "Episode 170 - reward: 482\n",
      "Episode 180 - reward: 380\n",
      "Episode 190 - reward: 500\n",
      "Episode 200 - reward: 500\n",
      "Episode 210 - reward: 399\n",
      "Episode 220 - reward: 340\n",
      "Episode 230 - reward: 356\n",
      "Episode 240 - reward: 442\n",
      "Episode 250 - reward: 458\n",
      "Episode 260 - reward: 500\n",
      "Episode 270 - reward: 272\n",
      "Episode 280 - reward: 129\n",
      "Episode 290 - reward: 84\n",
      "Episode 300 - reward: 53\n",
      "Episode 310 - reward: 64\n",
      "Episode 320 - reward: 83\n",
      "Episode 330 - reward: 124\n",
      "Episode 340 - reward: 158\n",
      "Episode 350 - reward: 175\n",
      "Episode 360 - reward: 228\n",
      "Episode 370 - reward: 433\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 500\n",
      "Episode 400 - reward: 500\n",
      "Episode 410 - reward: 498\n",
      "Episode 420 - reward: 444\n",
      "Episode 430 - reward: 388\n",
      "Episode 440 - reward: 394\n",
      "Episode 450 - reward: 411\n",
      "Episode 460 - reward: 485\n",
      "Episode 470 - reward: 476\n",
      "Episode 480 - reward: 500\n",
      "Episode 490 - reward: 500\n",
      "Episode 500 - reward: 500\n",
      "Episode 10 - reward: 20\n",
      "Episode 20 - reward: 32\n",
      "Episode 30 - reward: 47\n",
      "Episode 40 - reward: 113\n",
      "Episode 50 - reward: 88\n",
      "Episode 60 - reward: 123\n",
      "Episode 70 - reward: 98\n",
      "Episode 80 - reward: 101\n",
      "Episode 90 - reward: 121\n",
      "Episode 100 - reward: 67\n",
      "Episode 110 - reward: 50\n",
      "Episode 120 - reward: 47\n",
      "Episode 130 - reward: 100\n",
      "Episode 140 - reward: 192\n",
      "Episode 150 - reward: 308\n",
      "Episode 160 - reward: 74\n",
      "Episode 170 - reward: 54\n",
      "Episode 180 - reward: 102\n",
      "Episode 190 - reward: 204\n",
      "Episode 200 - reward: 409\n",
      "Episode 210 - reward: 224\n",
      "Episode 220 - reward: 103\n",
      "Episode 230 - reward: 405\n",
      "Episode 240 - reward: 269\n",
      "Episode 250 - reward: 136\n",
      "Episode 260 - reward: 142\n",
      "Episode 270 - reward: 159\n",
      "Episode 280 - reward: 155\n",
      "Episode 290 - reward: 164\n",
      "Episode 300 - reward: 312\n",
      "Episode 310 - reward: 500\n",
      "Episode 320 - reward: 500\n",
      "Episode 330 - reward: 452\n",
      "Episode 340 - reward: 450\n",
      "Episode 350 - reward: 404\n",
      "Episode 360 - reward: 452\n",
      "Episode 370 - reward: 500\n",
      "Episode 380 - reward: 423\n",
      "Episode 390 - reward: 417\n",
      "Episode 400 - reward: 400\n",
      "Episode 410 - reward: 399\n",
      "Episode 420 - reward: 259\n",
      "Episode 430 - reward: 27\n",
      "Episode 440 - reward: 34\n",
      "Episode 450 - reward: 76\n",
      "Episode 460 - reward: 307\n",
      "Episode 470 - reward: 356\n",
      "Episode 480 - reward: 409\n",
      "Episode 490 - reward: 500\n",
      "Episode 500 - reward: 500\n",
      "Episode 10 - reward: 30\n",
      "Episode 20 - reward: 28\n",
      "Episode 30 - reward: 32\n",
      "Episode 40 - reward: 39\n",
      "Episode 50 - reward: 63\n",
      "Episode 60 - reward: 40\n",
      "Episode 70 - reward: 52\n",
      "Episode 80 - reward: 75\n",
      "Episode 90 - reward: 101\n",
      "Episode 100 - reward: 119\n",
      "Episode 110 - reward: 199\n",
      "Episode 120 - reward: 109\n",
      "Episode 130 - reward: 68\n",
      "Episode 140 - reward: 68\n",
      "Episode 150 - reward: 126\n",
      "Episode 160 - reward: 92\n",
      "Episode 170 - reward: 144\n",
      "Episode 180 - reward: 427\n",
      "Episode 190 - reward: 411\n",
      "Episode 200 - reward: 75\n",
      "Episode 210 - reward: 101\n",
      "Episode 220 - reward: 157\n",
      "Episode 230 - reward: 423\n",
      "Episode 240 - reward: 500\n",
      "Episode 250 - reward: 500\n",
      "Episode 260 - reward: 500\n",
      "Episode 270 - reward: 333\n",
      "Episode 280 - reward: 178\n",
      "Episode 290 - reward: 326\n",
      "Episode 300 - reward: 500\n",
      "Episode 310 - reward: 500\n",
      "Episode 320 - reward: 386\n",
      "Episode 330 - reward: 54\n",
      "Episode 340 - reward: 11\n",
      "Episode 350 - reward: 27\n",
      "Episode 360 - reward: 223\n",
      "Episode 370 - reward: 291\n",
      "Episode 380 - reward: 254\n",
      "Episode 390 - reward: 25\n",
      "Episode 400 - reward: 157\n",
      "Episode 410 - reward: 297\n",
      "Episode 420 - reward: 236\n",
      "Episode 430 - reward: 294\n",
      "Episode 440 - reward: 235\n",
      "Episode 450 - reward: 205\n",
      "Episode 460 - reward: 185\n",
      "Episode 470 - reward: 145\n",
      "Episode 480 - reward: 134\n",
      "Episode 490 - reward: 142\n",
      "Episode 500 - reward: 154\n",
      "Episode 10 - reward: 25\n",
      "Episode 20 - reward: 40\n",
      "Episode 30 - reward: 34\n",
      "Episode 40 - reward: 36\n",
      "Episode 50 - reward: 57\n",
      "Episode 60 - reward: 31\n",
      "Episode 70 - reward: 58\n",
      "Episode 80 - reward: 183\n",
      "Episode 90 - reward: 318\n",
      "Episode 100 - reward: 230\n",
      "Episode 110 - reward: 295\n",
      "Episode 120 - reward: 346\n",
      "Episode 130 - reward: 78\n",
      "Episode 140 - reward: 56\n",
      "Episode 150 - reward: 58\n",
      "Episode 160 - reward: 61\n",
      "Episode 170 - reward: 71\n",
      "Episode 180 - reward: 95\n",
      "Episode 190 - reward: 97\n",
      "Episode 200 - reward: 221\n",
      "Episode 210 - reward: 500\n",
      "Episode 220 - reward: 463\n",
      "Episode 230 - reward: 447\n",
      "Episode 240 - reward: 398\n",
      "Episode 250 - reward: 411\n",
      "Episode 260 - reward: 492\n",
      "Episode 270 - reward: 324\n",
      "Episode 280 - reward: 452\n",
      "Episode 290 - reward: 164\n",
      "Episode 300 - reward: 38\n",
      "Episode 310 - reward: 53\n",
      "Episode 320 - reward: 85\n",
      "Episode 330 - reward: 122\n",
      "Episode 340 - reward: 144\n",
      "Episode 350 - reward: 195\n",
      "Episode 360 - reward: 193\n",
      "Episode 370 - reward: 169\n",
      "Episode 380 - reward: 131\n",
      "Episode 390 - reward: 96\n",
      "Episode 400 - reward: 70\n",
      "Episode 410 - reward: 91\n",
      "Episode 420 - reward: 84\n",
      "Episode 430 - reward: 75\n",
      "Episode 440 - reward: 106\n",
      "Episode 450 - reward: 110\n",
      "Episode 460 - reward: 78\n",
      "Episode 470 - reward: 114\n",
      "Episode 480 - reward: 200\n",
      "Episode 490 - reward: 352\n",
      "Episode 500 - reward: 474\n",
      "Episode 10 - reward: 19\n",
      "Episode 20 - reward: 29\n",
      "Episode 30 - reward: 29\n",
      "Episode 40 - reward: 26\n",
      "Episode 50 - reward: 26\n",
      "Episode 60 - reward: 37\n",
      "Episode 70 - reward: 44\n",
      "Episode 80 - reward: 112\n",
      "Episode 90 - reward: 98\n",
      "Episode 100 - reward: 94\n",
      "Episode 110 - reward: 86\n",
      "Episode 120 - reward: 153\n",
      "Episode 130 - reward: 210\n",
      "Episode 140 - reward: 76\n",
      "Episode 150 - reward: 64\n",
      "Episode 160 - reward: 79\n",
      "Episode 170 - reward: 106\n",
      "Episode 180 - reward: 113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 190 - reward: 147\n",
      "Episode 200 - reward: 252\n",
      "Episode 210 - reward: 294\n",
      "Episode 220 - reward: 286\n",
      "Episode 230 - reward: 89\n",
      "Episode 240 - reward: 105\n",
      "Episode 250 - reward: 215\n",
      "Episode 260 - reward: 365\n",
      "Episode 270 - reward: 338\n",
      "Episode 280 - reward: 438\n",
      "Episode 290 - reward: 476\n",
      "Episode 300 - reward: 467\n",
      "Episode 310 - reward: 456\n",
      "Episode 320 - reward: 442\n",
      "Episode 330 - reward: 491\n",
      "Episode 340 - reward: 500\n",
      "Episode 350 - reward: 328\n",
      "Episode 360 - reward: 151\n",
      "Episode 370 - reward: 266\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 500\n",
      "Episode 400 - reward: 500\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 488\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 460\n",
      "Episode 460 - reward: 318\n",
      "Episode 470 - reward: 245\n",
      "Episode 480 - reward: 392\n",
      "Episode 490 - reward: 453\n",
      "Episode 500 - reward: 500\n",
      "Episode 10 - reward: 21\n",
      "Episode 20 - reward: 29\n",
      "Episode 30 - reward: 20\n",
      "Episode 40 - reward: 25\n",
      "Episode 50 - reward: 22\n",
      "Episode 60 - reward: 24\n",
      "Episode 70 - reward: 74\n",
      "Episode 80 - reward: 46\n",
      "Episode 90 - reward: 78\n",
      "Episode 100 - reward: 100\n",
      "Episode 110 - reward: 134\n",
      "Episode 120 - reward: 72\n",
      "Episode 130 - reward: 76\n",
      "Episode 140 - reward: 110\n",
      "Episode 150 - reward: 52\n",
      "Episode 160 - reward: 44\n",
      "Episode 170 - reward: 83\n",
      "Episode 180 - reward: 87\n",
      "Episode 190 - reward: 133\n",
      "Episode 200 - reward: 89\n",
      "Episode 210 - reward: 61\n",
      "Episode 220 - reward: 104\n",
      "Episode 230 - reward: 166\n",
      "Episode 240 - reward: 177\n",
      "Episode 250 - reward: 120\n",
      "Episode 260 - reward: 131\n",
      "Episode 270 - reward: 174\n",
      "Episode 280 - reward: 181\n",
      "Episode 290 - reward: 97\n",
      "Episode 300 - reward: 82\n",
      "Episode 310 - reward: 108\n",
      "Episode 320 - reward: 127\n",
      "Episode 330 - reward: 167\n",
      "Episode 340 - reward: 90\n",
      "Episode 350 - reward: 58\n",
      "Episode 360 - reward: 52\n",
      "Episode 370 - reward: 48\n",
      "Episode 380 - reward: 66\n",
      "Episode 390 - reward: 94\n",
      "Episode 400 - reward: 128\n",
      "Episode 410 - reward: 163\n",
      "Episode 420 - reward: 262\n",
      "Episode 430 - reward: 141\n",
      "Episode 440 - reward: 95\n",
      "Episode 450 - reward: 114\n",
      "Episode 460 - reward: 82\n",
      "Episode 470 - reward: 43\n",
      "Episode 480 - reward: 37\n",
      "Episode 490 - reward: 37\n",
      "Episode 500 - reward: 53\n",
      "Episode 10 - reward: 26\n",
      "Episode 20 - reward: 17\n",
      "Episode 30 - reward: 35\n",
      "Episode 40 - reward: 56\n",
      "Episode 50 - reward: 60\n",
      "Episode 60 - reward: 192\n",
      "Episode 70 - reward: 36\n",
      "Episode 80 - reward: 32\n",
      "Episode 90 - reward: 78\n",
      "Episode 100 - reward: 208\n",
      "Episode 110 - reward: 172\n",
      "Episode 120 - reward: 173\n",
      "Episode 130 - reward: 130\n",
      "Episode 140 - reward: 127\n",
      "Episode 150 - reward: 125\n",
      "Episode 160 - reward: 97\n",
      "Episode 170 - reward: 33\n",
      "Episode 180 - reward: 27\n",
      "Episode 190 - reward: 27\n",
      "Episode 200 - reward: 36\n",
      "Episode 210 - reward: 45\n",
      "Episode 220 - reward: 50\n",
      "Episode 230 - reward: 154\n",
      "Episode 240 - reward: 420\n",
      "Episode 250 - reward: 138\n",
      "Episode 260 - reward: 198\n",
      "Episode 270 - reward: 500\n",
      "Episode 280 - reward: 474\n",
      "Episode 290 - reward: 482\n",
      "Episode 300 - reward: 427\n",
      "Episode 310 - reward: 350\n",
      "Episode 320 - reward: 439\n",
      "Episode 330 - reward: 38\n",
      "Episode 340 - reward: 27\n",
      "Episode 350 - reward: 136\n",
      "Episode 360 - reward: 347\n",
      "Episode 370 - reward: 464\n",
      "Episode 380 - reward: 248\n",
      "Episode 390 - reward: 114\n",
      "Episode 400 - reward: 87\n",
      "Episode 410 - reward: 40\n",
      "Episode 420 - reward: 40\n",
      "Episode 430 - reward: 38\n",
      "Episode 440 - reward: 40\n",
      "Episode 450 - reward: 44\n",
      "Episode 460 - reward: 48\n",
      "Episode 470 - reward: 51\n",
      "Episode 480 - reward: 53\n",
      "Episode 490 - reward: 51\n",
      "Episode 500 - reward: 49\n",
      "Episode 10 - reward: 25\n",
      "Episode 20 - reward: 30\n",
      "Episode 30 - reward: 38\n",
      "Episode 40 - reward: 53\n",
      "Episode 50 - reward: 90\n",
      "Episode 60 - reward: 146\n",
      "Episode 70 - reward: 118\n",
      "Episode 80 - reward: 74\n",
      "Episode 90 - reward: 222\n",
      "Episode 100 - reward: 328\n",
      "Episode 110 - reward: 340\n",
      "Episode 120 - reward: 500\n",
      "Episode 130 - reward: 452\n",
      "Episode 140 - reward: 402\n",
      "Episode 150 - reward: 48\n",
      "Episode 160 - reward: 15\n",
      "Episode 170 - reward: 39\n",
      "Episode 180 - reward: 101\n",
      "Episode 190 - reward: 84\n",
      "Episode 200 - reward: 120\n",
      "Episode 210 - reward: 134\n",
      "Episode 220 - reward: 194\n",
      "Episode 230 - reward: 485\n",
      "Episode 240 - reward: 500\n",
      "Episode 250 - reward: 500\n",
      "Episode 260 - reward: 500\n",
      "Episode 270 - reward: 500\n",
      "Episode 280 - reward: 500\n",
      "Episode 290 - reward: 500\n",
      "Episode 300 - reward: 500\n",
      "Episode 310 - reward: 500\n",
      "Episode 320 - reward: 195\n",
      "Episode 330 - reward: 403\n",
      "Episode 340 - reward: 500\n",
      "Episode 350 - reward: 500\n",
      "Episode 360 - reward: 500\n",
      "Episode 370 - reward: 500\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 354\n",
      "Episode 400 - reward: 403\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 453\n",
      "Episode 430 - reward: 268\n",
      "Episode 440 - reward: 260\n",
      "Episode 450 - reward: 452\n",
      "Episode 460 - reward: 306\n",
      "Episode 470 - reward: 402\n",
      "Episode 480 - reward: 110\n",
      "Episode 490 - reward: 305\n",
      "Episode 500 - reward: 196\n",
      "Episode 10 - reward: 18\n",
      "Episode 20 - reward: 22\n",
      "Episode 30 - reward: 22\n",
      "Episode 40 - reward: 33\n",
      "Episode 50 - reward: 28\n",
      "Episode 60 - reward: 45\n",
      "Episode 70 - reward: 85\n",
      "Episode 80 - reward: 113\n",
      "Episode 90 - reward: 162\n",
      "Episode 100 - reward: 233\n",
      "Episode 110 - reward: 244\n",
      "Episode 120 - reward: 172\n",
      "Episode 130 - reward: 85\n",
      "Episode 140 - reward: 30\n",
      "Episode 150 - reward: 45\n",
      "Episode 160 - reward: 84\n",
      "Episode 170 - reward: 191\n",
      "Episode 180 - reward: 236\n",
      "Episode 190 - reward: 379\n",
      "Episode 200 - reward: 331\n",
      "Episode 210 - reward: 488\n",
      "Episode 220 - reward: 500\n",
      "Episode 230 - reward: 438\n",
      "Episode 240 - reward: 450\n",
      "Episode 250 - reward: 452\n",
      "Episode 260 - reward: 434\n",
      "Episode 270 - reward: 498\n",
      "Episode 280 - reward: 482\n",
      "Episode 290 - reward: 414\n",
      "Episode 300 - reward: 453\n",
      "Episode 310 - reward: 178\n",
      "Episode 320 - reward: 204\n",
      "Episode 330 - reward: 154\n",
      "Episode 340 - reward: 155\n",
      "Episode 350 - reward: 156\n",
      "Episode 360 - reward: 145\n",
      "Episode 370 - reward: 150\n",
      "Episode 380 - reward: 179\n",
      "Episode 390 - reward: 196\n",
      "Episode 400 - reward: 120\n",
      "Episode 410 - reward: 131\n",
      "Episode 420 - reward: 179\n",
      "Episode 430 - reward: 342\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 500\n",
      "Episode 460 - reward: 500\n",
      "Episode 470 - reward: 500\n",
      "Episode 480 - reward: 354\n",
      "Episode 490 - reward: 500\n",
      "Episode 500 - reward: 500\n",
      "Episode 10 - reward: 14\n",
      "Episode 20 - reward: 19\n",
      "Episode 30 - reward: 20\n",
      "Episode 40 - reward: 29\n",
      "Episode 50 - reward: 30\n",
      "Episode 60 - reward: 31\n",
      "Episode 70 - reward: 28\n",
      "Episode 80 - reward: 31\n",
      "Episode 90 - reward: 55\n",
      "Episode 100 - reward: 30\n",
      "Episode 110 - reward: 28\n",
      "Episode 120 - reward: 68\n",
      "Episode 130 - reward: 43\n",
      "Episode 140 - reward: 64\n",
      "Episode 150 - reward: 169\n",
      "Episode 160 - reward: 80\n",
      "Episode 170 - reward: 122\n",
      "Episode 180 - reward: 289\n",
      "Episode 190 - reward: 257\n",
      "Episode 200 - reward: 92\n",
      "Episode 210 - reward: 53\n",
      "Episode 220 - reward: 67\n",
      "Episode 230 - reward: 122\n",
      "Episode 240 - reward: 257\n",
      "Episode 250 - reward: 183\n",
      "Episode 260 - reward: 142\n",
      "Episode 270 - reward: 102\n",
      "Episode 280 - reward: 430\n",
      "Episode 290 - reward: 121\n",
      "Episode 300 - reward: 107\n",
      "Episode 310 - reward: 156\n",
      "Episode 320 - reward: 246\n",
      "Episode 330 - reward: 216\n",
      "Episode 340 - reward: 257\n",
      "Episode 350 - reward: 446\n",
      "Episode 360 - reward: 500\n",
      "Episode 370 - reward: 500\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 500\n",
      "Episode 400 - reward: 500\n",
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 469\n",
      "Episode 430 - reward: 440\n",
      "Episode 440 - reward: 428\n",
      "Episode 450 - reward: 297\n",
      "Episode 460 - reward: 263\n",
      "Episode 470 - reward: 276\n",
      "Episode 480 - reward: 416\n",
      "Episode 490 - reward: 303\n",
      "Episode 500 - reward: 373\n",
      "Episode 10 - reward: 32\n",
      "Episode 20 - reward: 21\n",
      "Episode 30 - reward: 30\n",
      "Episode 40 - reward: 34\n",
      "Episode 50 - reward: 24\n",
      "Episode 60 - reward: 27\n",
      "Episode 70 - reward: 22\n",
      "Episode 80 - reward: 24\n",
      "Episode 90 - reward: 30\n",
      "Episode 100 - reward: 40\n",
      "Episode 110 - reward: 57\n",
      "Episode 120 - reward: 112\n",
      "Episode 130 - reward: 101\n",
      "Episode 140 - reward: 56\n",
      "Episode 150 - reward: 233\n",
      "Episode 160 - reward: 296\n",
      "Episode 170 - reward: 222\n",
      "Episode 180 - reward: 383\n",
      "Episode 190 - reward: 500\n",
      "Episode 200 - reward: 500\n",
      "Episode 210 - reward: 384\n",
      "Episode 220 - reward: 500\n",
      "Episode 230 - reward: 458\n",
      "Episode 240 - reward: 458\n",
      "Episode 250 - reward: 361\n",
      "Episode 260 - reward: 141\n",
      "Episode 270 - reward: 110\n",
      "Episode 280 - reward: 97\n",
      "Episode 290 - reward: 95\n",
      "Episode 300 - reward: 111\n",
      "Episode 310 - reward: 131\n",
      "Episode 320 - reward: 125\n",
      "Episode 330 - reward: 124\n",
      "Episode 340 - reward: 268\n",
      "Episode 350 - reward: 500\n",
      "Episode 360 - reward: 500\n",
      "Episode 370 - reward: 500\n",
      "Episode 380 - reward: 500\n",
      "Episode 390 - reward: 500\n",
      "Episode 400 - reward: 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 410 - reward: 500\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 500\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 500\n",
      "Episode 460 - reward: 369\n",
      "Episode 470 - reward: 196\n",
      "Episode 480 - reward: 354\n",
      "Episode 490 - reward: 500\n",
      "Episode 500 - reward: 210\n",
      "Episode 10 - reward: 20\n",
      "Episode 20 - reward: 26\n",
      "Episode 30 - reward: 29\n",
      "Episode 40 - reward: 26\n",
      "Episode 50 - reward: 39\n",
      "Episode 60 - reward: 24\n",
      "Episode 70 - reward: 60\n",
      "Episode 80 - reward: 74\n",
      "Episode 90 - reward: 222\n",
      "Episode 100 - reward: 168\n",
      "Episode 110 - reward: 40\n",
      "Episode 120 - reward: 76\n",
      "Episode 130 - reward: 114\n",
      "Episode 140 - reward: 246\n",
      "Episode 150 - reward: 162\n",
      "Episode 160 - reward: 123\n",
      "Episode 170 - reward: 101\n",
      "Episode 180 - reward: 82\n",
      "Episode 190 - reward: 60\n",
      "Episode 200 - reward: 65\n",
      "Episode 210 - reward: 79\n",
      "Episode 220 - reward: 104\n",
      "Episode 230 - reward: 124\n",
      "Episode 240 - reward: 149\n",
      "Episode 250 - reward: 159\n",
      "Episode 260 - reward: 187\n",
      "Episode 270 - reward: 296\n",
      "Episode 280 - reward: 365\n",
      "Episode 290 - reward: 258\n",
      "Episode 300 - reward: 82\n",
      "Episode 310 - reward: 33\n",
      "Episode 320 - reward: 43\n",
      "Episode 330 - reward: 73\n",
      "Episode 340 - reward: 124\n",
      "Episode 350 - reward: 134\n",
      "Episode 360 - reward: 128\n",
      "Episode 370 - reward: 96\n",
      "Episode 380 - reward: 74\n",
      "Episode 390 - reward: 57\n",
      "Episode 400 - reward: 52\n",
      "Episode 410 - reward: 64\n",
      "Episode 420 - reward: 99\n",
      "Episode 430 - reward: 221\n",
      "Episode 440 - reward: 314\n",
      "Episode 450 - reward: 256\n",
      "Episode 460 - reward: 307\n",
      "Episode 470 - reward: 226\n",
      "Episode 480 - reward: 321\n",
      "Episode 490 - reward: 270\n",
      "Episode 500 - reward: 329\n",
      "Episode 10 - reward: 18\n",
      "Episode 20 - reward: 23\n",
      "Episode 30 - reward: 30\n",
      "Episode 40 - reward: 39\n",
      "Episode 50 - reward: 42\n",
      "Episode 60 - reward: 47\n",
      "Episode 70 - reward: 102\n",
      "Episode 80 - reward: 101\n",
      "Episode 90 - reward: 122\n",
      "Episode 100 - reward: 112\n",
      "Episode 110 - reward: 47\n",
      "Episode 120 - reward: 42\n",
      "Episode 130 - reward: 77\n",
      "Episode 140 - reward: 121\n",
      "Episode 150 - reward: 147\n",
      "Episode 160 - reward: 134\n",
      "Episode 170 - reward: 131\n",
      "Episode 180 - reward: 175\n",
      "Episode 190 - reward: 184\n",
      "Episode 200 - reward: 124\n",
      "Episode 210 - reward: 235\n",
      "Episode 220 - reward: 278\n",
      "Episode 230 - reward: 301\n",
      "Episode 240 - reward: 386\n",
      "Episode 250 - reward: 285\n",
      "Episode 260 - reward: 24\n",
      "Episode 270 - reward: 10\n",
      "Episode 280 - reward: 29\n",
      "Episode 290 - reward: 10\n",
      "Episode 300 - reward: 29\n",
      "Episode 310 - reward: 25\n",
      "Episode 320 - reward: 130\n",
      "Episode 330 - reward: 135\n",
      "Episode 340 - reward: 172\n",
      "Episode 350 - reward: 104\n",
      "Episode 360 - reward: 69\n",
      "Episode 370 - reward: 96\n",
      "Episode 380 - reward: 130\n",
      "Episode 390 - reward: 243\n",
      "Episode 400 - reward: 294\n",
      "Episode 410 - reward: 141\n",
      "Episode 420 - reward: 117\n",
      "Episode 430 - reward: 160\n",
      "Episode 440 - reward: 92\n",
      "Episode 450 - reward: 91\n",
      "Episode 460 - reward: 213\n",
      "Episode 470 - reward: 428\n",
      "Episode 480 - reward: 485\n",
      "Episode 490 - reward: 436\n",
      "Episode 500 - reward: 500\n",
      "Episode 10 - reward: 15\n",
      "Episode 20 - reward: 25\n",
      "Episode 30 - reward: 22\n",
      "Episode 40 - reward: 30\n",
      "Episode 50 - reward: 34\n",
      "Episode 60 - reward: 34\n",
      "Episode 70 - reward: 24\n",
      "Episode 80 - reward: 20\n",
      "Episode 90 - reward: 36\n",
      "Episode 100 - reward: 74\n",
      "Episode 110 - reward: 131\n",
      "Episode 120 - reward: 101\n",
      "Episode 130 - reward: 50\n",
      "Episode 140 - reward: 35\n",
      "Episode 150 - reward: 34\n",
      "Episode 160 - reward: 35\n",
      "Episode 170 - reward: 30\n",
      "Episode 180 - reward: 34\n",
      "Episode 190 - reward: 77\n",
      "Episode 200 - reward: 97\n",
      "Episode 210 - reward: 122\n",
      "Episode 220 - reward: 91\n",
      "Episode 230 - reward: 55\n",
      "Episode 240 - reward: 52\n",
      "Episode 250 - reward: 153\n",
      "Episode 260 - reward: 111\n",
      "Episode 270 - reward: 97\n",
      "Episode 280 - reward: 133\n",
      "Episode 290 - reward: 146\n",
      "Episode 300 - reward: 182\n",
      "Episode 310 - reward: 217\n",
      "Episode 320 - reward: 190\n",
      "Episode 330 - reward: 199\n",
      "Episode 340 - reward: 247\n",
      "Episode 350 - reward: 332\n",
      "Episode 360 - reward: 137\n",
      "Episode 370 - reward: 108\n",
      "Episode 380 - reward: 72\n",
      "Episode 390 - reward: 117\n",
      "Episode 400 - reward: 202\n",
      "Episode 410 - reward: 342\n",
      "Episode 420 - reward: 500\n",
      "Episode 430 - reward: 477\n",
      "Episode 440 - reward: 500\n",
      "Episode 450 - reward: 410\n",
      "Episode 460 - reward: 500\n",
      "Episode 470 - reward: 480\n",
      "Episode 480 - reward: 500\n",
      "Episode 490 - reward: 500\n",
      "Episode 500 - reward: 500\n",
      "Episode 10 - reward: 20\n",
      "Episode 20 - reward: 19\n",
      "Episode 30 - reward: 31\n",
      "Episode 40 - reward: 46\n",
      "Episode 50 - reward: 37\n",
      "Episode 60 - reward: 85\n",
      "Episode 70 - reward: 107\n",
      "Episode 80 - reward: 127\n",
      "Episode 90 - reward: 231\n",
      "Episode 100 - reward: 195\n",
      "Episode 110 - reward: 273\n",
      "Episode 120 - reward: 237\n",
      "Episode 130 - reward: 188\n",
      "Episode 140 - reward: 221\n",
      "Episode 150 - reward: 238\n",
      "Episode 160 - reward: 321\n",
      "Episode 170 - reward: 308\n",
      "Episode 180 - reward: 466\n",
      "Episode 190 - reward: 329\n",
      "Episode 200 - reward: 59\n",
      "Episode 210 - reward: 22\n",
      "Episode 220 - reward: 42\n",
      "Episode 230 - reward: 104\n",
      "Episode 240 - reward: 151\n",
      "Episode 250 - reward: 184\n",
      "Episode 260 - reward: 202\n",
      "Episode 270 - reward: 222\n",
      "Episode 280 - reward: 386\n",
      "Episode 290 - reward: 500\n",
      "Episode 300 - reward: 500\n",
      "Episode 310 - reward: 500\n",
      "Episode 320 - reward: 500\n",
      "Episode 330 - reward: 467\n",
      "Episode 340 - reward: 499\n",
      "Episode 350 - reward: 500\n",
      "Episode 360 - reward: 467\n",
      "Episode 370 - reward: 473\n",
      "Episode 380 - reward: 228\n",
      "Episode 390 - reward: 157\n",
      "Episode 400 - reward: 346\n",
      "Episode 410 - reward: 484\n",
      "Episode 420 - reward: 478\n",
      "Episode 430 - reward: 328\n",
      "Episode 440 - reward: 82\n",
      "Episode 450 - reward: 60\n",
      "Episode 460 - reward: 96\n",
      "Episode 470 - reward: 150\n",
      "Episode 480 - reward: 169\n",
      "Episode 490 - reward: 169\n",
      "Episode 500 - reward: 206\n"
     ]
    }
   ],
   "source": [
    "n_runs = 30\n",
    "results = []\n",
    "for i in range(n_runs):\n",
    "    trained_agentPG, cumulative_rewardPG, lossesPG, steps_log = train_cartpole_entropy(n_episodes = 500, lr=5e-3, H=1e-2)\n",
    "    results.append(cumulative_rewardPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Results/entropy_REINFORCE_perf', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(results)\n",
    "results_v0 = np.array(results_v0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "episodes = np.arange(1,len(results[0])+1)\n",
    "plt.plot(episodes, results.mean(axis=0), label='entropy')\n",
    "plt.plot(episodes, results_v0.mean(axis=0), label='standard')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episodes, lossesPG)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
